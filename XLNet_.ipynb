{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-bhK596u5kB"
   },
   "source": [
    "## Models\n",
    "- DistillBERT\n",
    "- XLNet\n",
    "\n",
    "## Accuracies\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scTmVI8749nD"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install SentencePiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUhTaKyW4YBk"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import compute_class_weight\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, XLNetForSequenceClassification, XLNetTokenizer, XLNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qbutmwTngIR",
    "outputId": "55ff2ebc-387b-4cfb-c512-066f80cb0617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'MIDAS-Task/': No such file or directory\n",
      "Password: ··········\n"
     ]
    }
   ],
   "source": [
    "# user = input('User name: ')\n",
    "!rm -r MIDAS-Task/\n",
    "password = getpass('Password: ')\n",
    "password = urllib.parse.quote(password) # your password is converted into url format\n",
    "# repo_name = input('Repo name: ')\n",
    "cmd_string = f'git clone https://YashBhartia00:{password}@github.com/YashBhartia00/MIDAS-Task.git'\n",
    "os.system(cmd_string)\n",
    "cmd_string, password = \"\", \"\" # removing the password from the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49Q1EvxG4PR-"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./MIDAS-Task/flipkart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-crns-ytUuK7",
    "outputId": "bd2541a1-e868-4758-9d2b-968859c186ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENCODE_CAT</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alisha Alisha Solid Women's Cycling Shorts key...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AW AW Bellies key features of aw bellies sanda...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Alisha Alisha Solid Women's Cycling Shorts key...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Alisha Alisha Solid Women's Cycling Shorts key...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>dilli bazaaar dilli bazaaar Bellies, Corporate...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENCODE_CAT                                               TEXT  CATEGORY\n",
       "0           0  Alisha Alisha Solid Women's Cycling Shorts key...  Clothing\n",
       "1           2  AW AW Bellies key features of aw bellies sanda...  Footwear\n",
       "2           0  Alisha Alisha Solid Women's Cycling Shorts key...  Clothing\n",
       "3           0  Alisha Alisha Solid Women's Cycling Shorts key...  Clothing\n",
       "4           2  dilli bazaaar dilli bazaaar Bellies, Corporate...  Footwear"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AbShrzgtln_"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./MIDAS-Task/flipkart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "erpAAn8gMm-l",
    "outputId": "1683e020-5aad-4f2e-fc23-c4f173d2783d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENCODE_CAT</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alisha Alisha Solid Women's Cycling Shorts key...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AW AW Bellies key features of aw bellies sanda...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Alisha Alisha Solid Women's Cycling Shorts key...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Alisha Alisha Solid Women's Cycling Shorts key...</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>dilli bazaaar dilli bazaaar Bellies, Corporate...</td>\n",
       "      <td>Footwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENCODE_CAT                                               TEXT  CATEGORY\n",
       "0           0  Alisha Alisha Solid Women's Cycling Shorts key...  Clothing\n",
       "1           2  AW AW Bellies key features of aw bellies sanda...  Footwear\n",
       "2           0  Alisha Alisha Solid Women's Cycling Shorts key...  Clothing\n",
       "3           0  Alisha Alisha Solid Women's Cycling Shorts key...  Clothing\n",
       "4           2  dilli bazaaar dilli bazaaar Bellies, Corporate...  Footwear"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['ENCODE_CAT','TEXT', 'CATEGORY']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAxwSC0Vo7wM"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# Torch RNG\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "# Python RNG\n",
    "np.random.seed(seed)\n",
    "# random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "dd7cd9aea58e46039f6e4337520cfe62",
      "a8d8800d797a4b4786dbf0b583e4b09a",
      "8beb96ea11254e14a693e6acf8f297c8",
      "2ae06d60a24c4ded9a5a761eca994012",
      "29a5a26093a04f9ab3cdb0e6047a9d8f",
      "5d660d8a3fc34dc09f5d6c3c251199a8",
      "8fd116a2abc94062b365f77574b97466",
      "033f417598e245a7a91ff4ec9e01344c",
      "1f5188b5ab2f4091b8c88c1be8761ab7",
      "ba0f9eb03e9349bc8940bc0362c42b86",
      "70324cb7e09b464692a21b66480fc1c2",
      "431aa13dcdba4c3a8a6d472e64d44e72",
      "f27d7340b1f04cf786b69e65f4453527",
      "2c58603c9d79419f9e7475f4454a1c54",
      "93235cacd8664c85acebc92fa2d79820",
      "28f89249755e44b2b674299d5b02e251"
     ]
    },
    "id": "fyklYfZSLro1",
    "outputId": "71efee51-5e30-4534-e395-dd4afe1b016d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7cd9aea58e46039f6e4337520cfe62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5188b5ab2f4091b8c88c1be8761ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1382015.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "NUMLABELS = df.CATEGORY.nunique()\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7l6Jy2DLrl3"
   },
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.TEXT[index])\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.ENCODE_CAT[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS7zRlagLrhx",
    "outputId": "474c0428-2b70-4154-c1ca-0577adfaee26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (19215, 3)\n",
      "TRAIN Dataset: (15372, 3)\n",
      "TEST Dataset: (3843, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWDvFyc9Lrat"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPl8EVpfu7HF"
   },
   "source": [
    "## Models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3aIOiVGvcIg"
   },
   "source": [
    "### DistsillBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHVllCTZMBcY"
   },
   "outputs": [],
   "source": [
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 28)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a9ea55ebbc4944d4a8e09af5df51a0ba",
      "805235e746b54ef0a7eaeeb6003688e1",
      "c8af4ea753f64ef0a9026e55fe70e5d8",
      "9bd55b5ff9b94d4b8e8f7e5170d17399",
      "af65d665374c407d9a73e9ceca872030",
      "30ac40c9857049cd92205abf90417495",
      "397756d45e744570923fc0d126886ddb",
      "34c433a6584b4b689a271d181f90cb72",
      "ea7e184c32804f748be14a71bb9acf52",
      "7d97dac059b64df6866501ee2656ce1a",
      "51cc5007b53741e68e8f99075ad3b9d9",
      "c3ee5617cc7446198933aaa5b781cbd7",
      "adde972b1f814b14ab0654e7e0bdc2ad",
      "dfbfb17265f444a78de57a18e34af7ac",
      "001d9e5bd2624a1f80bc1b6c711c345d",
      "8bc3a15a49d74bceaf2596bf82b236ba"
     ]
    },
    "id": "1LOHFdoEMBTP",
    "outputId": "4d91ab44-3bd8-46d0-cabd-263f8aff7836"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ea55ebbc4944d4a8e09af5df51a0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7e184c32804f748be14a71bb9acf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiLJtKJlvUgY"
   },
   "source": [
    "### XLNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4c87fa8b40b74713b2154841cb2381ba",
      "d732ac48de144b0ca3a0d8ab9a9d63cf",
      "9ef081c49b734170bcab9c71013293b6",
      "003cd01772534e10b6d0425338407bdc",
      "3e45214b0f724d13ae453d9866a0bcb2",
      "e38214c1da6e4e82b9c91589924c0e60",
      "5862321621d64f2994e997439549b9e1",
      "3f12388d372a4ac68f40a7e471be44bd",
      "27470550cb604a1591e145754dbad19a",
      "c60fb9328264495896719cd2924ecd7d",
      "89d0c63e1a8144fdb83cd2d4068536b5",
      "e6820355bb4e4843bd84d8f401300d1e",
      "6b650ab0a7e54d0f873b8393a725f7f1",
      "60729f7712fc4c80ad5f9b283a5ad33c",
      "a86bfa28c1fa46ec9b809ad44bbfea67",
      "64a00263f5b54b12b249a089e4eeb4ff"
     ]
    },
    "id": "hZWq3iFJvQ7w",
    "outputId": "bd1b7bf6-5991-4bb0-fe8e-e4b17fc7dca9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c87fa8b40b74713b2154841cb2381ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27470550cb604a1591e145754dbad19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetClass(\n",
       "  (l1): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class XLNetClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XLNetClass, self).__init__()\n",
    "        self.l1 = XLNetModel.from_pretrained('xlnet-base-cased')\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, NUMLABELS)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "model = XLNetClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JPet3x3vFCj"
   },
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZEk6YMXJymR"
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', np.unique(df['ENCODE_CAT']), df[\"ENCODE_CAT\"])\n",
    "class_weights = torch.FloatTensor(class_weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcKDfclaMePN"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGxHJPYyMfnh"
   },
   "outputs": [],
   "source": [
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJxmdnMKMfzF"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    preds_epoch = []\n",
    "    labels_epoch = []\n",
    "    model.train()\n",
    "    for i,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "\n",
    "        preds.extend(list(np.argmax(outputs.detach().cpu().numpy(), axis=1).flatten()))\n",
    "        labels.extend(list(targets.detach().cpu().numpy().flatten()))\n",
    "        preds_epoch.extend(list(np.argmax(outputs.detach().cpu().numpy(), axis=1).flatten()))\n",
    "        labels_epoch.extend(list(targets.detach().cpu().numpy().flatten()))\n",
    "\n",
    "        if i%100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training Loss for {i} steps: {loss_step}\")\n",
    "            print(f\"Train Accuracy for {i} steps:\\n{metrics.classification_report(labels, preds)}\")\n",
    "            preds = []\n",
    "            labels = []\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {metrics.classification_report(labels_epoch, preds_epoch)}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "\n",
    "    #validation\n",
    "    model.eval()\n",
    "    preds, labels =[],[]\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    with torch.no_grad():\n",
    "            for _, data in enumerate(testing_loader, 0):\n",
    "                ids = data['ids'].to(device, dtype = torch.long)\n",
    "                mask = data['mask'].to(device, dtype = torch.long)\n",
    "                targets = data['targets'].to(device, dtype = torch.long)\n",
    "                outputs = model(ids, mask).squeeze()\n",
    "\n",
    "                nb_tr_steps += 1\n",
    "                nb_tr_examples+=targets.size(0)\n",
    "\n",
    "                logits = outputs.detach().cpu().numpy()\n",
    "                try:\n",
    "                  preds.extend(list(np.argmax(logits, axis=1).flatten()))\n",
    "                except:\n",
    "                  preds.extend(list(np.argmax(logits).flatten()))\n",
    "                  \n",
    "                labels.extend(list(targets.detach().cpu().numpy().flatten()))\n",
    "                \n",
    "            print(f\"Validation Accuracy Epoch: {metrics.classification_report(labels, preds)}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hY3APmRA_-2w",
    "outputId": "b35e47c8-c086-4811-9397-e0473d0d116b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for 0 steps: 2.409801483154297\n",
      "Train Accuracy for 0 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.33      1.00      0.50         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.12         8\n",
      "   macro avg       0.05      0.14      0.07         8\n",
      "weighted avg       0.04      0.12      0.06         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for 100 steps: 2.8859971490236793\n",
      "Train Accuracy for 100 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.19       273\n",
      "           1       0.07      0.17      0.10         6\n",
      "           2       0.13      0.15      0.14        54\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.17      0.03      0.06        30\n",
      "           6       0.00      0.00      0.00        11\n",
      "           7       0.00      0.00      0.00        34\n",
      "           8       0.13      0.36      0.19        42\n",
      "           9       0.09      0.25      0.13        12\n",
      "          10       0.08      0.29      0.13        35\n",
      "          11       0.00      0.00      0.00        18\n",
      "          12       0.07      0.16      0.10        45\n",
      "          13       0.10      0.04      0.06        23\n",
      "          14       0.05      0.10      0.06        20\n",
      "          15       0.52      0.10      0.16       125\n",
      "          16       0.05      0.12      0.07        24\n",
      "          17       0.11      0.16      0.13        31\n",
      "\n",
      "    accuracy                           0.12       800\n",
      "   macro avg       0.11      0.11      0.08       800\n",
      "weighted avg       0.29      0.12      0.13       800\n",
      "\n",
      "Training Loss for 200 steps: 2.8015907463149645\n",
      "Train Accuracy for 200 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.09      0.15       247\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.16      0.27      0.21        55\n",
      "           3       0.09      0.06      0.07        18\n",
      "           4       0.00      0.00      0.00        14\n",
      "           5       0.06      0.09      0.07        35\n",
      "           6       0.00      0.00      0.00        11\n",
      "           7       0.03      0.04      0.03        26\n",
      "           8       0.15      0.43      0.23        42\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.12      0.41      0.19        34\n",
      "          11       0.06      0.04      0.05        26\n",
      "          12       0.15      0.31      0.20        45\n",
      "          13       0.09      0.05      0.06        20\n",
      "          14       0.00      0.00      0.00        14\n",
      "          15       0.61      0.11      0.18       132\n",
      "          16       0.05      0.08      0.06        26\n",
      "          17       0.10      0.28      0.14        29\n",
      "\n",
      "    accuracy                           0.14       800\n",
      "   macro avg       0.12      0.12      0.09       800\n",
      "weighted avg       0.31      0.14      0.14       800\n",
      "\n",
      "Training Loss for 300 steps: 2.6601061527911214\n",
      "Train Accuracy for 300 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.19      0.30       270\n",
      "           1       0.14      0.25      0.18         8\n",
      "           2       0.10      0.20      0.13        56\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.08      0.22      0.11        27\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.25      0.11      0.15        28\n",
      "           8       0.40      0.67      0.50        45\n",
      "           9       0.21      0.50      0.29        16\n",
      "          10       0.17      0.41      0.24        29\n",
      "          11       0.11      0.32      0.16        19\n",
      "          12       0.38      0.57      0.46        51\n",
      "          13       0.00      0.00      0.00        14\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.72      0.59      0.65       150\n",
      "          16       0.14      0.09      0.11        23\n",
      "          17       0.23      0.37      0.29        19\n",
      "\n",
      "    accuracy                           0.32       800\n",
      "   macro avg       0.20      0.25      0.20       800\n",
      "weighted avg       0.47      0.32      0.33       800\n",
      "\n",
      "Training Loss for 400 steps: 2.4873092501538054\n",
      "Train Accuracy for 400 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.42      0.54       263\n",
      "           1       0.55      0.60      0.57        10\n",
      "           2       0.22      0.45      0.29        56\n",
      "           3       0.17      0.08      0.11        12\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.05      0.07      0.06        27\n",
      "           6       0.05      0.08      0.06        13\n",
      "           7       0.63      0.37      0.47        46\n",
      "           8       0.80      0.84      0.82        44\n",
      "           9       0.73      0.65      0.69        17\n",
      "          10       0.47      0.69      0.56        29\n",
      "          11       0.21      0.40      0.27        20\n",
      "          12       0.62      0.83      0.71        36\n",
      "          13       0.06      0.09      0.07        23\n",
      "          14       0.09      0.21      0.13        14\n",
      "          15       0.96      0.97      0.97       142\n",
      "          16       0.08      0.04      0.05        25\n",
      "          17       0.65      0.71      0.68        21\n",
      "\n",
      "    accuracy                           0.53       800\n",
      "   macro avg       0.39      0.42      0.39       800\n",
      "weighted avg       0.62      0.53      0.55       800\n",
      "\n",
      "Training Loss for 500 steps: 2.3204254189175284\n",
      "Train Accuracy for 500 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.47      0.61       245\n",
      "           1       0.71      1.00      0.83         5\n",
      "           2       0.21      0.33      0.26        57\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.06      0.11      0.08        28\n",
      "           6       0.67      0.31      0.42        13\n",
      "           7       0.52      0.56      0.54        39\n",
      "           8       0.89      0.95      0.92        42\n",
      "           9       0.48      0.76      0.59        17\n",
      "          10       0.62      0.62      0.62        26\n",
      "          11       0.34      0.48      0.40        23\n",
      "          12       0.79      0.88      0.84        52\n",
      "          13       0.11      0.37      0.17        30\n",
      "          14       0.29      0.18      0.22        11\n",
      "          15       0.99      0.99      0.99       147\n",
      "          16       0.20      0.04      0.06        28\n",
      "          17       0.52      0.67      0.58        21\n",
      "\n",
      "    accuracy                           0.58       800\n",
      "   macro avg       0.46      0.48      0.45       800\n",
      "weighted avg       0.67      0.58      0.60       800\n",
      "\n",
      "Training Loss for 600 steps: 2.1915109061857625\n",
      "Train Accuracy for 600 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.54      0.66       277\n",
      "           1       0.70      0.70      0.70        10\n",
      "           2       0.15      0.21      0.18        43\n",
      "           3       0.29      0.12      0.17        17\n",
      "           4       0.20      0.22      0.21         9\n",
      "           5       0.10      0.14      0.11        29\n",
      "           6       0.45      0.56      0.50        16\n",
      "           7       0.72      0.50      0.59        26\n",
      "           8       0.94      0.92      0.93        37\n",
      "           9       0.50      0.78      0.61         9\n",
      "          10       0.72      0.93      0.81        28\n",
      "          11       0.52      0.68      0.59        25\n",
      "          12       0.89      0.81      0.85        48\n",
      "          13       0.09      0.43      0.15        21\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       0.99      0.99      0.99       142\n",
      "          16       0.60      0.29      0.39        31\n",
      "          17       0.53      0.90      0.67        20\n",
      "\n",
      "    accuracy                           0.62       800\n",
      "   macro avg       0.51      0.54      0.51       800\n",
      "weighted avg       0.72      0.62      0.65       800\n",
      "\n",
      "Training Loss for 700 steps: 2.0558968419780403\n",
      "Train Accuracy for 700 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.52      0.67       277\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.15      0.27      0.19        44\n",
      "           3       0.73      0.57      0.64        14\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.13      0.36      0.19        25\n",
      "           6       0.50      0.40      0.44        10\n",
      "           7       0.84      0.68      0.75        38\n",
      "           8       0.89      0.98      0.93        48\n",
      "           9       0.87      0.93      0.90        14\n",
      "          10       0.87      0.93      0.90        29\n",
      "          11       0.63      0.81      0.71        21\n",
      "          12       0.91      0.87      0.89        47\n",
      "          13       0.10      0.29      0.15        28\n",
      "          14       0.00      0.00      0.00        15\n",
      "          15       0.99      1.00      1.00       138\n",
      "          16       0.67      0.43      0.52        28\n",
      "          17       0.68      0.85      0.76        20\n",
      "\n",
      "    accuracy                           0.65       800\n",
      "   macro avg       0.55      0.55      0.54       800\n",
      "weighted avg       0.78      0.65      0.69       800\n",
      "\n",
      "Training Loss for 800 steps: 1.9474705627720603\n",
      "Train Accuracy for 800 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.51      0.67       239\n",
      "           1       0.83      0.83      0.83         6\n",
      "           2       0.26      0.27      0.26        44\n",
      "           3       0.67      0.17      0.27        12\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.12      0.26      0.16        31\n",
      "           6       0.27      0.31      0.29        13\n",
      "           7       0.79      0.63      0.70        41\n",
      "           8       0.96      0.94      0.95        48\n",
      "           9       0.83      0.91      0.87        11\n",
      "          10       0.90      1.00      0.95        26\n",
      "          11       0.58      0.79      0.67        14\n",
      "          12       0.98      0.91      0.94        54\n",
      "          13       0.07      0.29      0.11        24\n",
      "          14       0.30      0.25      0.27        12\n",
      "          15       1.00      1.00      1.00       149\n",
      "          16       0.51      0.58      0.54        33\n",
      "          17       0.82      0.94      0.88        34\n",
      "\n",
      "    accuracy                           0.66       800\n",
      "   macro avg       0.60      0.59      0.58       800\n",
      "weighted avg       0.79      0.66      0.70       800\n",
      "\n",
      "Training Loss for 900 steps: 1.8540197548835842\n",
      "Train Accuracy for 900 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.53      0.65       253\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.43      0.51      0.47        53\n",
      "           3       0.50      0.48      0.49        21\n",
      "           4       1.00      0.25      0.40         8\n",
      "           5       0.26      0.41      0.31        27\n",
      "           6       0.45      0.50      0.48        10\n",
      "           7       0.86      0.82      0.84        38\n",
      "           8       0.97      0.97      0.97        33\n",
      "           9       1.00      0.86      0.92        14\n",
      "          10       0.84      0.94      0.89        34\n",
      "          11       0.82      0.75      0.78        24\n",
      "          12       0.95      0.93      0.94        41\n",
      "          13       0.08      0.33      0.13        12\n",
      "          14       0.00      0.00      0.00        11\n",
      "          15       1.00      0.99      1.00       151\n",
      "          16       0.29      0.56      0.38        34\n",
      "          17       0.84      0.96      0.90        27\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.67      0.65      0.64       800\n",
      "weighted avg       0.78      0.70      0.72       800\n",
      "\n",
      "Training Loss for 1000 steps: 1.7659926005712636\n",
      "Train Accuracy for 1000 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.61      0.73       252\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.41      0.54      0.47        46\n",
      "           3       0.38      0.64      0.47        14\n",
      "           4       1.00      0.17      0.29         6\n",
      "           5       0.17      0.46      0.25        28\n",
      "           6       0.67      0.46      0.55        13\n",
      "           7       0.86      0.79      0.83        39\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      0.93      0.96        14\n",
      "          10       0.94      0.97      0.96        33\n",
      "          11       0.73      0.73      0.73        15\n",
      "          12       0.98      0.83      0.90        52\n",
      "          13       0.25      0.17      0.20        12\n",
      "          14       0.10      0.31      0.15        13\n",
      "          15       1.00      1.00      1.00       165\n",
      "          16       0.42      0.44      0.43        32\n",
      "          17       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.69      0.67      0.65       800\n",
      "weighted avg       0.82      0.73      0.76       800\n",
      "\n",
      "Training Loss for 1100 steps: 1.697782183741029\n",
      "Train Accuracy for 1100 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.49      0.63       248\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.20      0.37      0.26        51\n",
      "           3       0.67      0.42      0.52        19\n",
      "           4       0.71      0.45      0.56        11\n",
      "           5       0.14      0.32      0.19        31\n",
      "           6       0.40      0.22      0.29         9\n",
      "           7       0.82      0.85      0.84        33\n",
      "           8       0.97      0.97      0.97        33\n",
      "           9       0.84      0.84      0.84        19\n",
      "          10       0.88      0.95      0.91        38\n",
      "          11       0.71      0.85      0.77        26\n",
      "          12       0.95      0.89      0.92        45\n",
      "          13       0.09      0.21      0.13        19\n",
      "          14       0.09      0.09      0.09        11\n",
      "          15       0.99      0.99      0.99       155\n",
      "          16       0.38      0.47      0.42        17\n",
      "          17       0.88      1.00      0.93        28\n",
      "\n",
      "    accuracy                           0.68       800\n",
      "   macro avg       0.64      0.63      0.63       800\n",
      "weighted avg       0.77      0.68      0.70       800\n",
      "\n",
      "Training Loss for 1200 steps: 1.6390915154809014\n",
      "Train Accuracy for 1200 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.51      0.65       272\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.31      0.45      0.37        44\n",
      "           3       0.44      0.50      0.47         8\n",
      "           4       0.57      0.50      0.53         8\n",
      "           5       0.09      0.37      0.15        27\n",
      "           6       0.79      0.69      0.73        16\n",
      "           7       0.95      0.80      0.87        46\n",
      "           8       1.00      0.94      0.97        32\n",
      "           9       1.00      0.93      0.96        14\n",
      "          10       0.88      0.91      0.90        33\n",
      "          11       0.66      0.76      0.70        25\n",
      "          12       0.94      0.93      0.94        55\n",
      "          13       0.13      0.35      0.19        17\n",
      "          14       0.80      0.33      0.47        12\n",
      "          15       0.99      0.99      0.99       134\n",
      "          16       0.60      0.50      0.55        30\n",
      "          17       0.82      0.96      0.88        24\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.71      0.69      0.68       800\n",
      "weighted avg       0.81      0.69      0.73       800\n",
      "\n",
      "Training Loss for 1300 steps: 1.5815120678334902\n",
      "Train Accuracy for 1300 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.60      0.73       252\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.32      0.46      0.38        54\n",
      "           3       0.88      0.64      0.74        11\n",
      "           4       0.42      0.56      0.48         9\n",
      "           5       0.16      0.43      0.24        23\n",
      "           6       0.67      0.44      0.53         9\n",
      "           7       0.88      0.85      0.86        33\n",
      "           8       0.98      1.00      0.99        50\n",
      "           9       0.96      0.92      0.94        24\n",
      "          10       1.00      0.96      0.98        27\n",
      "          11       0.57      1.00      0.72        13\n",
      "          12       0.96      0.96      0.96        52\n",
      "          13       0.11      0.23      0.15        22\n",
      "          14       0.33      0.20      0.25        15\n",
      "          15       1.00      0.99      1.00       147\n",
      "          16       0.44      0.53      0.48        32\n",
      "          17       1.00      0.91      0.95        23\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.70      0.69      0.68       800\n",
      "weighted avg       0.82      0.73      0.76       800\n",
      "\n",
      "Training Loss for 1400 steps: 1.5378899804790431\n",
      "Train Accuracy for 1400 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.53      0.69       244\n",
      "           1       0.80      1.00      0.89         4\n",
      "           2       0.42      0.43      0.42        47\n",
      "           3       1.00      0.42      0.59        12\n",
      "           4       0.60      0.75      0.67         8\n",
      "           5       0.19      0.37      0.25        30\n",
      "           6       1.00      0.43      0.60        14\n",
      "           7       0.93      0.74      0.82        38\n",
      "           8       0.96      1.00      0.98        46\n",
      "           9       0.91      0.95      0.93        21\n",
      "          10       0.97      0.94      0.96        35\n",
      "          11       0.73      0.92      0.81        24\n",
      "          12       0.95      0.87      0.91        46\n",
      "          13       0.12      0.44      0.19        25\n",
      "          14       0.16      0.40      0.22        25\n",
      "          15       1.00      1.00      1.00       130\n",
      "          16       0.60      0.46      0.52        26\n",
      "          17       0.82      0.92      0.87        25\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.73      0.70      0.68       800\n",
      "weighted avg       0.83      0.69      0.73       800\n",
      "\n",
      "Training Loss for 1500 steps: 1.4977117641658326\n",
      "Train Accuracy for 1500 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.52      0.68       272\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.48      0.41      0.44        56\n",
      "           3       0.75      0.17      0.27        18\n",
      "           4       0.40      0.40      0.40         5\n",
      "           5       0.15      0.51      0.23        37\n",
      "           6       0.80      0.67      0.73         6\n",
      "           7       0.88      0.90      0.89        42\n",
      "           8       0.96      0.98      0.97        48\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       0.93      0.96      0.95        27\n",
      "          11       0.85      0.79      0.81        14\n",
      "          12       0.95      0.92      0.94        39\n",
      "          13       0.14      0.26      0.18        23\n",
      "          14       0.15      0.57      0.23        14\n",
      "          15       1.00      0.99      0.99       138\n",
      "          16       0.73      0.65      0.69        17\n",
      "          17       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.72      0.69      0.68       800\n",
      "weighted avg       0.84      0.69      0.73       800\n",
      "\n",
      "Training Loss for 1600 steps: 1.4607207356678145\n",
      "Train Accuracy for 1600 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.54      0.67       231\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.32      0.52      0.40        50\n",
      "           3       0.32      0.60      0.41        10\n",
      "           4       0.57      0.33      0.42        12\n",
      "           5       0.12      0.21      0.15        29\n",
      "           6       0.83      0.56      0.67         9\n",
      "           7       0.91      0.91      0.91        47\n",
      "           8       0.98      0.96      0.97        45\n",
      "           9       1.00      0.96      0.98        25\n",
      "          10       0.92      0.89      0.91        27\n",
      "          11       0.75      0.83      0.79        18\n",
      "          12       0.98      0.92      0.95        48\n",
      "          13       0.13      0.43      0.20        21\n",
      "          14       0.12      0.13      0.13        15\n",
      "          15       0.98      0.99      0.99       149\n",
      "          16       0.75      0.47      0.58        32\n",
      "          17       0.85      0.92      0.88        25\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.69      0.68      0.67       800\n",
      "weighted avg       0.80      0.71      0.74       800\n",
      "\n",
      "Training Loss for 1700 steps: 1.425032040275642\n",
      "Train Accuracy for 1700 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.55      0.70       254\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       0.31      0.50      0.39        54\n",
      "           3       0.58      0.70      0.64        10\n",
      "           4       1.00      0.50      0.67         4\n",
      "           5       0.17      0.45      0.25        31\n",
      "           6       0.88      0.78      0.82         9\n",
      "           7       0.93      0.88      0.90        43\n",
      "           8       0.97      1.00      0.99        34\n",
      "           9       1.00      0.92      0.96        12\n",
      "          10       0.90      0.96      0.93        28\n",
      "          11       0.84      0.84      0.84        19\n",
      "          12       0.95      0.91      0.93        46\n",
      "          13       0.08      0.17      0.11        18\n",
      "          14       0.14      0.30      0.19        20\n",
      "          15       1.00      0.99      1.00       150\n",
      "          16       0.71      0.44      0.55        34\n",
      "          17       0.84      0.91      0.87        23\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.74      0.71      0.71       800\n",
      "weighted avg       0.83      0.71      0.75       800\n",
      "\n",
      "Training Loss for 1800 steps: 1.4021161464386842\n",
      "Train Accuracy for 1800 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.57      0.67       273\n",
      "           1       0.75      0.75      0.75         4\n",
      "           2       0.49      0.49      0.49        49\n",
      "           3       0.20      0.10      0.13        10\n",
      "           4       0.50      0.17      0.25         6\n",
      "           5       0.11      0.32      0.17        31\n",
      "           6       0.88      0.78      0.82         9\n",
      "           7       0.95      0.80      0.86        44\n",
      "           8       1.00      0.98      0.99        43\n",
      "           9       0.80      1.00      0.89        12\n",
      "          10       0.88      0.83      0.86        36\n",
      "          11       0.48      0.92      0.63        12\n",
      "          12       0.95      0.89      0.92        44\n",
      "          13       0.16      0.38      0.22        21\n",
      "          14       0.06      0.11      0.07         9\n",
      "          15       0.99      0.99      0.99       134\n",
      "          16       0.48      0.45      0.47        33\n",
      "          17       0.91      0.97      0.94        30\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.63      0.64      0.62       800\n",
      "weighted avg       0.78      0.69      0.72       800\n",
      "\n",
      "Training Loss for 1900 steps: 1.3725002853372288\n",
      "Train Accuracy for 1900 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.74       261\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.33      0.63      0.44        54\n",
      "           3       0.86      0.60      0.71        10\n",
      "           4       0.50      0.20      0.29         5\n",
      "           5       0.22      0.30      0.26        20\n",
      "           6       0.88      0.54      0.67        13\n",
      "           7       0.91      0.79      0.85        39\n",
      "           8       1.00      0.98      0.99        48\n",
      "           9       0.89      0.89      0.89        19\n",
      "          10       0.85      1.00      0.92        22\n",
      "          11       0.95      0.77      0.85        26\n",
      "          12       0.98      0.93      0.95        44\n",
      "          13       0.13      0.45      0.21        22\n",
      "          14       0.17      0.14      0.15         7\n",
      "          15       1.00      0.99      0.99       156\n",
      "          16       0.59      0.67      0.63        24\n",
      "          17       0.88      1.00      0.93        21\n",
      "\n",
      "    accuracy                           0.75       800\n",
      "   macro avg       0.73      0.69      0.69       800\n",
      "weighted avg       0.85      0.75      0.78       800\n",
      "\n",
      "The Total Accuracy for Epoch 0:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.47      0.61      4961\n",
      "           1       0.67      0.73      0.70       129\n",
      "           2       0.27      0.39      0.32       979\n",
      "           3       0.48      0.32      0.38       250\n",
      "           4       0.26      0.27      0.26       131\n",
      "           5       0.13      0.28      0.18       552\n",
      "           6       0.45      0.39      0.42       220\n",
      "           7       0.75      0.66      0.70       733\n",
      "           8       0.72      0.89      0.79       809\n",
      "           9       0.68      0.80      0.74       303\n",
      "          10       0.57      0.81      0.67       582\n",
      "          11       0.53      0.65      0.58       387\n",
      "          12       0.72      0.81      0.76       898\n",
      "          13       0.11      0.28      0.15       403\n",
      "          14       0.12      0.19      0.15       267\n",
      "          15       0.97      0.89      0.93      2767\n",
      "          16       0.39      0.39      0.39       534\n",
      "          17       0.62      0.80      0.70       467\n",
      "\n",
      "    accuracy                           0.60     15372\n",
      "   macro avg       0.52      0.56      0.52     15372\n",
      "weighted avg       0.70      0.60      0.63     15372\n",
      "\n",
      "Training Loss Epoch: 1.367331158640648\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c6928e977afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-8ef55497a65f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \"\"\"\n\u001b[0;32m-> 1188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZuT79sjuPxdw",
    "outputId": "bb28e097-4bf5-4e0e-929b-ddf6c28e03f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for 0 steps: 0.06789011508226395\n",
      "Train Accuracy for 0 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "          13       0.00      0.00      0.00         0\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.86      0.79      0.81         8\n",
      "weighted avg       1.00      0.88      0.92         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for 100 steps: 0.8487175714482765\n",
      "Train Accuracy for 100 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.56      0.71       260\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.39      0.47      0.43        57\n",
      "           3       0.75      0.21      0.33        14\n",
      "           4       0.80      0.67      0.73         6\n",
      "           5       0.20      0.53      0.29        38\n",
      "           6       1.00      0.73      0.84        11\n",
      "           7       1.00      0.86      0.93        37\n",
      "           8       0.97      0.94      0.96        34\n",
      "           9       0.89      0.94      0.92        18\n",
      "          10       0.96      0.90      0.93        29\n",
      "          11       0.74      0.88      0.80        16\n",
      "          12       0.93      0.91      0.92        47\n",
      "          13       0.08      0.42      0.14        19\n",
      "          14       0.50      0.14      0.22        14\n",
      "          15       1.00      0.99      1.00       146\n",
      "          16       0.94      0.60      0.73        25\n",
      "          17       0.88      1.00      0.94        22\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.78      0.71      0.71       800\n",
      "weighted avg       0.86      0.71      0.75       800\n",
      "\n",
      "Training Loss for 200 steps: 0.845267298422865\n",
      "Train Accuracy for 200 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.53      0.68       260\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       0.44      0.41      0.42        44\n",
      "           3       0.45      0.56      0.50        16\n",
      "           4       0.67      0.40      0.50        10\n",
      "           5       0.09      0.24      0.13        29\n",
      "           6       1.00      0.57      0.73        14\n",
      "           7       0.93      0.74      0.82        34\n",
      "           8       0.97      1.00      0.98        32\n",
      "           9       0.94      1.00      0.97        15\n",
      "          10       0.94      1.00      0.97        29\n",
      "          11       0.68      0.88      0.76        24\n",
      "          12       1.00      0.98      0.99        46\n",
      "          13       0.09      0.35      0.15        23\n",
      "          14       0.28      0.41      0.33        17\n",
      "          15       0.99      1.00      0.99       137\n",
      "          16       0.93      0.59      0.72        22\n",
      "          17       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.73      0.70      0.70       800\n",
      "weighted avg       0.83      0.71      0.75       800\n",
      "\n",
      "Training Loss for 300 steps: 0.8520846188260224\n",
      "Train Accuracy for 300 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.56      0.70       266\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.21      0.58      0.31        45\n",
      "           3       0.60      0.33      0.43         9\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       0.16      0.36      0.22        25\n",
      "           6       0.62      0.42      0.50        12\n",
      "           7       0.95      0.83      0.88        46\n",
      "           8       0.97      0.97      0.97        39\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       0.89      1.00      0.94        25\n",
      "          11       0.85      0.88      0.86        32\n",
      "          12       0.96      0.98      0.97        47\n",
      "          13       0.15      0.35      0.21        20\n",
      "          14       0.17      0.08      0.11        12\n",
      "          15       1.00      0.99      1.00       149\n",
      "          16       0.75      0.48      0.59        31\n",
      "          17       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.72      0.68      0.68       800\n",
      "weighted avg       0.84      0.72      0.75       800\n",
      "\n",
      "Training Loss for 400 steps: 0.8736520260990484\n",
      "Train Accuracy for 400 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.68       230\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.37      0.51      0.43        65\n",
      "           3       0.67      0.33      0.44        12\n",
      "           4       1.00      0.33      0.50         3\n",
      "           5       0.08      0.23      0.12        26\n",
      "           6       1.00      0.40      0.57        10\n",
      "           7       0.97      0.94      0.96        35\n",
      "           8       1.00      0.96      0.98        53\n",
      "           9       0.94      0.94      0.94        16\n",
      "          10       0.88      0.88      0.88        33\n",
      "          11       0.74      0.77      0.76        22\n",
      "          12       0.97      0.97      0.97        36\n",
      "          13       0.09      0.26      0.13        23\n",
      "          14       0.58      0.41      0.48        17\n",
      "          15       1.00      1.00      1.00       143\n",
      "          16       0.52      0.41      0.46        41\n",
      "          17       0.93      0.97      0.95        29\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.76      0.66      0.68       800\n",
      "weighted avg       0.81      0.70      0.73       800\n",
      "\n",
      "Training Loss for 500 steps: 0.8461843718609172\n",
      "Train Accuracy for 500 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.51      0.67       272\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       0.30      0.45      0.36        47\n",
      "           3       1.00      0.56      0.71         9\n",
      "           4       0.50      0.33      0.40         6\n",
      "           5       0.13      0.45      0.20        29\n",
      "           6       0.71      0.71      0.71         7\n",
      "           7       1.00      0.88      0.93        32\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       1.00      1.00      1.00        19\n",
      "          10       0.97      0.94      0.96        34\n",
      "          11       0.76      0.84      0.80        19\n",
      "          12       1.00      0.96      0.98        51\n",
      "          13       0.12      0.43      0.19        21\n",
      "          14       0.50      0.35      0.41        17\n",
      "          15       1.00      1.00      1.00       147\n",
      "          16       0.79      0.66      0.72        29\n",
      "          17       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.74      0.72      0.71       800\n",
      "weighted avg       0.85      0.71      0.75       800\n",
      "\n",
      "Training Loss for 600 steps: 0.8487763240198898\n",
      "Train Accuracy for 600 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.55      0.70       260\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.33      0.48      0.39        52\n",
      "           3       1.00      0.55      0.71        11\n",
      "           4       0.50      0.50      0.50         6\n",
      "           5       0.08      0.12      0.10        26\n",
      "           6       1.00      0.38      0.55         8\n",
      "           7       1.00      0.88      0.94        42\n",
      "           8       0.98      1.00      0.99        42\n",
      "           9       1.00      1.00      1.00        17\n",
      "          10       0.96      1.00      0.98        27\n",
      "          11       0.73      0.92      0.81        12\n",
      "          12       0.98      0.98      0.98        50\n",
      "          13       0.13      0.58      0.21        31\n",
      "          14       0.40      0.20      0.27        10\n",
      "          15       0.99      0.99      0.99       150\n",
      "          16       1.00      0.45      0.62        29\n",
      "          17       1.00      0.95      0.98        21\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.78      0.70      0.71       800\n",
      "weighted avg       0.86      0.72      0.76       800\n",
      "\n",
      "Training Loss for 700 steps: 0.8461720822943632\n",
      "Train Accuracy for 700 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.52      0.67       269\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.31      0.44      0.36        50\n",
      "           3       1.00      0.40      0.57        10\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.16      0.42      0.23        26\n",
      "           6       0.90      0.69      0.78        13\n",
      "           7       1.00      0.90      0.95        31\n",
      "           8       0.95      0.98      0.97        43\n",
      "           9       1.00      1.00      1.00        12\n",
      "          10       0.94      1.00      0.97        33\n",
      "          11       0.67      0.80      0.73        10\n",
      "          12       1.00      0.97      0.98        58\n",
      "          13       0.06      0.35      0.11        17\n",
      "          14       0.30      0.30      0.30        10\n",
      "          15       1.00      1.00      1.00       156\n",
      "          16       0.84      0.55      0.67        29\n",
      "          17       0.92      1.00      0.96        23\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.72      0.68      0.68       800\n",
      "weighted avg       0.86      0.72      0.76       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for 800 steps: 0.8485786213269795\n",
      "Train Accuracy for 800 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.61      0.72       260\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.25      0.42      0.31        48\n",
      "           3       0.75      0.46      0.57        13\n",
      "           4       0.67      0.67      0.67         6\n",
      "           5       0.15      0.26      0.19        23\n",
      "           6       0.75      0.55      0.63        11\n",
      "           7       0.95      0.90      0.92        41\n",
      "           8       0.98      0.96      0.97        48\n",
      "           9       1.00      0.95      0.97        20\n",
      "          10       0.96      0.93      0.95        28\n",
      "          11       0.96      0.92      0.94        24\n",
      "          12       0.97      0.95      0.96        40\n",
      "          13       0.07      0.21      0.10        28\n",
      "          14       0.40      0.31      0.35        13\n",
      "          15       1.00      0.99      1.00       138\n",
      "          16       0.76      0.43      0.55        30\n",
      "          17       0.93      1.00      0.96        26\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.75      0.70      0.71       800\n",
      "weighted avg       0.82      0.72      0.76       800\n",
      "\n",
      "Training Loss for 900 steps: 0.8418436857549211\n",
      "Train Accuracy for 900 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.50      0.66       272\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.38      0.37      0.37        41\n",
      "           3       0.67      0.40      0.50        15\n",
      "           4       1.00      0.60      0.75        10\n",
      "           5       0.25      0.31      0.28        26\n",
      "           6       0.67      0.46      0.55        13\n",
      "           7       0.97      0.76      0.85        37\n",
      "           8       1.00      1.00      1.00        45\n",
      "           9       0.83      0.94      0.88        16\n",
      "          10       0.97      1.00      0.98        29\n",
      "          11       0.87      0.95      0.91        21\n",
      "          12       0.97      0.98      0.98        61\n",
      "          13       0.06      0.53      0.10        17\n",
      "          14       0.17      0.20      0.18        10\n",
      "          15       0.99      1.00      1.00       128\n",
      "          16       0.48      0.56      0.52        27\n",
      "          17       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.73      0.69      0.69       800\n",
      "weighted avg       0.86      0.70      0.75       800\n",
      "\n",
      "Training Loss for 1000 steps: 0.845265968234281\n",
      "Train Accuracy for 1000 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.53      0.68       255\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       0.50      0.35      0.41        46\n",
      "           3       0.62      0.50      0.55        16\n",
      "           4       0.75      0.43      0.55         7\n",
      "           5       0.23      0.37      0.28        38\n",
      "           6       0.50      0.53      0.51        17\n",
      "           7       0.97      0.92      0.95        39\n",
      "           8       1.00      0.97      0.99        36\n",
      "           9       1.00      1.00      1.00        17\n",
      "          10       0.97      0.94      0.96        34\n",
      "          11       0.71      0.83      0.77        18\n",
      "          12       0.97      0.95      0.96        40\n",
      "          13       0.08      0.48      0.13        23\n",
      "          14       0.33      0.09      0.14        11\n",
      "          15       1.00      0.99      1.00       144\n",
      "          16       0.79      0.56      0.65        27\n",
      "          17       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.73      0.69      0.69       800\n",
      "weighted avg       0.83      0.70      0.74       800\n",
      "\n",
      "Training Loss for 1100 steps: 0.8392262508399906\n",
      "Train Accuracy for 1100 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.53      0.69       272\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.80      0.42      0.55        48\n",
      "           3       0.67      0.50      0.57         4\n",
      "           4       0.25      0.50      0.33         2\n",
      "           5       0.16      0.79      0.27        38\n",
      "           6       0.88      0.50      0.64        14\n",
      "           7       0.96      0.84      0.90        31\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.94      1.00      0.97        16\n",
      "          10       0.96      0.96      0.96        25\n",
      "          11       0.85      0.92      0.88        24\n",
      "          12       0.98      0.96      0.97        49\n",
      "          13       0.13      0.24      0.17        21\n",
      "          14       0.14      0.10      0.12        10\n",
      "          15       0.99      0.99      0.99       137\n",
      "          16       0.70      0.50      0.58        28\n",
      "          17       0.93      0.97      0.95        29\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.74      0.70      0.70       800\n",
      "weighted avg       0.88      0.72      0.76       800\n",
      "\n",
      "Training Loss for 1200 steps: 0.8359373815905933\n",
      "Train Accuracy for 1200 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.53      0.68       220\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.64      0.42      0.51        55\n",
      "           3       0.80      0.44      0.57        18\n",
      "           4       0.67      0.50      0.57         8\n",
      "           5       0.16      0.77      0.26        35\n",
      "           6       0.75      0.67      0.71         9\n",
      "           7       0.97      0.87      0.92        45\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       0.93      0.93      0.93        14\n",
      "          10       0.89      0.94      0.91        34\n",
      "          11       0.85      0.85      0.85        26\n",
      "          12       0.98      0.96      0.97        45\n",
      "          13       0.19      0.25      0.21        20\n",
      "          14       0.62      0.36      0.45        14\n",
      "          15       1.00      1.00      1.00       169\n",
      "          16       0.71      0.48      0.57        21\n",
      "          17       0.95      0.95      0.95        22\n",
      "\n",
      "    accuracy                           0.74       800\n",
      "   macro avg       0.78      0.72      0.73       800\n",
      "weighted avg       0.86      0.74      0.77       800\n",
      "\n",
      "Training Loss for 1300 steps: 0.8406871882378969\n",
      "Train Accuracy for 1300 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.48      0.64       251\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.36      0.45      0.40        65\n",
      "           3       0.70      0.54      0.61        13\n",
      "           4       0.67      0.57      0.62         7\n",
      "           5       0.18      0.43      0.26        21\n",
      "           6       0.57      0.31      0.40        13\n",
      "           7       0.92      0.92      0.92        36\n",
      "           8       0.98      1.00      0.99        41\n",
      "           9       0.95      1.00      0.98        20\n",
      "          10       0.93      0.96      0.95        28\n",
      "          11       0.84      0.76      0.80        21\n",
      "          12       1.00      0.96      0.98        52\n",
      "          13       0.07      0.43      0.12        23\n",
      "          14       0.67      0.27      0.38        15\n",
      "          15       1.00      1.00      1.00       143\n",
      "          16       0.87      0.50      0.63        26\n",
      "          17       0.86      0.95      0.90        19\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.75      0.70      0.70       800\n",
      "weighted avg       0.85      0.69      0.74       800\n",
      "\n",
      "Training Loss for 1400 steps: 0.8383072906175095\n",
      "Train Accuracy for 1400 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.52      0.67       247\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.28      0.47      0.35        45\n",
      "           3       0.69      0.56      0.62        16\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       0.24      0.38      0.29        42\n",
      "           6       0.33      0.42      0.37        12\n",
      "           7       1.00      0.91      0.95        45\n",
      "           8       1.00      1.00      1.00        48\n",
      "           9       0.93      0.93      0.93        15\n",
      "          10       0.94      0.97      0.95        31\n",
      "          11       0.68      0.81      0.74        21\n",
      "          12       1.00      1.00      1.00        44\n",
      "          13       0.09      0.35      0.14        17\n",
      "          14       0.13      0.21      0.16        14\n",
      "          15       1.00      1.00      1.00       134\n",
      "          16       0.91      0.66      0.76        32\n",
      "          17       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.71      0.70      0.69       800\n",
      "weighted avg       0.83      0.71      0.75       800\n",
      "\n",
      "Training Loss for 1500 steps: 0.8363183193770594\n",
      "Train Accuracy for 1500 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65       253\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.28      0.50      0.36        48\n",
      "           3       0.70      0.37      0.48        19\n",
      "           4       0.89      0.73      0.80        11\n",
      "           5       0.09      0.42      0.15        24\n",
      "           6       0.86      0.55      0.67        11\n",
      "           7       0.98      0.90      0.93        48\n",
      "           8       1.00      0.98      0.99        43\n",
      "           9       0.87      0.93      0.90        14\n",
      "          10       1.00      0.97      0.98        32\n",
      "          11       0.93      1.00      0.97        14\n",
      "          12       0.97      1.00      0.99        34\n",
      "          13       0.14      0.25      0.18        20\n",
      "          14       0.31      0.44      0.37        25\n",
      "          15       1.00      1.00      1.00       150\n",
      "          16       0.85      0.50      0.63        22\n",
      "          17       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.77      0.72      0.72       800\n",
      "weighted avg       0.86      0.71      0.75       800\n",
      "\n",
      "Training Loss for 1600 steps: 0.8369902672876094\n",
      "Train Accuracy for 1600 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.57      0.70       252\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       0.26      0.46      0.33        59\n",
      "           3       1.00      0.40      0.57        10\n",
      "           4       0.67      0.36      0.47        11\n",
      "           5       0.20      0.24      0.22        21\n",
      "           6       0.75      0.60      0.67        10\n",
      "           7       0.97      0.93      0.95        30\n",
      "           8       1.00      0.98      0.99        43\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       0.96      0.96      0.96        25\n",
      "          11       0.95      0.86      0.90        22\n",
      "          12       0.98      0.96      0.97        50\n",
      "          13       0.14      0.50      0.22        24\n",
      "          14       0.16      0.33      0.22        12\n",
      "          15       1.00      1.00      1.00       142\n",
      "          16       0.64      0.42      0.51        33\n",
      "          17       0.94      1.00      0.97        32\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.75      0.70      0.70       800\n",
      "weighted avg       0.83      0.72      0.75       800\n",
      "\n",
      "Training Loss for 1700 steps: 0.8277352056386653\n",
      "Train Accuracy for 1700 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.53      0.69       271\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.28      0.66      0.40        62\n",
      "           3       0.86      0.55      0.67        11\n",
      "           4       1.00      0.83      0.91         6\n",
      "           5       0.15      0.31      0.21        32\n",
      "           6       1.00      0.75      0.86         8\n",
      "           7       0.97      0.84      0.90        38\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       1.00      1.00      1.00        12\n",
      "          10       0.94      1.00      0.97        29\n",
      "          11       0.89      0.94      0.92        18\n",
      "          12       1.00      1.00      1.00        50\n",
      "          13       0.10      0.18      0.13        17\n",
      "          14       0.17      0.31      0.22        16\n",
      "          15       1.00      1.00      1.00       140\n",
      "          16       0.92      0.57      0.71        21\n",
      "          17       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.79      0.74      0.75       800\n",
      "weighted avg       0.85      0.72      0.76       800\n",
      "\n",
      "Training Loss for 1800 steps: 0.8170866162661227\n",
      "Train Accuracy for 1800 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.55      0.68       283\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       0.18      0.43      0.25        44\n",
      "           3       0.86      0.67      0.75        18\n",
      "           4       0.62      0.50      0.56        10\n",
      "           5       0.17      0.44      0.25        18\n",
      "           6       0.90      0.64      0.75        14\n",
      "           7       0.97      0.90      0.93        31\n",
      "           8       0.98      0.98      0.98        46\n",
      "           9       1.00      1.00      1.00        17\n",
      "          10       0.97      1.00      0.98        30\n",
      "          11       0.94      0.94      0.94        18\n",
      "          12       0.98      0.98      0.98        43\n",
      "          13       0.02      0.06      0.03        18\n",
      "          14       1.00      0.29      0.44         7\n",
      "          15       0.99      0.99      0.99       135\n",
      "          16       1.00      0.71      0.83        28\n",
      "          17       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.80      0.73      0.74       800\n",
      "weighted avg       0.86      0.73      0.77       800\n",
      "\n",
      "Training Loss for 1900 steps: 0.8124792707716798\n",
      "Train Accuracy for 1900 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.75       268\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.45      0.54      0.49        46\n",
      "           3       0.75      0.46      0.57        13\n",
      "           4       0.80      0.80      0.80         5\n",
      "           5       0.36      0.37      0.36        27\n",
      "           6       0.88      0.88      0.88         8\n",
      "           7       0.95      0.89      0.92        44\n",
      "           8       0.95      0.95      0.95        38\n",
      "           9       1.00      0.92      0.96        13\n",
      "          10       1.00      1.00      1.00        42\n",
      "          11       0.89      0.84      0.86        19\n",
      "          12       0.98      0.98      0.98        49\n",
      "          13       0.09      0.50      0.15        18\n",
      "          14       0.40      0.20      0.27        20\n",
      "          15       1.00      0.99      1.00       143\n",
      "          16       0.72      0.57      0.63        23\n",
      "          17       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.76       800\n",
      "   macro avg       0.78      0.75      0.75       800\n",
      "weighted avg       0.85      0.76      0.79       800\n",
      "\n",
      "The Total Accuracy for Epoch 0:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.54      0.69      4961\n",
      "           1       0.96      0.99      0.98       129\n",
      "           2       0.32      0.47      0.38       979\n",
      "           3       0.73      0.47      0.57       250\n",
      "           4       0.71      0.52      0.60       131\n",
      "           5       0.16      0.41      0.23       552\n",
      "           6       0.75      0.55      0.64       220\n",
      "           7       0.97      0.87      0.92       733\n",
      "           8       0.99      0.98      0.98       809\n",
      "           9       0.96      0.97      0.97       303\n",
      "          10       0.95      0.97      0.96       582\n",
      "          11       0.82      0.87      0.84       387\n",
      "          12       0.98      0.97      0.98       898\n",
      "          13       0.09      0.36      0.15       403\n",
      "          14       0.29      0.28      0.28       267\n",
      "          15       1.00      1.00      1.00      2767\n",
      "          16       0.77      0.53      0.63       534\n",
      "          17       0.95      0.98      0.96       467\n",
      "\n",
      "    accuracy                           0.72     15372\n",
      "   macro avg       0.74      0.71      0.71     15372\n",
      "weighted avg       0.84      0.72      0.75     15372\n",
      "\n",
      "Training Loss Epoch: 0.8125384975120311\n",
      "Validation Accuracy Epoch:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.64      1230\n",
      "           1       1.00      0.97      0.98        29\n",
      "           2       1.00      0.26      0.42       246\n",
      "           3       0.78      0.45      0.57        62\n",
      "           4       0.95      0.57      0.71        35\n",
      "           5       0.97      0.23      0.38       155\n",
      "           6       0.79      0.51      0.62        45\n",
      "           7       0.99      0.90      0.94       184\n",
      "           8       0.97      1.00      0.99       203\n",
      "           9       0.99      0.99      0.99        85\n",
      "          10       0.94      0.99      0.97       116\n",
      "          11       0.91      0.88      0.89        96\n",
      "          12       0.99      0.97      0.98       199\n",
      "          13       0.10      0.98      0.18       125\n",
      "          14       0.68      0.27      0.39        63\n",
      "          15       1.00      1.00      1.00       752\n",
      "          16       0.90      0.50      0.64       110\n",
      "          17       0.99      0.97      0.98       108\n",
      "\n",
      "    accuracy                           0.70      3843\n",
      "   macro avg       0.89      0.72      0.74      3843\n",
      "weighted avg       0.95      0.70      0.75      3843\n",
      "\n",
      "Training Loss for 0 steps: 1.371132731437683\n",
      "Train Accuracy for 0 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         4\n",
      "           5       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38         8\n",
      "   macro avg       0.42      0.38      0.39         8\n",
      "weighted avg       0.50      0.38      0.42         8\n",
      "\n",
      "Training Loss for 100 steps: 0.7674290375774818\n",
      "Train Accuracy for 100 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.52      0.67       245\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.33      0.40      0.36        52\n",
      "           3       0.86      0.46      0.60        13\n",
      "           4       1.00      0.57      0.73         7\n",
      "           5       0.15      0.50      0.24        24\n",
      "           6       0.85      0.65      0.73        17\n",
      "           7       1.00      0.86      0.93        36\n",
      "           8       0.97      0.97      0.97        37\n",
      "           9       1.00      1.00      1.00        20\n",
      "          10       1.00      1.00      1.00        41\n",
      "          11       0.75      1.00      0.86         9\n",
      "          12       0.98      0.98      0.98        46\n",
      "          13       0.13      0.39      0.19        28\n",
      "          14       0.21      0.27      0.24        15\n",
      "          15       1.00      1.00      1.00       151\n",
      "          16       0.39      0.35      0.37        26\n",
      "          17       0.96      1.00      0.98        24\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.75      0.72      0.71       800\n",
      "weighted avg       0.84      0.71      0.75       800\n",
      "\n",
      "Training Loss for 200 steps: 0.7310141397996884\n",
      "Train Accuracy for 200 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.53      0.67       268\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.39      0.32      0.35        37\n",
      "           3       0.75      0.38      0.50         8\n",
      "           4       1.00      0.50      0.67         4\n",
      "           5       0.24      0.27      0.26        22\n",
      "           6       1.00      0.45      0.62        11\n",
      "           7       1.00      0.92      0.96        36\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       0.88      1.00      0.93        14\n",
      "          10       0.97      1.00      0.98        32\n",
      "          11       0.86      0.78      0.82        23\n",
      "          12       1.00      0.98      0.99        55\n",
      "          13       0.11      0.73      0.19        22\n",
      "          14       0.71      0.42      0.53        12\n",
      "          15       1.00      1.00      1.00       148\n",
      "          16       0.52      0.71      0.60        35\n",
      "          17       0.96      1.00      0.98        26\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.80      0.72      0.73       800\n",
      "weighted avg       0.87      0.73      0.77       800\n",
      "\n",
      "Training Loss for 300 steps: 0.7432605009506676\n",
      "Train Accuracy for 300 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.49      0.65       247\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       0.38      0.42      0.40        52\n",
      "           3       1.00      0.60      0.75        20\n",
      "           4       1.00      0.50      0.67         6\n",
      "           5       0.29      0.31      0.30        29\n",
      "           6       1.00      0.71      0.83         7\n",
      "           7       1.00      0.94      0.97        48\n",
      "           8       0.97      0.97      0.97        37\n",
      "           9       1.00      1.00      1.00        11\n",
      "          10       1.00      1.00      1.00        33\n",
      "          11       0.82      0.82      0.82        17\n",
      "          12       0.96      0.94      0.95        53\n",
      "          13       0.11      0.67      0.19        24\n",
      "          14       0.14      0.17      0.15        12\n",
      "          15       0.99      1.00      1.00       153\n",
      "          16       0.38      0.38      0.38        26\n",
      "          17       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.77      0.72      0.72       800\n",
      "weighted avg       0.85      0.71      0.75       800\n",
      "\n",
      "Training Loss for 400 steps: 0.7509557318596746\n",
      "Train Accuracy for 400 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.52      0.67       250\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.43      0.45      0.44        51\n",
      "           3       0.60      0.38      0.46        16\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       0.22      0.34      0.27        35\n",
      "           6       0.80      0.40      0.53        10\n",
      "           7       1.00      0.90      0.95        41\n",
      "           8       1.00      1.00      1.00        49\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       0.97      1.00      0.98        30\n",
      "          11       0.84      1.00      0.91        16\n",
      "          12       1.00      1.00      1.00        48\n",
      "          13       0.08      0.50      0.13        20\n",
      "          14       0.47      0.44      0.45        16\n",
      "          15       1.00      1.00      1.00       153\n",
      "          16       0.73      0.62      0.67        26\n",
      "          17       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.76      0.75      0.73       800\n",
      "weighted avg       0.86      0.72      0.76       800\n",
      "\n",
      "Training Loss for 500 steps: 0.7553715801585424\n",
      "Train Accuracy for 500 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.53      0.67       253\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.31      0.51      0.39        55\n",
      "           3       0.80      0.44      0.57         9\n",
      "           4       1.00      0.56      0.71         9\n",
      "           5       0.12      0.45      0.19        31\n",
      "           6       1.00      0.38      0.56        13\n",
      "           7       1.00      0.87      0.93        31\n",
      "           8       0.98      0.98      0.98        44\n",
      "           9       1.00      1.00      1.00        18\n",
      "          10       0.93      0.97      0.95        29\n",
      "          11       0.94      0.94      0.94        16\n",
      "          12       1.00      0.98      0.99        55\n",
      "          13       0.21      0.44      0.28        16\n",
      "          14       0.22      0.13      0.17        15\n",
      "          15       1.00      1.00      1.00       147\n",
      "          16       0.95      0.66      0.78        32\n",
      "          17       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.80      0.71      0.73       800\n",
      "weighted avg       0.85      0.72      0.76       800\n",
      "\n",
      "Training Loss for 600 steps: 0.7400666194882309\n",
      "Train Accuracy for 600 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69       273\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       0.24      0.47      0.32        49\n",
      "           3       1.00      0.53      0.69        17\n",
      "           4       0.86      0.75      0.80         8\n",
      "           5       0.16      0.57      0.25        28\n",
      "           6       0.88      0.64      0.74        11\n",
      "           7       1.00      0.89      0.94        35\n",
      "           8       1.00      1.00      1.00        50\n",
      "           9       1.00      1.00      1.00        14\n",
      "          10       0.94      0.97      0.95        32\n",
      "          11       0.76      0.93      0.84        14\n",
      "          12       1.00      1.00      1.00        35\n",
      "          13       0.11      0.17      0.13        24\n",
      "          14       0.20      0.14      0.17         7\n",
      "          15       0.99      0.99      0.99       129\n",
      "          16       0.95      0.58      0.72        33\n",
      "          17       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.78      0.73      0.73       800\n",
      "weighted avg       0.85      0.73      0.76       800\n",
      "\n",
      "Training Loss for 700 steps: 0.7488126599622794\n",
      "Train Accuracy for 700 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.57      0.70       267\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       0.44      0.43      0.44        51\n",
      "           3       0.70      0.64      0.67        11\n",
      "           4       0.71      0.50      0.59        10\n",
      "           5       0.23      0.58      0.33        31\n",
      "           6       1.00      0.73      0.84        11\n",
      "           7       1.00      0.92      0.96        37\n",
      "           8       1.00      1.00      1.00        48\n",
      "           9       1.00      1.00      1.00        15\n",
      "          10       0.95      1.00      0.97        18\n",
      "          11       0.73      0.85      0.79        13\n",
      "          12       1.00      0.98      0.99        51\n",
      "          13       0.06      0.32      0.10        19\n",
      "          14       0.50      0.14      0.22        14\n",
      "          15       1.00      1.00      1.00       143\n",
      "          16       0.94      0.50      0.65        30\n",
      "          17       0.96      1.00      0.98        24\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.79      0.73      0.73       800\n",
      "weighted avg       0.86      0.73      0.77       800\n",
      "\n",
      "Training Loss for 800 steps: 0.7413611794630364\n",
      "Train Accuracy for 800 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.52      0.67       246\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.32      0.43      0.37        47\n",
      "           3       0.43      0.23      0.30        13\n",
      "           4       1.00      0.50      0.67         6\n",
      "           5       0.16      0.61      0.25        28\n",
      "           6       0.90      0.82      0.86        11\n",
      "           7       0.97      0.76      0.85        38\n",
      "           8       1.00      1.00      1.00        54\n",
      "           9       0.81      0.93      0.87        14\n",
      "          10       0.96      1.00      0.98        22\n",
      "          11       0.92      0.85      0.88        26\n",
      "          12       1.00      1.00      1.00        57\n",
      "          13       0.10      0.30      0.15        20\n",
      "          14       0.17      0.38      0.23         8\n",
      "          15       1.00      0.99      1.00       149\n",
      "          16       1.00      0.64      0.78        22\n",
      "          17       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.76      0.72      0.71       800\n",
      "weighted avg       0.87      0.73      0.77       800\n",
      "\n",
      "Training Loss for 900 steps: 0.7451692393687104\n",
      "Train Accuracy for 900 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.57      0.71       268\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.36      0.53      0.43        66\n",
      "           3       0.67      0.40      0.50         5\n",
      "           4       0.75      0.50      0.60         6\n",
      "           5       0.17      0.42      0.25        33\n",
      "           6       0.83      0.56      0.67         9\n",
      "           7       0.97      0.89      0.93        38\n",
      "           8       0.97      0.97      0.97        37\n",
      "           9       0.94      1.00      0.97        16\n",
      "          10       1.00      0.92      0.96        36\n",
      "          11       0.73      1.00      0.84        19\n",
      "          12       1.00      1.00      1.00        39\n",
      "          13       0.03      0.11      0.04        18\n",
      "          14       0.40      0.21      0.28        19\n",
      "          15       1.00      0.99      1.00       131\n",
      "          16       0.94      0.53      0.68        32\n",
      "          17       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.76      0.70      0.71       800\n",
      "weighted avg       0.85      0.71      0.75       800\n",
      "\n",
      "Training Loss for 1000 steps: 0.7512715514669043\n",
      "Train Accuracy for 1000 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.48      0.64       252\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       0.33      0.56      0.42        48\n",
      "           3       1.00      0.62      0.77         8\n",
      "           4       1.00      0.45      0.62        11\n",
      "           5       0.21      0.45      0.29        31\n",
      "           6       1.00      0.42      0.59        12\n",
      "           7       1.00      0.94      0.97        36\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       0.94      1.00      0.97        15\n",
      "          10       0.93      0.96      0.95        27\n",
      "          11       0.63      0.86      0.73        14\n",
      "          12       0.98      0.96      0.97        53\n",
      "          13       0.14      0.36      0.20        33\n",
      "          14       0.12      0.33      0.18        18\n",
      "          15       1.00      1.00      1.00       126\n",
      "          16       0.90      0.53      0.67        36\n",
      "          17       0.92      0.96      0.94        25\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.78      0.72      0.72       800\n",
      "weighted avg       0.84      0.69      0.73       800\n",
      "\n",
      "Training Loss for 1100 steps: 0.7563657571613868\n",
      "Train Accuracy for 1100 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.52      0.68       244\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.34      0.33      0.33        49\n",
      "           3       0.80      0.36      0.50        11\n",
      "           4       0.33      0.25      0.29         8\n",
      "           5       0.14      0.33      0.20        33\n",
      "           6       1.00      0.67      0.80        12\n",
      "           7       0.98      0.94      0.96        48\n",
      "           8       1.00      0.97      0.99        37\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       0.97      1.00      0.98        28\n",
      "          11       0.94      0.83      0.88        35\n",
      "          12       1.00      0.98      0.99        45\n",
      "          13       0.10      0.35      0.15        20\n",
      "          14       0.09      0.33      0.14        18\n",
      "          15       1.00      1.00      1.00       139\n",
      "          16       0.79      0.50      0.61        22\n",
      "          17       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.75      0.69      0.69       800\n",
      "weighted avg       0.85      0.70      0.75       800\n",
      "\n",
      "Training Loss for 1200 steps: 0.7532783567999062\n",
      "Train Accuracy for 1200 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.55      0.69       255\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.42      0.46      0.44        54\n",
      "           3       0.75      0.43      0.55        14\n",
      "           4       1.00      0.89      0.94         9\n",
      "           5       0.17      0.50      0.25        28\n",
      "           6       0.89      0.57      0.70        14\n",
      "           7       1.00      0.89      0.94        38\n",
      "           8       0.98      1.00      0.99        40\n",
      "           9       1.00      1.00      1.00        14\n",
      "          10       1.00      1.00      1.00        33\n",
      "          11       0.94      0.85      0.89        20\n",
      "          12       1.00      0.98      0.99        41\n",
      "          13       0.09      0.42      0.15        19\n",
      "          14       0.47      0.47      0.47        15\n",
      "          15       1.00      0.99      1.00       156\n",
      "          16       1.00      0.50      0.67        20\n",
      "          17       0.96      1.00      0.98        27\n",
      "\n",
      "    accuracy                           0.74       800\n",
      "   macro avg       0.81      0.75      0.76       800\n",
      "weighted avg       0.86      0.74      0.78       800\n",
      "\n",
      "Training Loss for 1300 steps: 0.7511910808731341\n",
      "Train Accuracy for 1300 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70       256\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       0.25      0.62      0.35        53\n",
      "           3       1.00      0.69      0.81        16\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       0.17      0.24      0.20        25\n",
      "           6       0.50      0.38      0.43         8\n",
      "           7       1.00      0.96      0.98        46\n",
      "           8       1.00      0.98      0.99        48\n",
      "           9       0.92      0.96      0.94        25\n",
      "          10       1.00      0.97      0.99        35\n",
      "          11       0.96      0.96      0.96        23\n",
      "          12       1.00      1.00      1.00        38\n",
      "          13       0.15      0.40      0.22        15\n",
      "          14       0.44      0.27      0.33        15\n",
      "          15       0.99      0.99      0.99       145\n",
      "          16       0.46      0.32      0.37        19\n",
      "          17       1.00      0.96      0.98        26\n",
      "\n",
      "    accuracy                           0.75       800\n",
      "   macro avg       0.73      0.70      0.70       800\n",
      "weighted avg       0.84      0.75      0.77       800\n",
      "\n",
      "Training Loss for 1400 steps: 0.7524188997932436\n",
      "Train Accuracy for 1400 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.53      0.69       260\n",
      "           1       0.80      1.00      0.89         4\n",
      "           2       0.30      0.52      0.38        44\n",
      "           3       1.00      0.63      0.77        19\n",
      "           4       1.00      0.20      0.33         5\n",
      "           5       0.15      0.38      0.22        26\n",
      "           6       1.00      0.31      0.47        13\n",
      "           7       0.93      0.82      0.87        34\n",
      "           8       0.98      0.98      0.98        44\n",
      "           9       1.00      1.00      1.00        21\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       0.87      0.90      0.88        29\n",
      "          12       1.00      1.00      1.00        52\n",
      "          13       0.04      0.22      0.07        18\n",
      "          14       0.62      0.38      0.48        13\n",
      "          15       1.00      1.00      1.00       142\n",
      "          16       1.00      0.65      0.79        20\n",
      "          17       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.82      0.70      0.71       800\n",
      "weighted avg       0.89      0.73      0.77       800\n",
      "\n",
      "Training Loss for 1500 steps: 0.7475386391917981\n",
      "Train Accuracy for 1500 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.56      0.71       256\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.31      0.50      0.38        46\n",
      "           3       0.67      0.36      0.47        11\n",
      "           4       0.56      0.50      0.53        10\n",
      "           5       0.11      0.43      0.18        21\n",
      "           6       0.62      0.45      0.53        11\n",
      "           7       1.00      0.91      0.96        47\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       1.00      1.00      1.00        17\n",
      "          10       1.00      0.97      0.98        29\n",
      "          11       0.96      1.00      0.98        25\n",
      "          12       1.00      0.98      0.99        44\n",
      "          13       0.13      0.50      0.21        18\n",
      "          14       0.71      0.42      0.53        12\n",
      "          15       1.00      1.00      1.00       144\n",
      "          16       0.94      0.58      0.71        26\n",
      "          17       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           0.75       800\n",
      "   macro avg       0.78      0.73      0.73       800\n",
      "weighted avg       0.89      0.75      0.79       800\n",
      "\n",
      "Training Loss for 1600 steps: 0.7432326688884212\n",
      "Train Accuracy for 1600 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.70       262\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.37      0.49      0.42        45\n",
      "           3       0.86      0.50      0.63        12\n",
      "           4       0.50      0.33      0.40         3\n",
      "           5       0.16      0.33      0.22        27\n",
      "           6       1.00      0.90      0.95        10\n",
      "           7       0.97      0.80      0.88        35\n",
      "           8       0.98      0.93      0.95        43\n",
      "           9       0.95      1.00      0.97        19\n",
      "          10       0.97      0.97      0.97        30\n",
      "          11       0.89      0.96      0.92        25\n",
      "          12       0.98      0.98      0.98        55\n",
      "          13       0.08      0.50      0.14        18\n",
      "          14       1.00      0.33      0.50        15\n",
      "          15       0.99      1.00      1.00       143\n",
      "          16       0.88      0.47      0.61        30\n",
      "          17       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.80      0.73      0.74       800\n",
      "weighted avg       0.87      0.73      0.78       800\n",
      "\n",
      "Training Loss for 1700 steps: 0.753865239462489\n",
      "Train Accuracy for 1700 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.70       261\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       0.39      0.44      0.42        61\n",
      "           3       0.91      0.56      0.69        18\n",
      "           4       0.67      0.50      0.57         4\n",
      "           5       0.17      0.51      0.25        35\n",
      "           6       0.86      0.33      0.48        18\n",
      "           7       0.97      0.91      0.94        34\n",
      "           8       1.00      1.00      1.00        34\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       0.89      0.96      0.93        26\n",
      "          11       0.86      1.00      0.93        19\n",
      "          12       1.00      1.00      1.00        42\n",
      "          13       0.09      0.27      0.14        26\n",
      "          14       0.25      0.15      0.19        13\n",
      "          15       1.00      0.98      0.99       139\n",
      "          16       0.63      0.50      0.56        34\n",
      "          17       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.76      0.70      0.71       800\n",
      "weighted avg       0.82      0.70      0.73       800\n",
      "\n",
      "Training Loss for 1800 steps: 0.7555742570736742\n",
      "Train Accuracy for 1800 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.50      0.66       272\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       0.31      0.39      0.34        57\n",
      "           3       1.00      0.86      0.92        14\n",
      "           4       1.00      0.44      0.62         9\n",
      "           5       0.18      0.31      0.22        32\n",
      "           6       1.00      0.60      0.75        10\n",
      "           7       1.00      0.93      0.97        30\n",
      "           8       1.00      1.00      1.00        36\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       1.00      0.89      0.94        36\n",
      "          11       0.90      0.90      0.90        21\n",
      "          12       0.97      0.94      0.95        32\n",
      "          13       0.08      0.43      0.13        23\n",
      "          14       0.35      0.38      0.36        21\n",
      "          15       1.00      1.00      1.00       136\n",
      "          16       0.64      0.56      0.60        32\n",
      "          17       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.68       800\n",
      "   macro avg       0.79      0.73      0.74       800\n",
      "weighted avg       0.84      0.68      0.73       800\n",
      "\n",
      "Training Loss for 1900 steps: 0.7533065174842353\n",
      "Train Accuracy for 1900 steps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.53      0.68       269\n",
      "           1       0.80      0.80      0.80         5\n",
      "           2       0.43      0.49      0.46        49\n",
      "           3       1.00      0.50      0.67        12\n",
      "           4       0.71      0.83      0.77         6\n",
      "           5       0.15      0.33      0.21        24\n",
      "           6       0.86      0.60      0.71        10\n",
      "           7       1.00      0.86      0.92        42\n",
      "           8       1.00      0.97      0.99        37\n",
      "           9       0.96      0.96      0.96        23\n",
      "          10       0.96      1.00      0.98        22\n",
      "          11       0.89      0.85      0.87        20\n",
      "          12       0.98      0.95      0.96        43\n",
      "          13       0.07      0.45      0.13        20\n",
      "          14       0.43      0.33      0.38         9\n",
      "          15       0.99      1.00      1.00       160\n",
      "          16       0.68      0.61      0.64        28\n",
      "          17       0.95      1.00      0.98        21\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.77      0.73      0.73       800\n",
      "weighted avg       0.86      0.72      0.77       800\n",
      "\n",
      "The Total Accuracy for Epoch 1:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.54      0.68      4961\n",
      "           1       0.96      0.99      0.98       129\n",
      "           2       0.34      0.47      0.39       979\n",
      "           3       0.85      0.52      0.64       250\n",
      "           4       0.79      0.53      0.64       131\n",
      "           5       0.17      0.42      0.24       552\n",
      "           6       0.89      0.55      0.68       220\n",
      "           7       0.99      0.89      0.94       733\n",
      "           8       0.99      0.99      0.99       809\n",
      "           9       0.96      0.99      0.98       303\n",
      "          10       0.97      0.97      0.97       582\n",
      "          11       0.86      0.90      0.88       387\n",
      "          12       0.99      0.98      0.99       898\n",
      "          13       0.09      0.39      0.15       403\n",
      "          14       0.27      0.30      0.29       267\n",
      "          15       1.00      1.00      1.00      2767\n",
      "          16       0.73      0.54      0.62       534\n",
      "          17       0.97      0.99      0.98       467\n",
      "\n",
      "    accuracy                           0.72     15372\n",
      "   macro avg       0.77      0.72      0.72     15372\n",
      "weighted avg       0.85      0.72      0.76     15372\n",
      "\n",
      "Training Loss Epoch: 0.7528334855451249\n",
      "Validation Accuracy Epoch:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65      1230\n",
      "           1       0.97      0.97      0.97        29\n",
      "           2       1.00      0.26      0.42       246\n",
      "           3       0.93      0.45      0.61        62\n",
      "           4       0.96      0.63      0.76        35\n",
      "           5       0.12      0.97      0.21       155\n",
      "           6       0.82      0.51      0.63        45\n",
      "           7       0.97      0.91      0.94       184\n",
      "           8       0.98      1.00      0.99       203\n",
      "           9       0.88      0.99      0.93        85\n",
      "          10       0.95      0.99      0.97       116\n",
      "          11       0.88      0.88      0.88        96\n",
      "          12       0.99      0.96      0.98       199\n",
      "          13       1.00      0.06      0.11       125\n",
      "          14       0.72      0.29      0.41        63\n",
      "          15       1.00      1.00      1.00       752\n",
      "          16       1.00      0.47      0.64       110\n",
      "          17       0.97      0.97      0.97       108\n",
      "\n",
      "    accuracy                           0.70      3843\n",
      "   macro avg       0.90      0.71      0.73      3843\n",
      "weighted avg       0.94      0.70      0.74      3843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS-1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "52mmdTYLGsaM",
    "outputId": "f6a9b5dc-e9b1-4c2d-82a1-b17d50890977"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Epoch: 0.0\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-f8f3fc1ece23>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "model.eval()\n",
    "preds, labels =[],[]\n",
    "n_correct = 0; n_wrong = 0; total = 0\n",
    "n_correct = 0\n",
    "nb_tr_steps = 0\n",
    "nb_tr_examples = 0\n",
    "with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "\n",
    "            logits = outputs.detach().cpu().numpy()\n",
    "            try:\n",
    "              preds.extend(list(np.argmax(logits, axis=1).flatten()))\n",
    "            except:\n",
    "              preds.extend(list(np.argmax(logits).flatten()))\n",
    "              \n",
    "            labels.extend(list(targets.detach().cpu().numpy().flatten()))\n",
    "            \n",
    "        # epoch_loss = tr_loss/nb_tr_steps\n",
    "        epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "        # print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "        print(f\"Validation Accuracy Epoch: {epoch_accu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVal54Th9jLJ"
   },
   "outputs": [],
   "source": [
    "def CountFrequency(my_list):\n",
    "    # Creating an empty dictionary \n",
    "    freq = {}\n",
    "    for items in my_list:\n",
    "        freq[items] = my_list.count(items)\n",
    "      \n",
    "    for key, value in freq.items():\n",
    "        print (\"% d : % d\"%(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MzWIR5FAc5S",
    "outputId": "c5688742-90de-4ffe-a874-fe5625404693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 :  1254\n",
      " 0 :  587\n",
      " 4 :  23\n",
      " 15 :  752\n",
      " 12 :  192\n",
      " 8 :  207\n",
      " 17 :  108\n",
      " 16 :  52\n",
      " 10 :  121\n",
      " 2 :  65\n",
      " 7 :  173\n",
      " 11 :  95\n",
      " 14 :  25\n",
      " 1 :  29\n",
      " 9 :  95\n",
      " 6 :  28\n",
      " 3 :  30\n",
      " 13 :  7\n",
      "\n",
      "\n",
      " 14 :  63\n",
      " 0 :  1230\n",
      " 4 :  35\n",
      " 5 :  155\n",
      " 15 :  752\n",
      " 12 :  199\n",
      " 8 :  203\n",
      " 17 :  108\n",
      " 16 :  110\n",
      " 13 :  125\n",
      " 10 :  116\n",
      " 2 :  246\n",
      " 7 :  184\n",
      " 11 :  96\n",
      " 3 :  62\n",
      " 1 :  29\n",
      " 6 :  45\n",
      " 9 :  85\n"
     ]
    }
   ],
   "source": [
    "CountFrequency(preds)\n",
    "print(\"\\n\")\n",
    "CountFrequency(labels)\n",
    "preds+=[19,22,25,26,27]\n",
    "labels+=[19,22,25,26,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXFRElmFCGjO",
    "outputId": "90c55804-0b5b-45a5-f2df-577f5e9a7d40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 587,   29,   65,   30,   23, 1254,   28,  173,  207,   95,  121,\n",
       "         95,  192,    7,   25,  752,   52,  108,    1,    1,    1,    1,\n",
       "          1])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(preds, labels).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Ost53doc084o"
   },
   "outputs": [],
   "source": [
    "C = confusion_matrix(preds, labels)\n",
    "C = C / C.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "SCATjz9Z71qI"
   },
   "outputs": [],
   "source": [
    "for mylist in C:\n",
    "  for (i, item) in enumerate(mylist):\n",
    "      if item > 1:\n",
    "          mylist[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "id": "SREXWb9I9X_H",
    "outputId": "ea3ee8fb-1639-40aa-cb82-0d3cfaeebc7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f248d32f190>"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCEAAARiCAYAAACavu08AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xT9f7H8fc3acsopQsoHUCVIUMBZSgioiggIOAW3PvqVXGhcuUny3vd47ruRa5yvTgRXAxxMFyIAiKyNxQobYHSlg0lOb8/WgoB0tiQnhzi6/l49PEwzUnOKzkB7Kcn3xjLsgQAAAAAAFDZXOEOAAAAAAAAfw4MIQAAAAAAgC0YQgAAAAAAAFswhAAAAAAAALZgCAEAAAAAAGzBEAIAAAAAANiCIQQAAAAAAPBhjBltjNlsjFnk53pjjHnFGLPKGLPAGHPGH7lfhhAAAAAAAOBIb0u6qJzre0hqXPp1h6R//5E7ZQgBAAAAAAB8WJb1vaRt5WzSV9IYq8TPkhKMMamB7pchBAAAAAAAqKh0SRsOu7yx9Hvliqq0nFIxp99iVfY+gnXL/OnhTgAAOECMy4Q7wa/9Xsf+MwoAgCRppLXOuf+QhoCTf6Y9HsXz//sXlbyN4qBRlmWNquz9VvoQAgAAAAAAOEvpwOF4hg7Zkuoddjmj9Hvl4u0YAAAAAACgoiZIuqH0UzLOklRkWVZOoBtxJgQAAAAAAPBhjPlA0nmSahljNkoaKilakizLGinpC0k9Ja2StFvSzX/kfhlCAAAAAADgh3G5w50QFpZl9Q9wvSXp7oreL2/HAAAAAAAAtmAIAQAAAAAAbMEQAgAAAAAA2IIhBAAAAAAAsAULUwIAAAAA4MefdWHKysKZEAAAAAAAwBYMIQAAAAAAgC0YQgAAAAAAAFuwJgQAAAAAAH6wJkRocSYEAAAAAACwBUMIAAAAAABgC4YQAAAAAADAFqwJAQAAAACAH6wJEVqcCQEAAAAAAGxxwgwhRg29WRun/VO/jRsR7pSjNO/eWcOWTdOIld+q+6N3hTvHB20V59QuibZg0VZxTu2S7G9r1v1cDV4yTY8vn6ELH7nzqOujYmJ00wev6vHlM/TgT58qqUG6JKl6UoLunfq+nitapCteGe5zm15PDNTwdTP1XNGiSu8/iGMaHKe2ObVLoi1YtFWcU7sk2oDynDBDiDETZ+riu18Md8ZRjMul/q+P0Gs9btLw5l3Vrn8fpTZrFO4sSbRFUpdEW7Boi5wuyf4243LpyldHaGSvm/Tkqd3Upl8f1T1if2fdcpV2FxTpiVPO17cvv6U+Tw+SJB3Yu0+Th76ozx558qj7XTxpql4465JK6z4SxzQ4Tm1zapdEW7Boi5wuiTYgkIBDCGNMU2PMo8aYV0q/HjXGNLMj7nA/zluhgqJddu82oMz2rbV5VZa2rt0gT3Gx5nw4US37dgt3liTaIqlLoi1YtEVOl2R/W4P2rbRldZbyS/c3b+xEndanq882p/XtqtljPpYkzR8/RU26nC1J2r97j9bMnKvivfuOut91v8zX9twtldZ9JI5pcJza5tQuibZg0RY5XRJtkci43RH5FS7lDiGMMY9K+lCSkTS79MtI+sAYM6jy85wvMT1FBRs2lV0u3JijxPSUMBYdQlvFObVLoi1YtFWcU7sk+9sS0uuqcEPOof1l5yo+va7PNvFpKWXbeD0e7S3aodjkxEprCgbHNDhObXNql0RbsGirOKd2SbQBgQT6dIxbJbWwLKv48G8aY16UtFjS08e6kTHmDkl3SJI742y5ap0SglQAAAAAAHAiC/R2DK+ktGN8P7X0umOyLGuUZVltLctqG+kDiILsPCXWO/QUJWSkqiA7L4xFh9BWcU7tkmgLFm0V59Quyf62wuxcJdRLPbS/9Loqys712aZoU17ZNi63W1Xj47Qrv6DSmoLBMQ2OU9uc2iXRFizaKs6pXRJtQCCBhhD3S5pmjJlijBlV+vWlpGmS7qv8POfLmvO76jTOVHJmhtzR0WrXr7cWTPgm3FmSaIukLom2YNEWOV2S/W3r5yxQ7UaZSird3xlX99bCiVN9tlk0Yara33C5JKn1FT20csasSusJFsc0OE5tc2qXRFuwaIucLok2IJBy345hWdaXxpgmktpLSi/9drakOZZleSo77nDvPPUXndvmFNVKqKE1Xz6vESM/19uf/WBnwjF5PR6NvWeIBnw1Ri63Wz+N/kg5S1aGO0sSbZHUJdEWLNoip0uyv83r8Wj8gKH665Qxcrld+vm/45S7ZKV6DntA639dqEUTp2rW6LG6fsxLenz5DO3eVqS3r7m37PZDV/+gqjVrKComWi37dtW/LrpBuUtXqc/Tg9S2fx9FV6+mEVk/adZbYzVlxMuV+jg4phXn1Dandkm0BYu2yOmSaItELlf4FnGMRMayrErdQczpt1TuDo7DLfOnhzsBAOAAMS4T7gS/9nsd+88oAACSpJHWOuf+QxoCcecOjMh/jHd8/3xYjlvAj+gEAAAAAAAIBYYQAAAAAADAFoE+ohMAAAAAgD8tw5oQIcWZEAAAAAAAwBYMIQAAAAAAgC0YQgAAAAAAAFuwJgQAAAAAAH6wJkRocSYEAAAAAACwBUMIAAAAAABgC4YQAAAAAADAFqwJAQAAAACAH8bF7+5DiWcTAAAAAADYgiEEAAAAAACwBUMIAAAAAABgC4YQAAAAAADAFixMCQAAAACAH8blDndCROFMCAAAAAAAYAuGEAAAAAAAwBaV/naMW+ZPr+xdBO2D868Jd8Ix9Z/xfrgTAAAAAAAIOdaEAAAAAADAD9aECC3ejgEAAAAAAGzBEAIAAAAAANiCIQQAAAAAALAFa0IAAAAAAOAHa0KEFmdCAAAAAAAAWzCEAAAAAAAAtmAIAQAAAAAAbMGaEAAAAAAA+GHcrAkRSpwJAQAAAAAAbMEQAgAAAAAA2IIhBAAAAAAAsAVDCAAAAAAAYAsWpgQAAAAAwA/jYmHKUOJMCAAAAAAAYAuGEAAAAAAAwBYMIQAAAAAAgC1YEwIAAAAAAD9YEyK0OBMCAAAAAADY4oQZQjTv3lnDlk3TiJXfqvujd9m67wvaNdbc/z2g3955SA/0P/eo6+ulJGjC87dq5n/u1aQXb1NarZqSpE6tT9YPo+4p+8r7crh6dWxma3s4n7dAnNrm1C6JtmDRVnFO7ZLsb2vW/VwNXjJNjy+foQsfufOo66NiYnTTB6/q8eUz9OBPnyqpQbokqXpSgu6d+r6eK1qkK14Z7nObXk8M1PB1M/Vc0aJK7z+IYxocp7Y5tUuiLVi0VZxTuyTagPKcEEMI43Kp/+sj9FqPmzS8eVe1699Hqc0a2bJvl8vohfv66IpBb6v9zf/U5V1a6ZQGdXy2+fudPfTB1/PU8fZX9ew70zX09u6SpB/mr1GnO15TpzteU5+H3tKevcWaPneVLd1SeJ+3QJza5tQuibZg0RY5XZL9bcbl0pWvjtDIXjfpyVO7qU2/Pqp7xP7OuuUq7S4o0hOnnK9vX35LfZ4eJEk6sHefJg99UZ898uRR97t40lS9cNYlldZ9JI5pcJza5tQuibZg0RY5XRJtQCAnxBAis31rbV6Vpa1rN8hTXKw5H05Uy77dbNl3m6YZWpOdr3U5BSo+4NEn0xeo19m+ZzOc0qCOvv9tjSTp+9/WqOfZR5/t0PfcU/XN7BXas6/Ylm4pvM9bIE5tc2qXRFuwaIucLsn+tgbtW2nL6izll+5v3tiJOq1PV59tTuvbVbPHfCxJmj9+ipp0OVuStH/3Hq2ZOVfFe/cddb/rfpmv7blbKq37SBzT4Di1zaldEm3Boi1yuiTaIpHL5Y7Ir7A9n8He0BhzcyhDypOYnqKCDZvKLhduzFFieoot+06rFa/szUVll7O3Fim1dk2fbRatzlXvTi0kSb07tVDN2KpKrFnNZ5vLu7TU+Om/V37wYcL5vAXi1Dandkm0BYu2inNql2R/W0J6XRVuyDm0v+xcxafX9dkmPi2lbBuvx6O9RTsUm5xYaU3B4JgGx6ltTu2SaAsWbRXn1C6JNiCQ4zkTYnjgTf4c/m/kFzqn1Un64Y171LHlScreUiSvxyq7PiUpTs1Pqqtpc1aGsRIAAAAAgPAq9yM6jTEL/F0lye/IzBhzh6Q7JKmTktRccUEHSlJBdp4S66WVXU7ISFVBdt5x3ecftWlrkdLrxJddTq8Vr5wt2322yc3foeuGvidJiq0aoz7ntlDRrr1l11963mma9ONiHfB4bWk+KJzPWyBObXNql0RbsGirOKd2Sfa3FWbnKqFe6qH9pddVUXauzzZFm/KUUC9Vhdm5crndqhofp135BZXWFAyOaXCc2ubULom2YNFWcU7tkmgDAgl0JkSKpBsk9T7GV76/G1mWNcqyrLaWZbU93gGEJGXN+V11GmcqOTND7uhotevXWwsmfHPc9/tHzFuWrYbptdSgbqKio9y6rEtLfTFrqc82STWryxgjSXrwms56d8qvPtdf0aWlxk/3N8+pPOF83gJxaptTuyTagkVb5HRJ9retn7NAtRtlKql0f2dc3VsLJ0712WbRhKlqf8PlkqTWV/TQyhmzKq0nWBzT4Di1zaldEm3Boi1yuiTaIpFxuSPyK1zKPRNC0iRJNSzLmn/kFcaYbyul6Bi8Ho/G3jNEA74aI5fbrZ9Gf6ScJfa8tcHj9WrgqxP0yTM3y+02enfKr1q2brMeu+lC/bZio6b8tEydWp+sobd1k2VJPy1Yq4demVB2+/opCUqvE68ff19rS+/hwvm8BeLUNqd2SbQFi7bI6ZLsb/N6PBo/YKj+OmWMXG6Xfv7vOOUuWamewx7Q+l8XatHEqZo1eqyuH/OSHl8+Q7u3Fenta+4tu/3Q1T+oas0aioqJVsu+XfWvi25Q7tJV6vP0ILXt30fR1atpRNZPmvXWWE0Z8XKlPg6OacU5tc2pXRJtwaItcrok2oBAjGVZgbc6DneazMrdwXH44Pxrwp1wTP1nvB/uBAD4U4lxmXAn+LXf69h/RgEAkCSNtNY59x/SEEi98rWI/Mc4Z9w9YTluJ8RHdAIAAAAAgBMfQwgAAAAAAGCLQGtCAAAAAADwpxXORRwjEWdCAAAAAAAAWzCEAAAAAAAAtmAIAQAAAAAAbMGaEAAAAAAA+MGaEKHFmRAAAAAAAMAWDCEAAAAAAIAtGEIAAAAAAABbsCYEAAAAAAB+sCZEaHEmBAAAAAAAsAVDCAAAAAAAYAuGEAAAAAAAwBasCQEAAAAAgB+sCRFanAkBAAAAAABswRACAAAAAADYgiEEAAAAAACwBUMIAAAAAABgiz/1wpT9Z7wf7oRjGt26S7gT/Lpl/vRwJwBAyO33WuFOAAAADmXcLEwZSpwJAQAAAAAAbMEQAgAAAAAA2IIhBAAAAAAAsMWfek0IAAAAAADKY1ysCRFKnAkBAAAAAABswRACAAAAAADYgiEEAAAAAACwBWtCAAAAAADgB2tChBZnQgAAAAAAAFswhAAAAAAAALZgCAEAAAAAAGzBmhAAAAAAAPjBmhChxZkQAAAAAADAFgwhAAAAAACALRhCAAAAAAAAWzCEAAAAAAAAtmBhSgAAAAAA/HC5TLgTIgpnQgAAAAAAAFucMEOI5t07a9iyaRqx8lt1f/SucOf4cGrbqKE3a+O0f+q3cSPCnXJMTn3enNol0RYs2irOqV0SbcGiLThObXNql0RbsGirOKd2SbQB5TkhhhDG5VL/10fotR43aXjzrmrXv49SmzUKd5YkZ7eNmThTF9/9Yrgzjsmpz5tTuyTagkVb5HRJtAWLtuA4tc2pXRJtwaItcrok2oBAToghRGb71tq8Kktb126Qp7hYcz6cqJZ9u4U7S5Kz236ct0IFRbvCnXFMTn3enNol0RYs2iKnS6ItWLQFx6ltTu2SaAsWbZHTJdEWiYzLRORXuAQcQhhjmhpjLjDG1Dji+xdVXpavxPQUFWzYVHa5cGOOEtNT7Np9uZzc5mROfd6c2iXRFizaKs6pXRJtwaItOE5tc2qXRFuwaKs4p3ZJtAGBlDuEMMYMkPS5pHslLTLG9D3s6icrMwwAAAAAAESWQB/RebukNpZl7TTGZEoab4zJtCzrZUl+z98wxtwh6Q5J6qQkNVfccUUWZOcpsV5a2eWEjFQVZOcd132GipPbnMypz5tTuyTagkVbxTm1S6ItWLQFx6ltTu2SaAsWbRXn1C6JNiCQQG/HcFmWtVOSLMtaJ+k8ST2MMS+qnCGEZVmjLMtqa1lW2+MdQEhS1pzfVadxppIzM+SOjla7fr21YMI3x32/oeDkNidz6vPm1C6JtmDRFjldEm3Boi04Tm1zapdEW7Boi5wuibZIZIyJyK9wCXQmRJ4xprVlWfMlqfSMiIsljZZ0WqXXlfJ6PBp7zxAN+GqMXG63fhr9kXKWrLRr9+Vycts7T/1F57Y5RbUSamjNl89rxMjP9fZnP4Q7S5Jznzendkm0BYu2yOmSaAsWbcFxaptTuyTagkVb5HRJtAGBGMuy/F9pTIakA5Zl5R7juo6WZc0MtIM7Tab/HeCYRrfuEu4Ev26ZPz3cCQAAAAAcZKS1Lny/VrdB47s/jcifaVe+fmlYjlu5Z0JYlrWxnOsCDiAAAAAAAAAOCvR2DAAAAAAA/rRcrog+0cN2gRamBAAAAAAACAmGEAAAAAAAwBYMIQAAAAAAgC0YQgAAAAAAAFuwMCUAAAAAAH4YFqYMKc6EAAAAAAAAtmAIAQAAAAAAbMEQAgAAAAAA2II1IQAAAAAA8IM1IUKLMyEAAAAAAIAtGEIAAAAAAABbMIQAAAAAAAC2YE0IAAAAAAD8cBnWhAglzoQAAAAAAAC2YAgBAAAAAABswRACAAAAAADYgjUhAAAAAADww7hYEyKUGEI40C3zp4c7wa/PrxgY7gS/+o5/PtwJAACgEtSIcubJuzsPeMOdAAAnHGf+jQ4AAAAAACIOQwgAAAAAAGAL3o4BAAAAAIAfrAkRWpwJAQAAAAAAbMEQAgAAAAAA2IIhBAAAAAAAsAVDCAAAAAAAYAsWpgQAAAAAwA8XC1OGFGdCAAAAAAAAWzCEAAAAAAAAtmAIAQAAAAAAbMGaEAAAAAAA+GH41X1I8XQCAAAAAABbMIQAAAAAAAC2YAgBAAAAAABswZoQAAAAAAD4YYwJd0JE4UwIAAAAAABgC4YQAAAAAADAFgwhAAAAAACALU6YIUTz7p01bNk0jVj5rbo/ele4c3zQdmznt66vH16+Vj+9ep3uueSMo67PqBWnj4b01bTn++njYZcqNSm27PtfP3OVvnnuan37Yn/d0LWFrd0cz+DQFhyntjm1S6ItWLQFx6ltTu2S7G87pdu5emTRVA1aOl3nP3znUde7Y2J03XuvaNDS6Row8xMlNkiXJFVPStCd37ynfxQs1KUvD/O5Tasre+nBeV9o4Pwv1evJRyv9MUgc02A4tUuiLdK4XCYiv8L2fIZtzxVgXC71f32EXutxk4Y376p2/fsotVmjcGdJos0fl8voyVs769p/TFTnB97XJR2bqElGos82Q27oqHHfLdcFAz/Ui+Nn67FrO0iS8gp36eLB49X14bHq+dh43XNJG6UkxtrSzfEMDm3BcWqbU7sk2oJFW3Cc2ubULsn+NuNy6dJXhuvN3jfruZbddXq/3ko5Yn9n3nKV9hRu19PNuuj7l0eXDRUO7N2nL4e9pEmPPuWzffWkBF389N/0Rrfr9HzrixRXt5YanX92pT2Gg4+DYxoZXRJtQCABhxDGmPbGmHal/93cGPOgMaZn5acdktm+tTavytLWtRvkKS7WnA8nqmXfbnYm+EXbsZ3eKEXrcou0fvN2FR/w6vOZK9W97ck+2zTJSNTMRRslSTMXZZddX3zAq/0HvJKkKlFuW6d0HM/g0BYcp7Y5tUuiLVi0BcepbU7tkuxvq9++lfJXZ2lb6f7mj52kFr27+mzToveFmvvOx5KkBR9PUeMuJQOF/bv3aN3MuSreu89n++ST62vrqnXatXWbJGnFtJlqedlFlfYYJI5pJHVJtAGBlDuEMMYMlfSKpH8bY56S9JqkWEmDjDGDbeiTJCWmp6hgw6ayy4Ubc5SYnmLX7stF27HVTYpVdv6Osss523aqbrLv2QyLs/LV88ySwUPP9icrrnqMEmtUlSSlJdfQtOf76deRN+q1z+Ypr2CXLd0cz+DQFhyntjm1S6ItWLQFx6ltTu2S7G+LT6urwo05h/aXnaP4I/YXn5aiwg0l23g9Hu0p2qHqyb5nZx5u66p1qt3kJCU2SJfL7dapfbopISO1ch5AKY5pxTm1S6INCCQqwPVXSGotqYqkXEkZlmVtN8Y8L+kXSf841o2MMXdIukOSOilJzRUXumJEjBFjZurJW8/VVec10y9LN2lT/k55vCVnQGzK36kLBn6olMRY/feRnpr08yptLdoT5mIAABDp9hRu1yf3PK7r339VXq9XWbPmKfnk+uHOAoCIEWgIccCyLI+k3caY1ZZlbZcky7L2GGO8/m5kWdYoSaMk6U6TaR1vZEF2nhLrpZVdTshIVUF23vHebUjQdmy523YpPfnQ8Ck1qYZy833PZsgr2KVbn58iSapeNVo9z2yo7bv3H7XNsvX5OrNZmib/vLrSuzmewaEtOE5tc2qXRFuwaAuOU9uc2iXZ31a0KdfnLIWE9FQVHbG/ok15SqiXqqLsXLncblWLj9Pu/IJy73fJ5OlaMnm6JOnM2/rJ6/GEPv4wHNOKc2qXRFskMmFcxDESBVoTYr8xpnrpf7c5+E1jTLwkv0OIUMua87vqNM5UcmaG3NHRatevtxZM+Mau3ZeLtmObvypPJ6XGq16dOEVHudS3Y2N9NXetzzZJcVVlSv88D7i0jT6csUSSlJoUq6oxbklSfGwVtW+aptWbCm3p5ngGh7bgOLXNqV0SbcGiLThObXNql2R/24Y5C1SrUaaSSvfX+uqLtXjSVJ9tFk+aprbXXy5Janl5D62aMSvg/daonSxJqpZQU2ffeZ1+Gf1R6OMPwzGNnC6JNiCQQGdCnGtZ1j5Jsizr8KFDtKQbK63qCF6PR2PvGaIBX42Ry+3WT6M/Us6SlXbtvly0HZvHa+mxt77XB4P7yu0y+nDGEq3YuE0PX91ev6/erK/nrlOHFul67JoOsizp56XZeuzN7yRJjTOSNPSGjrIsyRhp5MTftGx9vi3dHM/g0BYcp7Y5tUuiLVi0BcepbU7tkuxv83o8+vS+Ybp98v9k3C7NeXuc8pasVPeh92vDrwu1ZNI0zR49Vv3fflGDlk7X7oIivXvtgLLbP7bye1WtWUPumGi16NNV/+l5o/KWrlLfF4corWVTSdI3/3hVW1eu9ZcQssfBMY2MLok2IBBjWcf9bolyheLtGHCOz68YGO4Ev/qOfz7cCQAAoBLUiHLmp8rvPGDbicGAo4201kX0+xXaDv0qIn+mnTu8e1iOW6AzIQAAAAAA+NNiTYjQcuZYGQAAAAAARByGEAAAAAAAwBYMIQAAAAAAgC1YEwIAAAAAAD9chjUhQokzIQAAAAAAgC0YQgAAAAAAAFswhAAAAAAAALZgTQgAAAAAAPwwLtaECCXOhAAAAAAAALZgCAEAAAAAAGzBEAIAAAAAANiCIQQAAAAAALAFC1MCAAAAAOAHC1OGFmdCAAAAAAAAWzCEAAAAAAAAtmAIAQAAAAAAbMGaEAAAAAAA+OFiTYiQYgiBCuk7/vlwJ/j1Ufdbwp3g11VfjQ53AgAA5aoR5dwTZHce8IY7AQAQIs791wYAAAAAAEQUhhAAAAAAAMAWvB0DAAAAAAA/jGFNiFDiTAgAAAAAAGALhhAAAAAAAMAWDCEAAAAAAIAtWBMCAAAAAAA/DL+6DymeTgAAAAAAYAuGEAAAAAAAwBYMIQAAAAAAgC0YQgAAAAAAAFuwMCUAAAAAAH64XCbcCRGFMyEAAAAAAIAtGEIAAAAAAABbMIQAAAAAAAC2YE0IAAAAAAD8MKwJEVKcCQEAAAAAAGzBEAIAAAAAANiCIQQAAAAAALDFCTOEaN69s4Ytm6YRK79V90fvCneOD9qCE662C9o01C9v/lVzR9+j+67qeNT1GXXi9elT1+uHf/9FE569QWm14squS69dUx//41r9POouzXrjLtVLibetW+J4Bou2inNql0RbsGgLjlPb7O46pdu5emTRVA1aOl3nP3znUde7Y2J03XuvaNDS6Row8xMlNkiXJFVPStCd37ynfxQs1KUvD/O5Tasre+nBeV9o4Pwv1evJRyv9MUjOPZ4SbcFwapdEW6QxxkTkV7icEEMI43Kp/+sj9FqPmzS8eVe1699Hqc0ahTtLEm3BCleby2X07N09dNX/va8Od/xLl5/XQqfUr+WzzRO3d9XYab+r011v6Ln3vtfjN19Qdt2/H75Er46fpbPu+LcuvO9NbS3cVenNB3E8g0Nb5HRJtAWLtuA4tc3uLuNy6dJXhuvN3jfruZbddXq/3ko5Yn9n3nKV9hRu19PNuuj7l0eXDRUO7N2nL4e9pEmPPuWzffWkBF389N/0Rrfr9HzrixRXt5YanX92pT2Gg4/DicdToi2SuiTagEAqPIQwxoypjJDyZLZvrc2rsrR17QZ5ios158OJatm3m90Zx0RbcMLV1uaUdK3NKVBWbqGKD3j1yXeL1aPDKT7bnFK/ln6Yv06S9MPv69TzrFPKvh/ldunb39ZIknbtLdaefQcqvfkgjmdwaIucLom2YNEWHKe22d1Vv30r5a/O0rbS/c0fO0ktenf12aZF7ws1952PJUkLPp6ixl1KBgr7d+/RuplzVbx3n8/2ySfX19ZV67Rr6zZJ0oppM9Xysosq7TFIzj2eEm2R1CXRBgRS7hDCGDPhiK+Jki47eNmmRiWmp6hgw6ayy4Ubc5SYnmLX7stFW3DC1ZaaHKfsLUVllzdt3a7U5DifbRatydPFHZtKki7u2FRxsVWUGFdNDdOTVbRzr/73+JX69rXbNfy2C+Wy8eN6OJ7Boa3inNol0RYs2oLj1Da7u+LT6qpwY86h/WXnKP6I/cWnpahwQ8k2Xo9He4p2qHpyot/73LpqnXlqQWEAACAASURBVGo3OUmJDdLlcrt1ap9uSshIrZwHUMqpx1OiLRhO7ZJoAwKJCnB9hqQlkt6UZEkyktpKeqG8Gxlj7pB0hyR1UpKaK668zQFHGfKfb/TM3T3Uv2srzVq0Xpu2bJfH61WU26UOp9ZX57tHaePmIo1+7Apd07WV3v1qfriTAQA4oewp3K5P7nlc17//qrxer7JmzVPyyfXDnQUAx2TnLx7/DAINIdpKuk/SYEkPW5Y13xizx7Ks78q7kWVZoySNkqQ7TaZ1vJEF2XlKrJdWdjkhI1UF2XnHe7chQVtwwtWWk79D6bUPLSaZVqumcvJ3+GyTu22nbnxinCQptmq0endspu279mnT1u1auDpPWbmFkqTJs5apbdMMyaYhBMczOLRVnFO7JNqCRVtwnNpmd1fRplyfsxQS0lNVdMT+ijblKaFeqoqyc+Vyu1UtPk678wvKvd8lk6dryeTpkqQzb+snr8cT+vjDOPV4SrQFw6ldEm1AIOW+HcOyLK9lWS9JulnSYGPMawo8uAi5rDm/q07jTCVnZsgdHa12/XprwYRv7M44JtqCE662ecuzdXJakuqnJCg6yqXLOrfQlz+v8NkmqWY1HVws9v6rz9F7X5cMGeat2KT4GlWUHF9dknRuq5O0fP2WSm8+iOMZHNoip0uiLVi0BcepbXZ3bZizQLUaZSqpdH+tr75YiydN9dlm8aRpanv95ZKklpf30KoZswLeb43ayZKkagk1dfad1+mX0R+FPv4wTj2eEm2R1CXRhshijLnIGLPcGLPKGDPoGNfXN8bMMMb8ZoxZYIzpGeg+/9BAwbKsjZKuNMb0krS94unHx+vxaOw9QzTgqzFyud36afRHylmy0u6MY6ItOOFq83gtPfKvKRr/j2vldhm99/V8Lcvaor9df55+W7lJX/68Que0zNTjN3eRZUmzFmXp4denlDR7LQ35z1R99vT1MpLmr8rRmCnzKr35II5ncGiLnC6JtmDRFhynttnd5fV49Ol9w3T75P/JuF2a8/Y45S1Zqe5D79eGXxdqyaRpmj16rPq//aIGLZ2u3QVFevfaAWW3f2zl96pas4bcMdFq0aer/tPzRuUtXaW+Lw5RWsuSNZi++cer2rpybaU9hoOPw4nHU6Itkrok2hA5jDFuSa9L6ippo6Q5xpgJlmUtOWyz/5P0kWVZ/zbGNJf0haTMcu/Xso773RLlCsXbMYA/4qPut4Q7wa+rvhod7gQAAMpVI8q5n9y+84A33AkAyjHSWhfRiyZc8MoPEfkz7bQBnco9bsaYDpKGWZbVvfTy3yTJsqynDtvmDUlrLMt6pnT7FyzLKvczl21/awUAAAAAACcKE6ELUx7+gRKlRpWu73hQuqQNh13eKOnMI+5mmKSvjTH3SoqVdGGg/TKEAAAAAADgT+bwD5Q4Dv0lvW1Z1gulZ0K8Y4w51bIsv6ewOfe8OwAAAAAAEC7Zkuoddjmj9HuHu1XSR5JkWdYsSVUl1SrvThlCAAAAAACAI82R1NgYc5IxJkZSP0kTjthmvaQLJMkY00wlQ4hyP0KQt2MAAAAAAOCHO0LXhAjEsqwDxph7JH0lyS1ptGVZi40xIyTNtSxrgqSHJP3HGPOAJEvSTVaAT79gCAEAAAAAAI5iWdYXKvnYzcO/N+Sw/14iqWNF7pO3YwAAAAAAAFswhAAAAAAAALbg7RgAAAAAAPjxZ10TorJwJgQAAAAAALAFQwgAAAAAAGALhhAAAAAAAMAWrAkBAAAAAIAfrAkRWpwJAQAAAAAAbMEQAgAAAAAA2IIhBAAAAAAAsAVDCAAAAAAAYAsWpgQAAAAAwA8WpgwthhCokM+vGBjuBL+2PNEq3Al+Te3zWbgT/Hpt4OvhTjimCwfeFO4Ev5bu2BfuBIRYkxox4U7wa8XO/eFOwJ/Ev9peHO4Ev26bPTHcCce032uFOwEATji8HQMAAAAAANiCIQQAAAAAALAFb8cAAAAAAMAP1oQILc6EAAAAAAAAtmAIAQAAAAAAbMEQAgAAAAAA2II1IQAAAAAA8COKNSFCijMhAAAAAACALRhCAAAAAAAAWzCEAAAAAAAAtmBNCAAAAAAA/HCzJkRIcSYEAAAAAACwBUMIAAAAAABgC4YQAAAAAADAFgwhAAAAAACALViYEgAAAAAAP1iYMrQ4EwIAAAAAANiCIQQAAAAAALAFQwgAAAAAAGCLE2ZNiObdO+uql4fI5XZr5ptj9dUz/w53Uhnaju381vU14uZOcruM3p+2RK99Ns/n+oxacXrxr12UXLOaCnfu0z2vfK2cbbuUUStOox/uIeMyina7NHrKAo35ZnHIun6Yt0hP/ecDebxeXdG1k26/oqfP9R9O+VYfTJkhl8ul2KpVNOyvN6hR/TTtLz6gYf8ao8Wrs+QyRn+7rZ/an9Y0ZF2SVKvT2Wo6eKCM262N4z7V2lFv+1yf2PYMNR38kGqc0lgLHvib8r6aJkmKa9ZEzYc9pqgasbI8Xq0Z+ZZyv/g6pG1nZCTo9rMz5TJG3yzL0/jfN/lcf1uHBjotNV6SVCXKpfhq0er/vzmSpBvb11e7+omSpA/nbdSPa/KPu6fBhZ3U+ZnBMm6XFv9vnOa+9B+f690x0er2xrOqc3oL7d1WqC9uekA71mcrrn66bpjzhQpWrpUk5c75XdMfGCpJanJFL7V76C+SJe3M3ayvbntYe7cVHHdreZz694dTuyT72zIv7KTznh0sl8uthWPGac6Lo3yud8dE66JRzymldQvt2VaoyTfdr+3rs1WzfrpumjtF20pfazlz5mva/SWvtcs+eVOxdevIRLmV/dNcTX9wuCyvt1IfB8c0OE5tC2dX17Oa6bn7L5Pb7dLbE2bphXem+lxfr26iRg6+RrUSaqhg+27dOuwdZW8plCT9/e4+uujsFnK5jKbPXq6BL30cVEOz7ufqspeGyuV2adZbYzX12ZE+10fFxOi6/72gemecql35hXq7/z3alpVd0v/oXTrrlqvk9Xj18f3Dtezr7yVJne+9SR1u6ydjjGa9+aG+feW/kqSewx/UaX26yvJ6tXNLvt69eaC252wOqrs8Tn2tSc5tc2qXRFukcbv43X0onRDPpnG51P/1EXqtx00a3ryr2vXvo9RmjcKdJYk2f1wuoydv7axr/zFRnR94X5d0bKImGYk+2wy5oaPGfbdcFwz8UC+On63Hru0gScor3KWLB49X14fHqudj43XPJW2Ukhgbki6Px6u/v/Ge3hh6vya+9oS++GG2Vq33/WH64s5n6vNXhuvTfw7VLZdepGdHj5UkjS/9n5TPXxmuN4c/qGf/+5G8ofyhweVSs6GP6tfb79WPPS9X6sUXKbbhST6b7MnJ0cJBw5Qz6Uvfx7VnrxY+8rhm9rpSv952t5o+9pCi4mqELs1Id55zkoZNWaq7x83XuY1qqV5CNZ9t3pyVpfs+WaD7PlmgSYtzNWvdNklS23oJalgrVgM+/l0PfbZQl7VMU7Vo93H1GJdL570wRJ9dfpveaddLTa64WEmnNPTZpsUNV2pf4Xb9r3U3/fb62zpn+MCy6wrXrtf751yi98+5pGwAYdxudX5msD7udaPeO7uPti5arlZ/ufa4Ov/I43Di3x9O7ZLsbzMul7q8MFSfXna73m7XU02P8Vo79YYrtbewSKNbd9W8199WpxEPl11XuHa93u3YV+927Fs2gJCkSTfep3fO7qMx7Xupeq0kNbm0R6U9hoOPg2NacU5tC/e/7y89dKUueXCkzuj/pK7s2kZNM+v6bPPUvZfo/SlzdOb1z+ip0V9q+F29JUlnnnaSOrQ8We2vf1ptr31KbZrVV6fTK95tXC5d+eoIjex1k548tZva9Oujukc8/rNuuUq7C4r0xCnn69uX31KfpwdJkuo2a6Qzru6tp07rrn/3vFFXvTZCxuVSaosm6nBbP71w1iV65vSeatGri2o1bCBJmv78KD1zeg8926aXFk2aroseHxDMUxfwMTnxtSY5t82pXRJtQCAnxBAis31rbV6Vpa1rN8hTXKw5H05Uy77dwp0liTZ/Tm+UonW5RVq/ebuKD3j1+cyV6t72ZJ9tmmQkauaijZKkmYuyy64vPuDV/gMlP9xXiXLLFcLVaBeuXKv6deuoXt3aiomOUo9O7TV99nyfbWpUP/TD9Z59+yRTsv/VG3J0VstmkqTkhJqKi62uRavWhawtvuWp2p21UXs2ZMsqPqCcyV+pzoXn+WyzNztHO5evlI4Yfuxet167szZIkvZt3qr92woUk+Q79DkejWvXUE7RXuXt2KcDXkvfr96qMzP93/+5DWvp+1VbJUn1Eqtrcc52eS1p3wGv1m7brTb1Eo6rJ6VtSxWtydL2dRvlLS7Wio8n6+ReF/hsc3KvLlrywaeSpJWffaV653Uo9z6NMZIxio4tOf5V4mpoVyX8putwTv37w6ldkv1tddu2VOGaLBWt2yBvcbGWfTxZDS++0Gebhr0u0JL3S15rKz77UvUDvNYkaf+OXZIkV1SUXDHRsiwr9PGH4ZgGx6lt4exq27yBVm/conWb8lV8wKPxU+fp4nNP89mmaWZdfTt3hSTpu19Xll1vWZaqxkQrJjpKVaKjFB3l1uZtOyrc0KB9K21ZnaX80sc/b+xEndanq882p/XtqtljSs6ymD9+ipp0Obvk+326at7YiTqwf7+2rduoLauz1KB9K6U0a6Ss2fNVvGevvB6PVn0/W60uvUiStHfHzrL7rRJbTaqEP69Ofa1Jzm1zapdEGxBIhYYQxphzjDEPGmNsfaUmpqeoYMOh31YXbsxRYnqKnQl+0XZsdZNilZ1/6H8scrbtVN1k37MZFmflq+eZJYOHnu1PVlz1GCXWqCpJSkuuoWnP99OvI2/Ua5/NU17BrpB05eUXqG6tQz88101O1Ob8o0+3f3/ydHX/y9/0wtvj9djt/SVJp5yUoemz5+uAx6ONeVu0ZHWWcreG7lT9qim1tTc3t+zy3tzNqppSp8L3E9+yhUx0tHav3xiytuTYGG3dta/scv6u/UqOrXLMbWvXiFFKzSpasKlIkrQuf5fOqJegKm6XalaJUsu0mqoVG3NcPTVSU7Rj46HnauemPNVI831tx6amaOfGHEmS5fFo3/Ydqlo6mIlvkKH+P3yqy794R2kd2kiSvAcOaMYDw3TtrIm6bcUPSmraUIvHjD+uzkCc+veHU7sk+9tqpKZoR/Zhr7XsXMWl+u6vRlqKdhz+WivaoarJh15r1/34ma6a8q7Sz27rc7vLPn1Ld66ZpeIdu7TyM9+zm0KNYxocp7aFsyutdoKyNxeWXc7eXKi02vE+2yxcla2+57WSJPXt3FI1Y6sqqWZ1zV60Tt/NW6E1E5/Qmkl/19Rflmp5Vl6FGxLS66pwQ07Z5cLsXMWn+56NEZ+WUraN1+PR3qIdik1OVHx6XRVsPOy2G3OUkF5XOYuWq+E57VU9KUHR1aqqeY/zlFAvtWy7Xk8M1PB1M9Xmmr76YuhLFW4OxKmvNcm5bU7tkmgDAil3CGGMmX3Yf98u6TVJcZKGGmMGVXIbItyIMTPVoXm6vn72anVoka5N+TvlKf0N/6b8nbpg4IfqcO+7uuq8pqoVXy3AvYXWNb266Ks3ntKDN16hNz6aJEm67MJzVDc5UVc+9Hc99eZYtW7aUC6HvT8spnYtnfbsE1o0aFil/Kbmjzi3YS3NXJMvb+nuf8su0q8bCvVs31M18ILGWpa3Q94wtUnS7tzNGt3ifH3Q6VL98NjTuuitFxQTFytXVJRa3tpfH3S6RG826aSti5er7UN/CVsnTny7cjfrP83P07vnXKJv//aUepa+1g765NJb9UbjjnJXiVG9zmeFsRQIrcde/UydTm+kWf97ROec3kjZmwvl8Vo6OaOWmjaoq8Z9h6hRn8fVuU0Tnd3q5MB3aIO8Zas19bmRuvvLMbrri/8p+/clsjyesusnP/68hmZ21K/vf65Od98QxlIA4eB2mYj8CpdAP0FFH/bfd0jqalnWcEndJPl9s7Qx5g5jzFxjzNwlqvhpdkcqyM5TYr20sssJGakqyK745Lwy0HZsudt2KT05ruxyalIN5eb7ns2QV7BLtz4/Rd0eGaunPvhZkrR99/6jtlm2Pl9nNktTKKQkJ/qcvZCbX6A6yf7fVtCzUztN+6Xk7RpRbrcG3dZPn/5zqF4ffI927NyjzLTQTY735m1R1bqHfpNTtW4d7c37428HcMfGqs2ol7XypddV9PvCkHVJJWc+1DrszIfk2BjlH3ZmxOE6Nayl71dv9fneR79l675PFmjIF0tljFF20d7j6tmZk6e4jEPPVY20FO3c5Pva3pWTpxoZJb/FMm63qtSM095tBfLsL9bebSW/xds8f7GK1q5XQqOTVLv0rTZFa0ve1rLikylKO/P04+oMxKl/fzi1S7K/bWdOnuIO+w1rjfS62pHju7+dm/IUd/hrLT5Oe/OPfq0Vrl2vxEa+67x49u3XqsnT1KiX71s8Qo1jGhyntoWza9OWQqXXOfSWuvQ6Cdq0pchnm5yt29X/b2+pw43PatgbJYP8op171KdzS81evE679uzXrj379fXPS3Xmqb5/Jv6Iwuxcn7MUEtLrquiwM5YkqWhTXtk2LrdbVePjtCu/QEXZuUrMOOy2GakqLL3tz6M/0nPt++iV86/W7oIibV6x9qh9z33/c7W67KIKNwfi1Nea5Nw2p3ZJtAGBBBpCuIwxicaYZEnGsqwtkmRZ1i5JB/zdyLKsUZZltbUsq21zxfnb7A/LmvO76jTOVHJmhtzR0WrXr7cWTPjmuO83FGg7tvmr8nRSarzq1YlTdJRLfTs21ldzff8xT4qrenC5BQ24tI0+nLFEkpSaFKuqMSULF8bHVlH7pmlavalQoXBq40xl5eRpY94W7S8+oCk/zNb57Vv5bLPusB9mv5u7QA1SS94SsWffPu3eW/KD90/zF8vtdqlR/dAMRyRp+8LFqp5ZT9Uy0mSio5Taq7s2T/vuD93WREfp9H+9oE2fTS77xIxQWrllp9LiqyolroqiXEbnNqyl2VlHvxUlI76qalRxa1neoffPuowUV6Xkg3gyk6orM6m6ftt4fMcz79eFSjg5UzUbZMgVHa0ml/fSmi+m+2yz5ovpat7/UklS40u6a8N3JYOuasmJMqVnsNTMzFBCw0wVrdugnZvylNS0oaqVDqXqd+mobctXH1dnIE79+8OpXZL9bbm/LlRCw0OvtaaX99Kayb5/xlZ/MV3Nryl5rTW55CKt/26WJKlarUOvtfjMekosfa1Fx1ZXbEptSSVDi5O7n6dtK9ZU2mOQOKbBcmpbOLt+XbpejerVVoPUJEVHuXXFhWdo8g++g+/k+NiSdXYkPXxDV42ZVPL374bcAp1zeiO53S5FuV065/SGQb0dY/2cBardKFNJpY//jKt7a+FE30/oWDRhqtrfcLkkqfUVPbRyRsmfy4UTp+qMq3srKiZGSZkZqt0oU1mzf5ck1aidLElKrJemVpdepF8/+FySVLtRZtn9ntanqzYvD/2fV6e+1iTntjm1S6INCCTQR3TGS/pVkpFkGWNSLcvKMcbUKP2eLbwej8beM0QDvhojl9utn0Z/pJwlK+3afbloOzaP19Jjb32vDwb3ldtl9OGMJVqxcZsevrq9fl+9WV/PXacOLdL12DUdZFnSz0uz9dibJT9wN85I0tAbOsqyStaEHDnxNy1bf/wf6SiVnM0w+I5rdPuwf8rr9erSCzqqcf10vfreZ2rRKFNdzmyt9ydP16zflyoqyq342Op68v5bJEnbCnfo9mEvyeUyqpOUqKcfuC0kTQdZHo+WjnhGbd56XcbtUvb4Cdq1ao0aDbhTRYuWaMv071XztOY6/fUXFFWzpmqff64aDbhTM3tdqbo9uimx7emKTohX2mUlq5AvGjRUO5auCEmb15JGzlyr4T2ayeUymrp8s9YX7NG1bepp5dadZQOJTo1q6YfVvsfK7TJ6uk8LSdLu/R69MGNl2Vs1gmV5PPr24RG65NM3ZdxuLXnnY21btkpnDR6gvHmLtHbKdC0eM17dRz2nG+d/rb0FRZpy8wOSpPSO7XTW4AHyFh+Q5fVq+v1Dta+gSPsk/fL067riy/fkLT6g7Ruy9c1dfzu+0ACc+veHU7sk+9ssj0czBo7Q5Z+9JeNya9E745W/bJXOHjxAub8t0povpmvRmHHq8Z/ndMv8b7S3oEiTS19rGWe3U4f/u6/stTb1/iHaW1Ck6rWT1XfsSLmrRMu4XNrw/S/6/a0PKu0xSBzTYDm1Laz/vnu8evCF8Zrwz7/K7XJpzKSftXRtrh6/vafmLV2vyT8uUqczGmvEXRfLsqSZ81fr/ufHSZI+nTFf57VtojnvDpJlSd/8vFRf/Liowg1ej0fjBwzVX6eMkcvt0s//HafcJSvVc9gDWv/rQi2aOFWzRo/V9WNe0uPLZ2j3tiK9fc29kqTcJSv127jJemzR1/Ic8GjcvUPKPh731nH/VmxygjzFBzTu3iHaU1RyNm/vpx5RnSYny/JaKlifrbF3DQ7Rs+n7mJz4WpOc2+bULok2IBATzIrcxpjqklIsyzr6PLUj3Gkyw/fmb4Tc51cMDLxRmGx8olXgjcJkap/7wp3g12sDXw93wjFdOPCmcCf4tXTHsd+KghNXkxrHt1hqZVqxc3/gjYAQGHNWn3An+HXb7InhTjim/cc7VQcixEhrXfgWGLDBHR/Nj8g/7KOuah2W4xboTIhjsixrt6SAAwgAAAAAAICDnLW0PwAAAAAAiFgMIQAAAAAAgC0YQgAAAAAAAFsEtSYEAAAAAAB/Bm5XRK+7aTvOhAAAAAAAALZgCAEAAAAAAGzBEAIAAAAAANiCNSEAAAAAAPDDbVgTIpQ4EwIAAAAAANiCIQQAAAAAALAFQwgAAAAAAGAL1oQAAAAAAMAPt4s1IUKJMyEAAAAAAIAtGEIAAAAAAABbMIQAAAAAAAC2YE0IAAAAAAD8YE2I0OJMCAAAAAAAYAuGEAAAAAAAwBa8HQMV0nf88+FO8Gv8d9XDneDXjC27w53gV0HB3nAnHNPSHfvCnYA/kRU794c7ASHUMblauBP8mpm/J9wJft3w84RwJ/jFn1AAiBycCQEAAAAAAGzBmRAAAAAAAPgRxcKUIcWZEAAAAAAAwBYMIQAAAAAAgC0YQgAAAAAAAFuwJgQAAAAAAH64WRMipDgTAgAAAAAA2IIhBAAAAAAAsAVDCAAAAAAAYAvWhAAAAAAAwA/WhAgtzoQAAAAAAAC2YAgBAAAAAABswRACAAAAAADYgjUhAAAAAADwgzUhQoszIQAAAAAAgC0YQgAAAAAAAFswhAAAAAAAALZgCAEAAAAAAGxxwgwhmnfvrGHLpmnEym/V/dG7wp3jg7bg2NlW9/xz1OOnyer5y5dqeu9tR13violWh1EvqOcvX+rCKR+qer00SZKJilL7V59U928/U48fJ6rZgNslSXENM9Vt+idlX//P3n1HR1E9bBz/zm4KLYWahAQS6R2ki4CAdEgQBRUb2LHhz4ZYkGLvBQuvIlZUEETpIAHFQpUamrQESKOlQRJImfePxJANhJCQzK7x+ZyTQzZzZ+4zc3d22Lt37l67bx2N7rm1TPcBnNuenS6rxjd3deK7ezpxS6e65yz38/LkvRvbMH1Uez6/vQOd61UDoH1IVT4d2Z4v7ujApyPb07aur6W5QedBSbhqLlC2klK286vdqythaxYxZN0Smo85//Wh27S3GLJuCQOWfkflfNeHLu+/zOBVPxH25wJaPHx3ieovat/dPDy467v3mbznF55c8yPVg4PylvUbdz+T9/zCxF3hNOvbPe/vt376Gq/Fb2D8tqUO2wqd/CjPblnMM5sWMWbpl/gE1CpR5kvdJ2dStpJx1WyumguUrbyx24xy+eMs/4pOCMNmY8QHk3l/wCgmNetDhxFhBDRt4OxYgLKVlJXZDJuNdq8+y6oR97KkayjB1w7Eu1F9hzL1br6OM0nJLOrUn93/9wWtxz8GQJ2wftg9PFja4xqW9RlO/duup1Kd2qTsi2RZr2tZ1utafu49jMy0dA4vCi+T/Pn3w1ntaTPg0T6NePz7LdwybR29m/kRUr2SQ5mRXUJYsesId3y+gYnztvNY30YAJKVmMHbOVkZOX88LC3cyfnAzSzL/Q+dB+ckFylZSylZ43R1fHc+KG+5h/pWhhFw7CJ8C14cGNw/jTGISP3Xsz86pX9J2wuMABA/ph93TgwXdh7Dw6mE0HHlDXgdFceovat+vvPN6UhOSeK5hD8Lf/pShr44DIKBpAzrcGMrk5n2Z0n8kIz58HsOW89+61Z/PZkr/kefU9/PrH/NC6wG8ePlAti1YwaDnHi5W3tLaJ2dRtpJx1WyumguUTaQo/4pOiJCObTiyN4pjBw6RlZHB+u/m02pIX2fHApStpKzMVq1tS1IOHORU1GGyMzI4OHcxgf17OZSp3b8XkTN/BODw/GX4deucs8A0sVeqiGG3Y6/gSXZGBpkppxzWrdW9M6ciD5J6OKZM8v/Dme3ZNMCbw4lpxCSlk5ltsnxnPF0b1nAoY2JS2TPnW38re7px7OQZAPYcOcnx3N8PHDuFp5sNd7t1Pa86D8pPLlC2klK286vethUpBw5yMvf6EDV3EXUGOF4f6gzoxb7vfgIgat5S/PNdH9zyrg8VyM7IIKPA9aEoF7PvrYb0ZfUXcwDYOHsRTa7ukvf39d/NJ/PMGY5HHubI3ihCOrYBYO9v60g9kXROfekpJ/N+96hcCdM0i5W3tPbJWZStZFw1m6vmAmUTKcoFOyEMw+hkGIZ37u8VDcOYZBjGfMMwXjUMw8eaiFA10I+EQ2ff4CUejqVqoJ9V1V+QspWMldkq+vuRFh2X9zg1No6KBYagVvL3IzW3jJmVRUZKCh7VfDk0Zp6MQgAAIABJREFUfxlZqWmEbfuV0I3h7PrwM84kOv7Hru41A4n6YVGZZM/Pme1Z08uTI8npeY+PppymZhVPhzLTf4+kb3M/frj/Ct4Y3op3fv77nO30aFyTv+NTyMgq/f/4FkbnQfG5ai5QtpJStvOrFFCLUzFnrw+nYuKpGOBXoIwfqdGxQO71ITkFz2q+RM1bRmZqGsO2r+K6zeHs+GD6OdeHolzMvvvmK5OdlUVaUgqVq1ct8XEb8sLjvHTwTzrePIT5z71VrLwXQ8+1klG24nPVXKBsIkUpaiTEdCA19/d3AR/g1dy/fVaGuURcQvW2LTGzs5nXqgcLOvSl8X2jqJzvflybuzuB/XpyaP7SC2zlv6F3Mz8Wb4vj2g9X8/j3W3l2cDPyj3e4rEYl7ruqPq8t3e20jCIipaVG25aYWVnMbnEVc9v1oen9t1Ml3/XBVf307Bs8XbcL62b8RI8Hz71lQ0REzuXsuRv+a3NC2EzTzMz9vb1pmv8zTfN30zQnAfUKW8kwjHsMw9hgGMaGHaRccsiE6Hiq5rvP0jcogITo+EvebmlQtpKxMltaXDwVA/3zHlcK8Cct9ohDmdS4eCrlljHsdty9vDhzIpG61w4idsVvmJmZnD52gmPrNlGtdYu89fyv7kbCth2cPnq8TLLn58z2PJpymlreFfIe1/Ty5OjJ0w5lBrcKYMWunOO6PSYZTzcbPpXc88q/NLQlLyzcSUxiOlbSeVB8rpoLlK2klO38UmOPULn22etD5dp+pMXGFygTT6XAACD3+uDtxekTiVx23WCiw3/HzMwk/dgJjq7dSPU2LSiOi9n3xHxlbHY7FX28OHU84ZKP27oZP3L5df2Llfdi6LlWMspWfK6aC5RNpChFdUJEGIZxe+7vWwzDaA9gGEYjIKOwlUzT/Ng0zfamabZvhtclh4xav4VaDUOoHhKE3d2dDjeGsnXez5e83dKgbCVjZbYTmyLwqhdM5bqB2NzdqTt0ANFLVzqUiVm6kpAbrgEgKLQv8b+vBSA1Oha/rjn3/9orVaR6u9Yk792ft17w0IEctOBWDHBue+6KTaFO1YoE+FTAzWbQu6kff+w95lAmPjmddsFVAQiuXgkPu43E1AyqeLrx+rBWfPTrPrZFF2+ocmnQeVB+coGylZSynd/xTdvwqhdMldzrQ/DQgRxa4nh9OLRkJfVvHAJAcFg/4n5bA8Cpw7H4d+sEgFulitRo35qkPfspjovZ963zfuaKkdcB0HbYQHav+DPv7x1uDMXNw4PqIUHUahhC5LrNF6yvVoOQvN9bD+lD/K59xcp7MfRcKxllKz+5QNlEiuJWxPK7gHcNw3gWOAasNgzjEHAod5klsrOymPngc4xZ+iU2u50/p88idsceq6q/IGUrGSuzmVlZbBz3IlfN/ATDbmP/N3NJ3r2XFk8+yInN24lZupL9M+bQ+YNXGbh2CWcSEll9b87s53unf0vHd1+k/6p5YBgc+G4uSTty5jqwV6qI31Vd2PD4xDLJXZAz2zPLNHnr57956/rW2AyDhdtiOXAslTu7XsauuGT+2Huc91fsZWz/JtzQoQ6mafLiop0AXNc2kEDfitzeJYTbu4QA8MisLSSmFtqPWap0HpSfXKBsJaVs52dmZbFu3Atc/f00DJuNvd/8QNLuvbQe9xDHN0dweMlK9s6YTdcPX2XIuiWcSUzit7tzvj1p9/Rv6PLei4T+Ph8M2PftXBJ3nDsXzoUUtu+hkx4hasM2ts5fzh+fzuL2r95i8p5fSD2RyLQbHwIgdsce/pq1gAk7fiYrM5PvHngOMzsbgDu/eY9GPTpTpUZVXj60mvkT3ubP6bO45pUn8WtcDzM7mxNR0Xwz+pnSPaAX2CdXoGwl46rZXDUXKJtIUYyLmRk5d3LKy8jptDhsmuZFj9kZbYRYNwOd/Kf1rFmp6EJOsvJoatGFnCTiFdec3qXFuNuLLiQich5XVq/o7AiF+uN4mrMjiIiUuqlmpPMmGLDAKyv3lMv3tON6NnRKuxU1EgIA0zSTgS1lnEVEREREREREyrGi5oQQERERERERESkV6oQQEREREREREUtc1O0YIiIiIiIiIv9Fdlu5nvLCchoJISIiIiIiIiKWUCeEiIiIiIiIiFhCnRAiIiIiIiIiYgl1QoiIiIiIiIiIJTQxpYiIiIiIiEghNDFl6dJICBERERERERGxhDohRERERERERMQS6oQQEREREREREUtoTggRERERERGRQmhOiNKlkRAiIiIiIiIiYgl1QoiIiIiIiIiIJdQJISIiIiIiIiKW0JwQIiIiIiIiIoXQnBClSyMhRERERERERMQS6oQQEREREREREUvodgwpFv8KrvuUWXk01dkR/pVajLvd2RHO69ueNzk7QqFGrPzG2RGklHm48DDLM9mmsyOc100dazs7QqG+WRfj7AgiIiJSCNd9RykiIiIiIiLiZHbDdT+s+DfS7RgiIiIiIiIiYgl1QoiIiIiIiIiIJdQJISIiIiIiIiKWUCeEiIiIiIiIiFhCE1OKiIiIiIiIFMKmiSlLlUZCiIiIiIiIiIgl1AkhIiIiIiIiIpZQJ4SIiIiIiIiIWEJzQoiIiIiIiIgUwq4pIUqVRkKIiIiIiIiIiCXUCSEiIiIiIiIillAnhIiIiIiIiIhYQnNCiIiIiIiIiBTCZtOkEKVJIyFERERERERExBLqhBARERERERERS6gTQkREREREREQsoTkhRERERERERAphNzQnRGnSSAgRERERERERscS/phOiWb+rmLgrnMl7fqHfk/c5O44DZTurQZ/uPLhlGWMiwun6+L3nLLd7eDDsq3cZExHOXatm41s3EIDA9q0YvWZezs/a+TQJ6wOAm6cHd/82h9Fr53P/X4vp8ezDZb4PVhyzoupw8/Dgru/eZ/KeX3hyzY9UDw7KW9Zv3P1M3vMLE3eF06xvdwCqBgXwyIpvmbD9Z56LWEavMbefs83ej97FVDOSytWrOmWfytLVHRqy4YtH2PTVYzwyovs5y+v4+TLvjTv545OHWPDWXdSu4Q1Atzb1+O3jB/N+4pdMYtCVTS3N7qqvH66aC6zP1rRfd57ZEc743SvpPXb0OcvdPDwY9e0Uxu9eyaN/zqVacM7rWqVqvjy0/BteT4pg2HuTHNYZ9PzjTIr8g9eTIso8/z+c2aZVO3ei/axv6TB7FnVuu/Wc5T5t2nD5F5/R7Y9V1OjV85zl9sqV6DT/R+o//qgVcR246rngqrlA2UpK2YrPVXOBsolcyL+iE8Kw2RjxwWTeHzCKSc360GFEGAFNGzg7FqBsBesb+M5EZgy5kw8u70+L4YOp2cSxvrajhpOekMR7La5mzZTP6P3iWACObP+bj68cytTOYXw95A5Cp7yAzW4n8/QZvuh/K1M7hTK1UygN+nYjqGObMt2Hsj5mF1PHlXdeT2pCEs817EH4258y9NVxAAQ0bUCHG0OZ3LwvU/qPZMSHz2PYbGRlZjL7sReY1LwPr3YeylUP3OqwzapBATTt253jUYdLdV+Ks09lxWYzePPhMIaN+5yOt7/Ddb1a0zi4lkOZF0YP4NtlG7ny7im89tUKJtzdD4DfNu+n2z3v0+2e9wl77FPS0jNYsWGvJbnBdV8/XDUXOOd1bfiUyUwdNIqXWvSl3Y1h+Beor/MdOefr84178su7nxL2Ss75mpl+moUT3uLHsS+ds93tC5bzZudryix3QU5tU5uNBk88TsT/HmPDjTdRs29vKl0W4lAkPT6Ov59/gSPLfj7vJkLuvYekTZvLPmsBrnouuGouULaSUrbykwuUTaQoF+yEMAxjjGEYdawKU5iQjm04sjeKYwcOkZWRwfrv5tNqSF9nxwKULb/ADq05sS+KhMic+iK+X0jjwb0dyjQe3JvNM+YCsOOHJdTrcQUAGWnpZGdlAeDm6YlpmnnrnDmVCoDd3Q27m7vDstJmxTG7mDpaDenL6i/mALBx9iKaXN0l7+/rv5tP5pkzHI88zJG9UYR0bENy3FEObdoOwOmTp4jbuQ/fQP+87Q1/ezw/jH0ZyujQOfM8aNckiP3Rx4mMTSAjM4sfVmxlUBfH0QyNg2uxatN+AFZt2s/ALueOdhjSvQU/r/ubtNMZluQG1339cNVcYH224I6tOboviuO59W2cOZ+WuSO1/tFySB/WfZlzvm6evZhGvXLO1zOpaez/YwMZ6afP2W7k2s0kxx0ts9wFObNNvZo1I+3wYdJjYjAzMzn683Kqd+/mUOZ0bByn9u7DzM4+Z/0qTRrjXq0aCWvXWZI3P1c9F1w1FyhbSSlb+ckFyiZSlKJGQjwPrDUM4zfDMO43DKOmFaEKqhroR8KhmLzHiYdjqRro54wo51C2s7xr+5F8ODbvcXJ0HN4F6stfJjsri/Tkk1TKvT0gsENr7v9rMfdvWMiCMePzOiUMm43Ra+bxxMG17FvxO9Hrt5TZPlhxzC6mDt98ZbKzskhLSqFy9aoXtW714CDqXN6MA2tzPjVsHdaHxOh4orfuLNX9yM+Z50HtGj5EH0nKexx9LImAmt4OZSL2xRHarTkAod2a4125AlW9KzqUua5XK2avKLvn1vm46uuHq+YC67P5BvqTeOjs61pidBw++Tr4AHxq++WVyc7KIj33fHUlzmxTz1o1OR0fn/f49JGjeNS8yP9OGAb1xjzE/vemlFG6C3PVc8FVc4GylZSyFZ+r5gJlK49shlEuf5x2PItYvh8IIqczoh2wwzCMJYZhjDQMw6uwlQzDuMcwjA2GYWzYQUopxpXyLHr9Fj5sN4CPu15LtydG4+bpAYCZnc3UzmG81aArge1bU6tZQycndV2elStxz5yPmPW/yaSnnMS9YgX6P/0A8557y9nRnOrZqYvo2voyfvu/B7my1WVEH00iO+vssBC/al40u8yf8PV7nJhSRAqqfd21nPhzNWeOWDdqRERERMpWUV/RaZqmmQ0sA5YZhuEODABGAG8A5/0owzTNj4GPAUYbIZc8ADwhOp6qdWrnPfYNCiAhOv4Ca1hH2c5KjonHOygg77F3oD/JBer7p0xydBw2u50K3lVIPZ7gUObY7n2cOZlKreaNiNl4dtK29KQUIn9dQ4O+3Tmyo2zeLFpxzC6mjsTcMom5x6mijxenjidccF2bmxv3zJnKuhk/snnuUgBq1g+m+mVBjN+yOLe8P89sXMArHa8hOb70/lPvzPMg5lgSgbV88h4H1vAh9miyQ5m44yncMmEGAJUreBDWvTlJp9Lzlg/t0ZIFv28nM+vcoeBlyVVfP1w1F1ifLTE6Dt86Z1/XfAP9SYqOcyiTFBOPb52AvPO1Qu756kqc2aanjxzF0+/sp2yetWpy5ujFvf54t2yBd5vW1L7uWuyVKmK4u5OVmkbkhx+VVVwHrnouuGouULaSUrbic9VcoGwiRSlqJITDGA3TNDNM05xnmuYIILjsYjmKWr+FWg1DqB4ShN3dnQ43hrJ13vknr7Kasp0Vs2Er1RsE4xucU1+L4YPYvTDcoczuheG0uXkoAM2u7c+BX9cA4BschM1uB8Cnbm1qNK5HYlQ0lWpUo4JPzqAbtwqe1Lv6So7t3l9m+2DFMbuYOrbO+5krRl4HQNthA9m94s+8v3e4MRQ3Dw+qhwRRq2EIketybru47dNXidu5l/C3P83bTkzEbsb6teeZy7ryzGVdSTwcx4ttB5dqB8TF7lNZ2bgrmvqBNQj2r4q7m51re7Vi0WrHW0+qeVfCyB1y9uhNV/H14r8clg/r1YrZK7Zakjc/V339cNVcYH22g+u3UrNBCNVy62t7Qyjb5i93KBMxbzkdb8s5X9sMG8CelavLLE9JObNNU3bupGKdICoEBGC4uVGzT2+Or/r9otbdNWES64Zcy7qh17H/vfeJX7TYsg4IcN1zwVVzgbKVlLKVn1ygbCJFKWokxA2FLTBNM7WUsxQqOyuLmQ8+x5ilX2Kz2/lz+ixiy+iT8OJSNsf6Fj0yiVvnf4Zht7Ppi+85unMPPcc/TMzGCHYvDGfT57MYOv1NxkSEk5aQyOxb/wdA3S7t6fr4vWRnZGBmmyx8eAKpxxPwa9GYaz55HZvdhmGzsX3OIv5evLJM96Gsj1lhdYROeoSoDdvYOn85f3w6i9u/eovJe34h9UQi0258CIDYHXv4a9YCJuz4mazMTL574DnM7GzqX9mezrddx+GtO3lm0yIAfnr6NSIW/1Kq2Yu7T1bIys7m8Snz+OHV27HbDb5e/Be7Io/w9KjebPr7MIv/3EW3NvWYcFdfTBP+3HqAx96bl7d+XT9fAmv58PuWA5bkzc9VXz9cNRc453Vt9pgJ3L/4S2x2G2s++564HXsYOPERDv61jYj5y1k9fSa3fvk243evJPVEEp/f9FDe+hP2/UYF7yq4ebjTakgfPux/G3E79xL2yjjajwjDvVJFJkf9yepPZ7J48rtluh9Oa9OsLPa+8RYt3nsbw2Ynbv4CUg8cIPieu0jZuYsTv/1OlaZNaf7ay7h5eVG9W1eC776Tv0bcYk2+C3DVc8FVc4GylZSylZ9coGzlkd150yeUS0ZZftMAlM7tGOI6/CsU1W/lPHHpmc6OIKXo2543OTtCoUas/MbZEaSUedhc938XZ7Jd8zJ6U8faRRdykm/WxRRdSERESs1UM9J1L6Sl4JtNh13zYnyJbro8yCntVtTtGCIiIiIiIiIipUKdECIiIiIiIiJiCdcdWy8iIiIiIiLiZDYXvm3z30gjIURERERERETEEuqEEBERERERERFLqBNCRERERERERCyhOSFERERERERECmEzNCdEadJICBERERERERGxhDohRERERERERMQS6oQQEREREREREUuoE0JERERERERELKGJKUVEREREREQKYde8lKVKIyFERERERERExBLqhBARERERERERS6gTQkREREREREQsoTkhRERERERERAphMzQpRGnSSAgRERERERERsYQ6IURERERERETEErodQ4olLj3T2REKFVLJ3dkRChWZmuHsCP86I1Z+4+wIhfqyc5izIxTqtjXznB3hX+lMtunsCIWq4uaanxd8sy7G2RFERETkX0idECIiIiIiIiKFsNs0J0Rpcs2PV0RERERERESk3FEnhIiIiIiIiIhYQp0QIiIiIiIiImIJzQkhIiIiIiIiUgiboTkhSpNGQoiIiIiIiIiIJdQJISIiIiIiIiKWUCeEiIiIiIiIiFhCnRAiIiIiIiIiYglNTCkiIiIiIiJSCLvmpSxVGgkhIiIiIiIiIpZQJ4SIiIiIiIiIWEKdECIiIiIiIiJiCc0JISIiIiIiIlIIm6FJIUqTRkKIiIiIiIiIiCXUCSEiIiIiIiIillAnhIiIiIiIiIhYQnNCiIiIiIiIiBTCbtOcEKVJIyFERERERERExBL/mk6IZv2uYuKucCbv+YV+T97n7DgOlK1krMx2WZ9u3L1pKfduXU7nx+45Z7ndw4MhX7zDvVuXc9svs/GpG+iw3DsogEfjN9Px4Ttzynt6cNuvs7ljzTzuXL+Irs+MKdP8/1B7lowzs/Xp3JTN3z3Dtu/H89itvc9ZXse/KgunPMDar55kyQcPEVjTN2/ZCw+EsWHGU2z89mneeOQ6K2OrPUvI6myN+3ZnbMRyxu1cQc8nRp+z3O7hwS0z3mPczhWM+eMHqgbnvLZVqubL6J9n8GLCNoa+O9FxHXd3hn30Ik9uD2fstp9pObR/me+H2rT4XDUXKFtJKVvxuWouUDaRC/lXdEIYNhsjPpjM+wNGMalZHzqMCCOgaQNnxwKUraSszGbYbPR9ayKzht7FJ+0G0Gz4YKo3cayr1chhpCcm83+terP+/c/o8fwTDst7vfI0+5etynucdfoM3w68jemdw/jsijDq9elO7Q5tyiR//v1QexafM7PZbAZvPzacax6dStsRLzG8TzuahPg7lHn5oWv4ZvF6Ot36Ki9PX8Kk+0IB6NTyMq5oVY+Ot75C+5tfpl3TunS73Jrcas+SsTqbYbMx9L1JTAu9nddb9ePyG0PxK1BfpzuuJy0xmVea9mLVu9MZ9NKTAGSmn2bJxLdZ8OTL52z36qce4OSR47za/Gpeb9WXfavWltk+/LMfatPykQuUraSUrfzkAmUTKcoFOyEMw/AwDOM2wzB65z6+yTCM9w3DeMAwDHdrIkJIxzYc2RvFsQOHyMrIYP1382k1pK9V1V+QspWMldkC2rciYX8USZGHyM7IYMfshTQcfLVDmYaDe7Ntxg8A7Jq7hOAeVzgsS4o6zLGdexzWyTiVCoDN3Q2buxumaZZJ/n+oPUvGmdnaNwtm3+GjRMYcJyMzi9nLNzK4e0uHMk1C/Pllw98A/PrXnrzlpmlSwcMdD3c3PN3dcHezc+REiiW51Z4lY3W2uh1bc3xfFCdy69s8cwHNQ/s4lGke2psNX80BYOucxTTs1QWAM6lpRP6xgYz00+dst+OoYax49SMg53mYejyhzPYB1KblKRcoW0kpW/nJBcpWHtmM8vnjtONZxPLPgEHAw4ZhfAUMB9YCHYBpZZwtT9VAPxIOxeQ9TjwcS9VAP6uqvyBlKxkrs3nV9iflcGze45ToOLwC/AqU8SPlcBwAZlYWp5NPUrF6VdwrV6Lzo/fw+0tTztmuYbNx++p5jIlcQ+SKP4jdsKVM8v9D7VkyzsxWu6Yv0UcS8x5HH0mkdk0fhzLb9kYzpEdrAIZc1QrvyhWo5l2JdRGR/Lrxb/bPf579C15g+dqd7I6KtyS32rNkrM7mU9ufxHyvbYnRsfgUqM+nth+Jh3LKZGdlkZaUQqXqVQvdZgUfLwD6TXqU/62bx63fvk+VWjXKIP1ZatPic9VcoGwlpWzF56q5QNlEilJUJ0RL0zRvAIYCfYFhpml+BdwOXF7YSoZh3GMYxgbDMDbswJpP7kTKQtdnHmL9+5/ljXrIz8zO5rMrwvigUTcC2rWiRrOGTkgo/3ZPT/mRbpc3YPUXY+l6eQOijySSlW1SL6gGTYL9aTjkORqEjeeqdo3o0rqes+NKOWdzc8O3Tm2iVm/knY5hRK3dROhrTzk7loiIiJQjRX1Fp80wDA+gMlAJ8AFOAJ5AobdjmKb5MfAxwGgj5JLHqCdEx1O1Tu28x75BASREW/OJYFGUrWSszJYSE4dXUEDeY69Af1Ji4wuUiccryJ+UmDgMux1P7yqkHU+gdvvWNLmmPz1fGIunjzdmdjaZ6afZ+H9f5617OimFg6vWUq9Pd47tcLxlozSpPUvGmdlijiYSWOvsRJOBtXyJOZrkUCb2WDIjnvoUgMoVPbimZxuSTqZx+5ArWLc9klNpZwBYtmYnnVpcxp9b9pd5brVnyVidLSkmDt98r22+gQEkFagvKSYe3zoBJEXHYbPbqejjdcHbK1KPJ3DmVCrb5i4BYMvsRXQcNbxsdiCX2rT4XDUXKFtJKVvxuWouUDaRohQ1EuJTYBewGXgG+N4wjE+A9cB3ZZwtT9T6LdRqGEL1kCDs7u50uDGUrfN+tqr6C1K2krEyW+xf26hWPwSf4CBs7u40GzaIvQvDHcrsXRhOy5uvBaDJ0P5E/boGgBl9b+KjZj35qFlPNnzwOavfmMrG//uaijWq4Zk7bNmtgichvbpwfHfZvjlUe5aMM7P9tfMgDerUJDigGu5udob1bsvC37Y5lKnuUxnDyLkp74nb+vDlgpzn3qG4BLpe3gC73Yab3UbXy+tbdjuG2rNkrM52aP1WajQIoVpufW1uGMz2BcsdymxfEE77W3O+WaXVdQPYu3J1kdvdviCc+ld1BqBhry7E79xb+uHzUZuWn1ygbCWlbOUnFyibSFEuOBLCNM23DcOYmft7jGEYXwK9gU9M01xnRUDIuY915oPPMWbpl9jsdv6cPovYMvzEuTiUrWSszGZmZbHssUnc8NN0DLudrV/O5tjOvXR79mFiN25j76IVbPnie0KnvcG9W5eTlpDITyMfueA2q/jXZPDHr2HYbRg2G7vmLGbfkpVlkv8fas+ScWa2rKxsHn1zNvPeuR+7zcaXC9aw80Ac4+8eyMadB1n4ewTd2jZk8n2DMU34Y/M+/vfG9wDMXbmZHu0bsf7rcZgm/LxmJ4t+j7Akt9qzZKzOlp2VxdyHJ3L3wi8w7DbWf/498Tv20G/C/zj01zZ2LAhn3fSZjPj8LcbtXEFqQhJf33z264Sf3rOKCt5VsHu40zysD58MHEn8zr0sevpVRnz+FmFvjefU0RPMvGtsme3DP/uhNi0fuUDZSkrZyk8uULbyyG44cRbHcsgo6xn9S+N2DJGLEVLJsi9sKbbI1AxnR5BS9GXnMGdHKNRta+Y5O4KUsipurvlt2iczs50dQUREXMRUM7Jcv0v/dd+xcvme9qr6NZzSbq75PxsRERERERERKXfUCSEiIiIiIiIilijq2zFERERERERE/rNsmhOiVGkkhIiIiIiIiIhYQp0QIiIiIiIiImIJdUKIiIiIiIiIiCU0J4SIiIiIiIhIIez66L5U6XCKiIiIiIiIiCXUCSEiIiIiIiIillAnhIiIiIiIiIhYQnNCiIiIiIiIiBTCZhjOjlCuaCSEiIiIiIiIiFhCnRAiIiIiIiIiYgl1QoiIiIiIiIiIJdQJISIiIiIiIiKW0MSUIiIiIiIiIoWwa2LKUqWRECIiIiIiIiJiCXVCiIiIiIiIiIgl1AkhIiIiIiIiIpbQnBBSLP4V9JQRa1Rxc90+0tvWzHN2hEKtfPAdZ0coVL8PH3F2hEKdyTadHaFQrpxNypemXp7OjlConSmnnR1BRP7DbJoTolS57v/yRURERERERKRcUSeEiIiIiIiIiFhCnRAiIiIiIiIiYgnd4C8iIiIiIiJSCLs+ui9VOpwiIiIiIiIiYgl1QoiIiIiIiIjIOQzD6G8Yxm7DMPYahjGukDLXG4axwzCM7YZhfFPUNnXRxfDVAAAgAElEQVQ7hoiIiIiIiIg4MAzDDnwA9AEOA+sNw5hnmuaOfGUaAk8BV5qmmWAYRq2itqtOCBEREREREZFC2AzD2RGcpSOw1zTN/QCGYXwHDAF25CtzN/CBaZoJAKZpHilqo7odQ0REREREROQ/xjCMewzD2JDv554CRQKBQ/keH879W36NgEaGYfxhGMYawzD6F1WvRkKIiIiIiIiI/MeYpvkx8PElbsYNaAj0AIKAVYZhtDRNM7GwFTQSQkREREREREQKigbq5HsclPu3/A4D80zTzDBN8wDwNzmdEoVSJ4SIiIiIiIiIFLQeaGgYxmWGYXgANwLzCpT5kZxREBiGUYOc2zP2X2ijuh1DREREREREpBD/1XkpTdPMNAzjQWApYAemm6a53TCMycAG0zTn5S7raxjGDiALeMI0zeMX2q46IURERERERETkHKZpLgIWFfjbc/l+N4FHc38uim7HEBERERERERFLqBNCRERERERERCyh2zFERERERERECmHjPzopRBnRSAgRERERERERscS/phOiWb+rmLgrnMl7fqHfk/c5O44DZTurQZ/uPLhlGWMiwun6+L3nLLd7eDDsq3cZExHOXatm41s3EIDA9q0YvWZezs/a+TQJ6wOAm6cHd/82h9Fr53P/X4vp8ezDJcp1WZ9u3L1pKfduXU7nx+45b64hX7zDvVuXc9svs/HJzfUP76AAHo3fTMeH78wp7+nBbb/O5o4187hz/SK6PjOmRLmKS8+1sxr37c7YiOWM27mCnk+MPme53cODW2a8x7idKxjzxw9UDc5p00rVfBn98wxeTNjG0Hcn5pX3rFKZRzYsyPuZFLuBsDfHl/l+OLNNuzWtxZJnr2bZc725u8+5X+ccULUiXz50JXPH9mDeuJ50b+YHgJvN4JVb2jLvqZ4seuZq7jnPuhejab/uPLMjnPG7V9J77Llt6ObhwahvpzB+90oe/XMu1YLPnpd9nryP8btX8syOcJr07Z739x4P38FTW5cybssSRs54FzdPDwBGfPIKT25cxJObFnPHrA/xqFypRJmL4sz2LOnxrFTNl4eWf8PrSREMe2+SpZn/ode24rM6V3Dvbtz21xJGbl5G+0fuPme53cOdAZ+9zcjNy7hhxSy8cq+jXnUDeSB+Czf9/iM3/f4jvd4++xxrNGwQN6+ex81/zmPID9OoUK1qme+Hq7YnKFtJuGouUDaRC/lXdEIYNhsjPpjM+wNGMalZHzqMCCOgaQNnxwKUrWB9A9+ZyIwhd/LB5f1pMXwwNZs41td21HDSE5J4r8XVrJnyGb1fHAvAke1/8/GVQ5naOYyvh9xB6JQXsNntZJ4+wxf9b2Vqp1CmdgqlQd9uBHVsU+xcfd+ayKyhd/FJuwE0Gz6Y6gVytRo5jPTEZP6vVW/Wv/8ZPZ5/wmF5r1eeZv+yVXmPs06f4duBtzG9cxifXRFGvT7dqd2heLmKS881x/qGvjeJaaG383qrflx+Yyh+BerrdMf1pCUm80rTXqx6dzqDXnoSgMz00yyZ+DYLnnzZofzpk6d4u/3gvJ+Eg9FEzF1SZvvwz344q01tBjw3vDV3fbSaQS+GM7hdEPX9vRzK3NevMYs3RTP0tV945PMNTLi+NQD9Lw/Ew81G2Msrufa1X7jhyssIrFa8N/WGzcbwKZOZOmgUL7XoS7sbw/AvsO+d77ie1IQknm/ck1/e/ZSwV8YB4N+0AW1vCOXllv34aOBIrn9/MobNhk9tP656aBRvdAzjldb9sdnttL0xFIC5j77Aq20H8urlA0g4GE33B24r6aG74D45qz0v5Xhmpp9m4YS3+HHsS5ZkLUivba6fy7DZ6PHmc/x43V181WEQjYYNplrj+g5lmt82nNOJyXzRpi+bPvicrpMez1uWeOAg33S9hm+6XsOKRybkbNNu56pXn2HOoJHM6BLGsYjdtL735jLbh3/2wxXbE5StPOUCZRMpyr+iEyKkYxuO7I3i2IFDZGVksP67+bQa0tfZsQBlyy+wQ2tO7IsiITKnvojvF9J4cG+HMo0H92bzjLkA7PhhCfV6XAFARlo62VlZALh5epLzTS85zpxKBcDu7obdzd1h2cUIaN+KhP1RJEUeIjsjgx2zF9Jw8NUOZRoO7s22GT8AsGvuEoJzc/2zLCnqMMd27nFYJyM3l83dDZu7W7FzFZeea2fV7dia4/uiOJFb3+aZC2ge2sehTPPQ3mz4ag4AW+cspmGvLgCcSU0j8o8NZKSfLnT7NRpeRpWa1dn/+/oy2wdwbpu2Cq5K1LGTHD6eSkaWycK/DnN1S3+HMqZpUqWCOwBeFdw4kpSW83dMKnq4YbcZVHC3kZGVzcn0jGLVH9yxNUf3RXE8d983zpxPyzDHNmw5pA/rvsxpw82zF9Motw1bhvVh48z5ZJ45w4nIwxzdF0Vwx5wOEpubHfeKFbDZ7bhXqkByzBEA0lNO5m3XvWIFKIPz1ZnteSnH80xqGvuLOCfKkl7bXD+XX/tWJO2PIjnyMNkZGfw9ZyH1BjleR+sN6sWOb3Ou73t+XEqdfNfR8zEMAwwD98oVAfD0qsKp2CNlswO5XLU9QdnKUy5QtvIo9yWr3P04S5GdEIZh1DMM43HDMN41DOMtwzBGG4bhbUW4f1QN9CPhUEze48TDsVQN9LMyQqGU7Szv2n4kH47Ne5wcHYd3gfryl8nOyiI9+SSVqucMvwzs0Jr7/1rM/RsWsmDM+LxOCcNmY/SaeTxxcC37VvxO9PotxcrlVduflHy5UqLj8ArwK1DGj5TDcQCYWVmcTj5JxepVca9cic6P3sPvL005Z7uGzcbtq+cxJnINkSv+IHZD8XIVl55rZ/nU9icxX5smRsfiU6A+n9p+JB46+1xLS0rJe64V5fLrB7P5+4WlF7gQzmxTP9+KxCWk5T2OT0zHz7eiQ5n3F+8itEMQv07ux8f3XcELs7cCsHRTDGlnMvn9hf6snNyP6eF7SEotXieEb6B/XvsAJEbH4RPo2AlSsA3Tk1KoXL0qPoH+JORv/8Ox+Ab6kxQTz4o3P2FS5B+8EL2W9KQUdv38W165mz59jRdi1uPXuD6/vv9FsfJeDGe256UcT2fTa1vxWZ2rSsDZayTAyZh4qtR2rK9ygB8nc8/LnOtoSt7tFT7BQYz4bS7XLfqK2le0AyA7M5OVj0zk5tXzuevv36jWpD7bv5xdZvsArtueoGwl4aq5QNlEinLBTgjDMMYAU4EKQAfAE6gDrDEMo0eZp5P/lOj1W/iw3QA+7not3Z4YnXcvt5mdzdTOYbzVoCuB7VtTq1nJ7j8via7PPMT69z/LG/WQn5mdzWdXhPFBo24EtGtFDQtzSdlqc/1gNs2c7+wYTjeoXRBz1x7iqueWcs9Hq3nt1nYYRs4oiuxsk27PLuHqicu4o1cDgqqXzRwLxVHR15uWYX2YVL87zwZ1xqNyJdrffE3e8m/uHMv4oE7E7dpL2xsGOzGpyH9HatwRpjfvybfdhvLb06/Q/9M38fCqjM3NjVZ3juDbbtcwrVE3jm3fTfvHzp1LSkREyp+iRkLcDQwwTfMFoDfQ3DTNZ4D+wNuFrWQYxj2GYWwwDGPDDlIuOWRCdDxV69TOe+wbFEBCdPwlb7c0KNtZyTHxeAcF5D32DvQnuUB9+cvY7HYqeFch9XiCQ5lju/dx5mQqtZo3cvh7elIKkb+uoUG+SeguRkpMHF75cnkF+pMSG1+gTDxeQTmfGhp2O57eVUg7nkDt9q3p+cJY7tuxkvYPjOKKx0fT9t5bHNY9nZTCwVVrqdeneLmKS8+1s5Ji4vDN16a+gQEkFagvKSYe3zpnn2sVfbzOea6dT0CrJtjc3IjeGFG6oc/DmW0an5iGf9WzIx/8fCsQn5jmUGbYFcEs3hgNwObIBDzd7VSt7MHg9kH8tvMImdkmJ06eYeP+E7Ss61us+hOj4/LaB3I+yU+KjnMoU7ANK/h4cep4AknRcVTN3/5BASRGx9G4d1eORx7i5LETZGdmsmXuUi67oq3DNs3sbDbOXEDra/sXK+/FcGZ7XsrxdDa9thWf1blOxp69RgJUqe3HyRjH+k7FxlMl97zMuY56kX4igawzGaSfSATgyObtJB04iG+Dy6jZqikASQcOAfD3D4up3enyMtsHcN32BGUrCVfNBcomUpSLmRPCLfdfT6AKgGmaBwH3wlYwTfNj0zTbm6bZvhlehRW7aFHrt1CrYQjVQ4Kwu7vT4cZQts77+ZK3WxqU7ayYDVup3iAY3+Cc+loMH8TuheEOZXYvDKfNzUMBaHZtfw78ugYA3+AgbHY7AD51a1OjcT0So6KpVKMaFXxynkNuFTypd/WVHNu9v1i5Yv/aRrX6IfgEB2Fzd6fZsEHsLZBr78JwWt58LQBNhvYnKjfXjL438VGznnzUrCcbPvic1W9MZeP/fU3FGtXwzJcrpFcXjhczV3HpuXbWofVbqdEghGq59bW5YTDbFyx3KLN9QTjtb70OgFbXDWDvytUXte3LbwizbBSEM9t028FEQmpWIah6JdztBoPaBbFim+Ob1tiENK5oXBOAen5V8HS3ceLkGWIT0ujUqAYAFT3stA6pyv74k+fUcSEH12+lZr42bHtDKNvmO7ZhxLzldLwtpw3bDBvAntw23DZ/OW1vCMXNw4NqIUHUbBBC1LotJByMIaTT5TlzPgCNenUhfuc+AGrUD87bbovQ3sTvKv3z1ZnteSnH09n02ub6ueL/2oZvvRC8c6+jja4bxP5FKxzK7F+0gmYjcq7vDa/px6Hc62jF6lUxbDn/3fQOCcK3fghJkYc4GRNPtSb1qZh7S1DdXldyYve+MtsHcN32BGUrT7lA2cojm1E+f5zFrYjl04D1hmGsBboBrwIYhlETOFHG2fJkZ2Ux88HnGLP0S2x2O39On0Xsjj1Fr2gBZXOsb9Ejk7h1/mcYdjubvvieozv30HP8w8RsjGD3wnA2fT6LodPfZExEOGkJicy+9X8A1O3Snq6P30t2RgZmtsnChyeQejwBvxaNueaT17HZbRg2G9vnLOLvxSuLlcvMymLZY5O44afpGHY7W7+czbGde+n27MPEbtzG3kUr2PLF94ROe4N7ty4nLSGRn0Y+csFtVvGvyeCPX8PIzbVrzmL2LSleruLSc82xvrkPT+TuhV9g2G2s//x74nfsod+E/3Hor23sWBDOuukzGfH5W4zbuYLUhCS+vvns16g+vWcVFbyrYPdwp3lYHz4ZOJL4nXsBaD1sINPC7iiz7AX3w1ltmpVtMvn7rUy7vwt2w2DOmij2xqUwZmATIg4msiIijlfmRvDCiDaM6lkf04RxX28EYMaq/bx8S1sWPN0LA/hh7UF2xyQXq/7srCxmj5nA/Yu/xGa3seaz74nbsYeBEx/h4F/biJi/nNXTZ3Lrl28zfvdKUk8k8flNDwEQt2MPm75fyNMRy8jKzOL7h57DzM4mat1mNs9ZzNgNC8jKzCR68w7+/ORbDMPgls/eoIJ3FTAMYrbuZNb9pf/1q85sz0s5ngAT9v1GBe8quHm402pIHz7sfxtxueeEFdn12ubaucysLH55YjLXzJ2GYbez46s5nNi1l87PjCF+YwQHFq9g+5ez6ffx64zcvIz0hCQW355zHQ28sgOdnxlDdkYmZnY2K/43gdMJSZwG1r7yAcOWzCA7I5PkQ9H8fN9TZbYP4LrtCcpWnnKBsokUxShqRn/DMJoDTYEI0zR3FbeC0UZI2X5lgFjKv0JR/VbOU8GZ3XlFiCzmpH0CVdxc98t7TmZmOztCoVY++I6zIxSq34cX7txzpjPZrnup8nDR1zZXPmZSMk29PJ0doVA7U5zz7S0icnGmmpGuebEqJbvik8vlRa+Jn7dT2q3Id5SmaW4HtluQRURERERERETKMdf9qFFEREREREREyhXXHVsvIiIiIiIi4mRGub7ZxHoaCSEiIiIiIiIillAnhIiIiIiIiIhYQp0QIiIiIiIiImIJzQkhIiIiIiIiUggbmhSiNGkkhIiIiIiIiIhYQp0QIiIiIiIiImIJdUKIiIiIiIiIiCU0J4SIiIiIiIhIIQxNCVGqNBJCRERERERERCyhTggRERERERERsYQ6IURERERERETEEpoTQkRERERERKQQNs0JUao0EkJERERERERELKFOCBERERERERGxhDohRERERERERMQS6oQQEREREREREUv8pyem9K/gmrsfl57p7Aj/SpGpGc6OIKXoZGa2syP8K/X78BFnRyjUjH53OTtCoe5a/qmzIxQqKUPngljjUJquoyIi56N5KUuXRkKIiIiIiIiIiCXUCSEiIiIiIiIillAnhIiIiIiIiIhYwjUnRRARERERERFxATZDs0KUJo2EEBERERERERFLqBNCRERERERERCyhTggRERERERERsYTmhBAREREREREphKaEKF0aCSEiIiIiIiIillAnhIiIiIiIiIhYQp0QIiIiIiIiImIJzQkhIiIiIiIiUgh9cl+6dDxFRERERERExBLqhBARERERERERS6gTQkREREREREQsoTkhRERERERERAphGIazI5QrGgkhIiIiIiIiIpZQJ4SIiIiIiIiIWEKdECIiIiIiIiJiiX9NJ0SzflcxcVc4k/f8Qr8n7yvz+hr06c6DW5YxJiKcro/fe85yu4cHw756lzER4dy1aja+dQMBCGzfitFr5uX8rJ1Pk7A+DusZNhv3rp7HTXM+LvN9gH//cXPz9ODu3+Yweu187v9rMT2efbjM98HqY1YcylYyypajab/uPLMjnPG7V9J77Ohzlrt5eDDq2ymM372SR/+cS7XgnPOzUjVfHlr+Da8nRTDsvUkO6wx6/nEmRf7B60kRpZazV7t6rP14NOun3cfDw684Z3lQLW/mvnQTqz64i59euYXa1b3ylh2Z/xS/TLmLX6bcxdfPDS+VPI36dufxiOU8sWMFPZ4497jZPTy4acZ7PLFjBQ/8/gNVc49bw6u78tCan/jfxsU8tOYn6vc4uy/9Jj/GU/t+Z/KJbaWS8WLoPCgZV81mda7GfbszNmI543auoGch58EtM95j3M4VjPnj7HlQqZovo3+ewYsJ2xj67kSHdVoPH8SjGxfx+OYlDHrpyTLfB3Dd9gRlKwlXzQXKJnIh/4pOCMNmY8QHk3l/wCgmNetDhxFhBDRtUKb1DXxnIjOG3MkHl/enxfDB1GziWF/bUcNJT0jivRZXs2bKZ/R+cSwAR7b/zcdXDmVq5zC+HnIHoVNewGa3563X+cFRHNu9t8yyF9yPf/txyzx9hi/638rUTqFM7RRKg77dCOrYpkz3wcpjVhzKVjLKdrau4VMmM3XQKF5q0Zd2N4bhX6CuzndcT2pCEs837skv735K2CvjAMhMP83CCW/x49iXztnu9gXLebPzNaWW02YzeO3+/lz/3Hd0Gf1/XHtVcxrXqeFQZvKdvZkZvo3uD0zjjW9/Y/ztPfOWpZ3JpMdD0+jx0DRumfz9JecxbDaueXcS00Nv563W/Wh9Qyi1Chy3DrdfT1pCMq8368Xv701nQO6bqVPHT/D50Lt5p+0AZt35BDd89mbeOjsXhPP+lUMvOV9x9kPnQfG5ajZnXN+HvjeJaaG383qrflx+Yyh+BerrdMf1pCUm80rTXqx6d3pep0Jm+mmWTHybBU++7FC+UjVfBr/yFP/X9xbeaNMfL/8aNOjZpcz24Z/9cMX2BGUrT7lA2cojm1E+f5x2PJ1X9cUL6diGI3ujOHbgEFkZGaz/bj6thvQts/oCO7TmxL4oEiJz6ov4fiGNB/d2KNN4cG82z5gLwI4fllAv9xOujLR0srOyAHDz9MQ0zbx1vAP9adi/Bxs/m1Vm2fMrL8ftzKlUAOzubtjd3B2WlTarj1lxKFvJKFuO4I6tOboviuO5dW2cOZ+WBUZqtRzSh3VfzgFg8+zFNOqV84bgTGoa+//YQEb66XO2G7l2M8lxR0stZ9tGtTkQc4KouEQyMrOZu2oHA65o5FCmcd0arNoSCcBvW6IY0LnRebZUOup0aM3xfVGcyD1uW2YtoFmo43FrHtqbv77KOW7b5izOeyMVs3kHKbFHAIjf/jfuFStg9/AA4OC6zaSU4nEris6DknHVbFbnqtvR8TzYPHMBzc9zHmzIPQ+2zllMw3yvH5Hnef2oXq8ux/ZGcurYCQD+Dv+DVtf2L7N9ANdtT1C28pQLlE2kKP+KToiqgX4kHIrJe5x4OJaqgX5lVp93bT+SD8fmPU6OjsO7QH35y2RnZZGefJJK1asCOW/G7/9rMfdvWMiCMePz3lz3f/1Zfn7mVczssnsTnV95OW6GzcboNfN44uBa9q34nej1W8psH6w+ZsWhbCWjbDl8A/1JPHT2/EyMjsMn0N+hjE9tv7wy2VlZpCelUDn3/LRKQHUvoo+l5D2OOZZMQL7bLQAiDsQz+MomAAzu0hivSp5U9aoIQAUPN8LfvYOlb41i4BWX3jnhE+hPYr7XtaToWHxqF3hdC/Qj6bDjcatU4Li1vHYA0Zu2k3XmzCVnKgmdByXjqtmszuVT2/E8SIyOxadAfQVfP9LOcx7kd2xvJDUbXUbV4EBsdjstwvriGxRQNjuQy1XbE5StJFw1FyibSFHcLrTQMAwf4CngGqAWYAJHgJ+AV0zTTCxkvXuAewC6UY1meJ2vWLkVvX4LH7YbQI3G9Rk67TX2Lv2Ver2u5NSR48Ru2k5It07OjuiSznfcMk+fwczOZmrnMCr4eHHDzI+o1awhR3bscXZcEXGSCdPCefW+fozo3YrVEQeJOZZMVnY2AG1GvU/s8RSC/X358eWb2XHgCJFx571UWcavWUMGvDiWaYNGOjWHiCtJS0zmhwfHc+s3U8jOziZq9Uaq16vr7FgiImKBC3ZCALOAFUAP0zTjAAzD8AdG5i4779gd0zQ/Bj4GGG2EXPLH/gnR8VStUzvvsW9QAAnR8Ze62UIlx8Tjna833jvQn+QC9f1TJjk6DpvdTgXvKqQeT3Aoc2z3Ps6cTKVW80bUuaIdjQdfTcP+V+Hm6YmndxWunf4mP9zxWJntR3k4bjEbz052l56UQuSva2jQt3uZdUJYfcyKQ9lKRtlyJEbH4Vvn7PnpG+hPUnScQ5mkmHh86wSQ+M/56ePFqQLnZ1mL/X/27jw6iirR4/jvdicICCRhC5AgUWFQlEUFdHAFWQQBR3FUGBcQdVwR54k6OoPAuM6Cy+jocxRQR5+gjgoBXAjiBmoAWYOySSQJhC1EkCCh+74/CIEEOp003VVF+/2ck3Poruqub1XRgdxU3966Q2mNDwxct2jcQBu27qiwzsZtO3Xdw/su+z62dqIGnH2Sfvzp5/LHS1Luxu36Ykmu2p/Y7IgGIYrzN1b47WxSWnMVF1T6vpZfqKT05io+6Ljt/76WlNZM17z5vCZff7e2rf0h4o4jxesgMl5tc7qruKDi6yA5rbmKK21v//eP/a+DOge9DkLJmT5bOdNnS5LOvOGq8isgY8Wr51OiLRJe7ZJoi0fGxfkT4lG4t2NkWGsf3z8AIUnW2o3W2scltYpt2gG52YvVtE2GGmWky5+YqC5XDdCSqR/FbHsF85eoUetWSm61b3un/vZifTc9q8I6303PUqff7ZtUrN1lF+n7T76UJCW3Si+fiDLpuBZq3PYEbc/NV9bov2t863P05EkX6K1rR+r7OfNiOgAhxcdxq9u4oWon7fuBJKH2MTrhwrO15bu1MdsHp49ZTdAWGdr2+SF7iZq0zlDDsm2dfuUALZ02q8I6y6bOUtdrB0mSOl3eV6s+nheTlqp8s7JAJ7RoqONSk5SY4NOl57XTzC9XVlinYYM65f8ZGHnF2Xrtw31v0UqqV1u1Evzl63Rt11Irf9hyRD1585eoUesMpZQdt45X9NeKzIrHLSczS2dcs++4tR/UV2vm7DtutZPqa+h7L2nmA39V7rwFR9RxpHgdRMarbU53rc9eosYHff/odGV/La/0OliemaXOZa+DDoP6anU1vn/Ua9JIklQnuYG63Xy1vpoQ2zmzvHo+JdriqUuiDQgn3JUQucaYeyS9bK0tlCRjTKqkoZLWx7itXDAQ0OTbR2vEB6/I5/dr7oQp2hDDy/GDgYBm3DVW10ybKOP365uX39TmFavU/c93qmDhMn03PUvfTJqiSyf8QyOWZamkaLveumakJOm4bp11zt2/V7C0VDZoNf3OB8P+JiCW+3G0H7fUU9vqN//+m3x+n4zPp+Vvz9DKmR/HdB+cPGY1QVtkaDuwrbdGPKhbZ74in9+nLye+qY05q9RvzF36YcFSLZs2S/MmTNY1rzyhP3/3sXZtK9akIXeUP/7BNZ+pdoN6SqiVqA6X9NK/LrpWG1es1sDH7lPnwQOVWLeOxuXO1byXJmvmuKci7gwEre597gO9+dBg+X0+vf7hYn33wxbdd/V5WrRqg97/apXObt9Kfx7aXVZW85at1z3Pvi9J+lXLRhp/Rz8Fg1Y+n9FTb87Vd+uPbBAiGAjovZFjNHz6y/L5fMp++U0V5qxSrwdHKm/BUq3IzFL2xMm6ctJ4jcqZrZKiYr1+9QhJUrdbr1XjE1up5wN3qOcD+47li/2u00+bt6rvo/fqtCv3Hbf7136hrydO0ay/RH7cqrMfvA5qzqttbvz7/s6dY3Tj9Jdl/D5lT9r3Oujz4EitX7BUOZlZ+nrCZA2eNF73rZitXUXF+s/vRpQ//v5Vn6p2g3ry10rUKQN76d/9rlPhitW6ZPxoteiwb36Xjx7+p7as+j5m+7B/P7x4PiXa4qlLog0Ix1T1SQPGmBRJ90m6RPvmhJCkQklTtW9OiLA/XUfj7Rix0qx2uDEYd2zcvdfthJC8eswkbx83wCm13Py8pTBe63OD2wkh3TDrJbcTQiouDbqdgF+Iegnena98515eB4CXPW/Xefc/IFGwsedKIVgAACAASURBVPgnz/5MeySaJR3rynmr8ifKskGGe8u+KjDGDJM0MUZdAAAAAAC4zrtDtEenIzmeY6NWAQAAAAAA4l64j+hcEmqRJD5QFgAAAAAAVFu4N/inSuojqfLcD0bS3JgUAQAAAACAuBRuECJTUj1r7aLKC4wxc2JSBAAAAACARxgT1/NuOi7cxJTDq1g2JPo5AAAAAAAgXjHRJwAAAAAAcASDEAAAAAAAwBEMQgAAAAAAAEeEm5gSAAAAAIBfLB/zUkYVV0IAAAAAAABHMAgBAAAAAAAcwSAEAAAAAABwBHNCAAAAAAAQAlNCRBdXQgAAAAAAAEcwCAEAAAAAABzBIAQAAAAAAHAEc0IAAAAAABCCj0khospYa2O6gbsSjo/tBo5AScCzacAvXlKidy/UKi4Nup2AKPv49ifdTgip+zMj3U4AAKBKz9t1cf1j+vadu+LyB8fkenVdOW/e/V8+AAAAAACIKwxCAAAAAAAARzAnBAAAAAAAIRgT1+82cRxXQgAAAAAAAEcwCAEAAAAAABzBIAQAAAAAAHAEgxAAAAAAAMARTEwJAAAAAEAIPualjCquhAAAAAAAAI5gEAIAAAAAADiCQQgAAAAAAOAI5oQAAAAAACAEpoSILq6EAAAAAAAAjmAQAgAAAAAAOIJBCAAAAAAA4AjmhAAAAAAAIASfYVaIaOJKCAAAAAAA4AgGIQAAAAAAgCMYhAAAAAAAAI5wdRDipD7n6Y/Ls3T/tx/rwntuPmS5v1YtXfv6P3X/tx9r5Nx3lNIqTZJUt2Gybp31uh7bvkyXPTW2fP3EOrV149SXdN+yWbp38Qfq/8g9juxHuz7na8y3WRq3ao763HuLI9usLtpqzqtdEm0H+1Xv83T3slkalTNbF4w6/PePIa89rVE5s3Xb5/8t//7R5sJzdMeX72nkwpm648v3dOIFvy5/zPXTJurO+dP1h0Xv69JnHpLxxf5bpFfPqVe7JHfbzj25qd7/04X6cHRP3dirzSHLm6fU0St3nK137rlAU+/rrvPapUqSEnxGj119uqb+sbtmPHChbjrMY2ONcxoZr7Z5tUuiLVK01ZxXuyTa4o0x8fnlFtcGIYzPp0FPj9ML/Yfq8fa9ddqVA5V6cusK65x1/RUqKSrWIyd11ydPvqQBj94nSdq7+2fNfHC8pt7zyCHP+/H4f+uxU3vq75376/hunXXSRefHfD8GPztOz/QdqrHteqnL4IFqXmk/3EJb/HRJtFXe3m+eGqsJA4ZpfMc+6njlADWttL0uw65QSdGP+lu7Hvr86Qnq+8i9kqSftm7TpEtv1JOn99WU4aN05cR/lD/mtSF36KnOF2t8p4t0bJOG6nB5v5jtw/798OI59WqX5G6bz0ijf9tRNzw3Txc/nKX+Z6TrxGb1K6xzS5+2mvlNvi796xzdNWm+HryioyTpotPSVCvBp4GPfqzL/jpHV559vNIa1nWkW+KcRsqrbV7tkmiLFG3x0yXRBoTj2iDEcV07asuaXG39fr0CpaX6Zso0nTqwV4V1Th3YS1+/+rYkafHbM9WmRzdJ0p5dJfr+i/kq3f1zhfVLS3Zr9ZwvJUmB0lLlLVym5LTmMd2PjK6dtGl1rraU7Uf2G9PU4ZLeMd1mddEWP10SbQdr2aWjtq7J1bay7S2ekql2Ayp+/zhlQE8tKPv+sfTtmWrdfd/3j4JFOdqxYZMkqXD5SiXWqS1/rVqSpJ937JQk+RIS5K+VKGttzPZB8u459WqX5G5bh1Ypyt2yU3lbd6k0YDV9QZ4ubN+swjrWWtWrnShJql87QZuKS/bdL6s6tRLk9xnVTvSpNBDUzt2ljnRLnNNIebXNq10SbZGiLX66JNqAcFwbhEhu0Uzb128ov12ct1FJLSr+Zy6pRWr5OsFAQLuLd+jYRinVev7aSfV1Sv8LtWr2F9GLPoyUtFQVrS8ov709b4NS0lJjus3qoq3mvNol0XawpLRm2p530PeP/A1KalFxew3SUlWcV/H7R91K3z/aX9ZX+d8sV2DPnvL7hmdO0p/zs/Xzjp+09O2ZMdsHybvn1Ktdkrttqcl1tLGopPx24fbdSk2uU2GdZ2Z+qwFd0vXJuD564ZZf66G3lkiSPvimQCV79urzhy7Sx+P6aELWKhXvcm4QgnMaGa+2ebVLoi1StNWcV7sk2oBwYjIIYYy5yRgz3xgzf2lwRyw2USWf369rX3tanz4zSVu/X+/49gF4X2q7Nur78D36720PVLj/pf5D9fBxZyrhmFrlV08A1XXxGel656v1On/0B7rpuXn66zVnyJh9V1EEg1bn/ul9XTjmQ13fo7XSGzn3dgwAAACviHgQwhgT8leE1toXrLWdrbWd2/vqH3ad7QUbldzywFslktKbqbhgY4V1igsKy9fx+f2qnVRfP20tCtt2xfOPaPOqdfr06YnV2pcjUZRfqJSWLcpvJ6c3V1F+Ycy3Wx201ZxXuyTaDlacv1HJ6Qd9/0hrruKCitv7Mb9QSekVv3/sKvv+kZTWTNe8+bwmX3+3tq394ZDn3/vzHuVM+0jtBvSM2T5I3j2nXu2S3G0r3F6iZikHrnxITa6twu0lFda5/NetNHNhviRp0boiHZPoV8qxtdS/c7o+W7FJe4NW23bu0cK129T+uGRHuiXOaaS82ubVLom2SNFWc17tkmiLR8bauPxyS5WDEMaY00N8nSGp05FseH32EjVpnaGGGenyJybqtCsGaPm0WRXWWTZtlrpeM0iS1HFQX63+eF7Y5+077n9UO6m+3v3DuCPJq7bc7MVq2iZDjcr2o8tVA7Rk6keObDsc2uKnS6LtYHnzl6hR6wyllG2v4xX9tSKz4vePnMwsnVH2/aP9oL5aM2ff94/aSfU19L2XNPOBvyp33oLy9WsdW1f1mzWRtG/Q4qS+3bXpuzUx2wfJu+fUq12Su21Lf9iujCb1lN6orhL9Rhefka7ZSysOnm8oKtGv2+77e3RCaj0dk+jTtp17tKGoRGf+qrEkqU4tvzpmpGht4U5HuiXOaaS82ubVLom2SNEWP10SbUA4CWGWZ0v6RNLhPsDjiH6FEwwE9PadD+r3M16Rz+/TV5Pe1MacVbpozF1aP3+plmfO0lcTJut3Lz+h+7/9WLuKivXqkDvKH//n1Z/pmAb1lFArUe0v6aXn+16r3T/uVO/7b1fhitX6n+xMSdJn/3pFX02YfCSpYfdj8u2jNeKDV+Tz+zV3whRtyFkVs+3VBG3x0yXRVnl7740co+HTX5bP51P2y2+qMGeVej04UnkLlmpFZpayJ07WlZPGa1TObJUUFev1q0dIkrrdeq0an9hKPR+4Qz0f2Pc95cV+18kYo+v++28lHFNLxme0Zs6X+uqF12O2D/v3w4vn1KtdkrttgaDVuDeX6MVbu8lvjN7+MlerN+7QiH4nadkP2zV72UY99s4yPTS4k4Z2P1HWSvf9Z6Ek6bVP1+rRq09X5v09ZCT996sf9F3Bj450S5zTSHm1zatdEm2Roi1+uiTagHBMVbO/G2OWSbrUWnvI30xjzHprbctwG7gr4Xj3rvMIoyTg2TTgFy8p0bV5c8MqLg26nYAo+/j2J91OCKn7MyPdTgAAoErP23WH+6V13NhdUhKXPzjWrlPHlfMW7kqIMQr9lo07QtwPAAAAAEB8sPwCKpqqHISw1r5VxeLqfVYmAAAAAACAjuwjOsdGrQIAAAAAAMS9Kq+EMMYsCbVIUmr0cwAAAAAAQLwKNydEqqQ+kooq3W8kzY1JEQAAAAAAHmGYEyKqwg1CZEqqZ61dVHmBMWZOTIoAAAAAAEBcCjcx5fAqlg2Jfg4AAAAAAIhXRzIxJQAAAAAAQLWFezsGAAAAAAC/XMwJEVVcCQEAAAAAABzBIAQAAAAAAHAEgxAAAAAAAMARDEIAAAAAAABHMDElAAAAAAChWOt2QVzhSggAAAAAAOAIBiEAAAAAAIAjGIQAAAAAAACOYE4IAAAAAABCsUG3C+JKzAchSgJM4gGg5opL+WYP53R/ZqTbCSFNPL2X2wmHNWzhR24nAACAoxBvxwAAAAAAAI5gEAIAAAAAADiCOSEAAAAAAAjBMCdEVHElBAAAAAAAcASDEAAAAAAAwBEMQgAAAAAAAEcwJwQAAAAAAKEwJ0RUcSUEAAAAAABwBIMQAAAAAADAEQxCAAAAAAAARzAIAQAAAAAAHMHElAAAAAAAhMLElFHFlRAAAAAAAMARDEIAAAAAAABHMAgBAAAAAAAcwZwQAAAAAACEwpwQUcWVEAAAAAAAwBEMQgAAAAAAAEcwCAEAAAAAABxx1AxCtOtzvsZ8m6Vxq+aoz723uJ1TAW2R8WqbE13htpFQq5ZueOMZjVs1R/d++a4atUovX9bnvls1btUcjfk2S+16nxf2Odv26Kb7F2TqgW9m6O7P3lSTE1u5sk9uoq3mvNol0RZK71+foqVv/0U57z6su4dedMjy45o11PvP/UHz33hQH/7v3UprmlK+7OE7Bmnh5DFaOHmMLu/V2clsSZzTSHi1S6ItUrTVnFe7JNriTjAYn18uOSoGIYzPp8HPjtMzfYdqbLte6jJ4oJqf3NrtLEm0RcqrbU50VWcbZw+/QruKijW6zQXKeuIlXfr4fZKk5ie3VperBmjcKb31z4uu0+B//UXG56vyOYc895Am/O5OPXxaP2W//p76/emOqO5PdffJLbTFT5dEWyg+n9FT9w3RwBFPqePlo3Vln6466fjmFdZ57K7f6j/T56nzVWP1yIuZ+svtl0qS+p7TXqeddJy6DBmnc657RHdd00f1j63tSLfEOY2nLom2SNEWP10SbUA4R8UgREbXTtq0Oldbvl+vQGmpst+Ypg6X9HY7SxJtkfJqmxNd1dlGh0t6a97Lb0uSFr41Qydd2K38/uw3pmnvnj3aui5Pm1bnKqNrpyqf01qr2g3qS5JqJzXQ9oLCqO5PdffJLbTFT5dEWyhdTjlea9Zv1vf5W1S6N6ApH2ZrwAWdKqxz8vEtNCf7W0nSnOxvNeD8TmX3N9dn36xUIBDUrt17tHRVnnp3O9WRbolzGk9dEm2Roi1+uiTagHCOikGIlLRUFa0vKL+9PW+DUtJSXSw6gLbIeLXNia7qbCP5oHWCgYBKinfo2EYpIR9b1XP+54b7dPuMiXp0/Tyddc2l+uCx56K6P9XdJ7fQVnNe7ZJoC6VF02StL9xWfju/sEhpTZIrrLNk1Xr9psfpkqRLup+mBvXqqGHSsVqyKk+9f32q6tSupUbJ9XRB57ZqmZoip3BOa86rXRJtkaKt5rzaJdEGhJMQiyc1xtwk6SZJOlcN1U71Y7EZANVw4V3D9Uy/YVr39SL1uvsmXT7+T/rPjfe5nQXAYfc98aaevHeIrunfTZ9/s1J5hUUKBIKa9WWOzmiXoU8m3KctRTv05dK1CgT4PHQAAPYzln8Xo6nKKyGMMQ2MMY8aY141xgyptOxfoR5nrX3BWtvZWts5GgMQRfmFSmnZovx2cnpzFeVH/5LySNAWGa+2OdFVnW1sP2gdn9+vOkn19dPWopCPDXV/vcYNld7xZK37epEkaf7kTJ3Y7Yyo7k9198kttNWcV7sk2kIp2LRdLVMblt9OS01R/ubtFdbZsKVYV456Tmf+7i8a/ey7kqTinSWSpMcnzFDXIePU77YnZIy06gfnjinntOa82iXRFinaas6rXRJtQDjh3o4xUZKR9Lakq4wxbxtjjilbdlZMyw6Sm71YTdtkqFFGuvyJiepy1QAtmfqRU5uvEm2R8WqbE13V2caSqR/p19cNkiSdfnk/fTd7bvn9Xa4aoIRatdQoI11N22Ro3deLQj7nrqJi1Umqr6ZtjpckndzrHG1YsTqq+1PdfXILbfHTJdEWyvycdWrdsqkyWjRWYoJfV/TuosxPFldYp1FyPRljJEn3DOurl6d+LmnfpJYNk46VJJ3aOk3tW6froy9zHOmWOKfx1CXRFina4qdLog0IJ9zbMU601g4q+/O7xpgHJM02xgyMcVcFwUBAk28frREfvCKf36+5E6ZoQ84qJxNCoi0yXm1zoivUNgaMvUu585dqybRZ+uKlKRr26niNWzVHu7Zt14tX7ftEiw05q7RgSqYezPlIgb179cZto2WDQVkpZPd/bvyjfv/2c7JBq11FxXrl+lFR3Z+q9skLaIufLom2UAKBoEb+9XVlPjNSfr/RpPe+0Iq1BRp980AtzMlV5qeLdd4Zv9JDt18ma6XPvlmpOx97XZKUmODX7BfvkST9+NNuDf3zS46+HYNzGj9dEm2Roi1+uiTagHCMtTb0QmNWSDrF2gNvgjHGDJU0SlI9a22rcBu42WSE3gAAAKjSxNN7uZ1wWMMW8pszAMA+z9t1xu2GWCrd/ENc/kyb2OQ4V85buCshpknqIWnW/justZOMMRsl/TOWYQAAAAAAuI6JKaOqykEIa+09Ie5/3xjzSGySAAAAAABAPAo3MWVVxkatAgAAAAAAxL0qr4QwxiwJtUhSavRzAAAAAABAvAo3J0SqpD6SiirdbyTNjUkRAAAAAABeUcWHOaDmwg1CZGrfp2AsqrzAGDMnJkUAAAAAACAuhZuYcngVy4ZEPwcAAAAAAMSrI5mYEgAAAAAAoNrCvR0DAAAAAIBfLht0uyCucCUEAAAAAABwBIMQAAAAAADAEQxCAAAAAAAARzAnBAAAAAAAIRjmhIgqroQAAAAAAACOYBACAAAAAAA4gkEIAAAAAADgCAYhAAAAAACAI5iYEgAAAACAUJiYMqq4EgIAAAAAADiCKyEAAPCwYQs/cjvhsCZ06uF2QkjXL5rtdgIAAAiBKyEAAAAAAIAjuBICAAAAAIBQmBMiqrgSAgAAAAAAOIJBCAAAAAAA4AgGIQAAAAAAgCOYEwIAAAAAgFCYEyKquBICAAAAAAA4gkEIAAAAAADgCAYhAAAAAACAI5gTAgAAAACAEAxzQkQVV0IAAAAAAABHMAgBAAAAAAAcwSAEAAAAAABwBIMQAAAAAADAEUxMCQAAAABAKEEmpowmroQAAAAAAACOYBACAAAAAAA4gkEIAAAAAADgiKNmEKJdn/M15tssjVs1R33uvcXtnApoi4xX27zaJdEWKdpqzqtdEm2R8mrbCw8OU17Wk/rmzXFupxyWV4+bV7sk2iJFW815tUuiLe5YG59fLjkqBiGMz6fBz47TM32Hamy7XuoyeKCan9za7SxJtEXKq21e7ZJoixRt8dMl0RYpL7e9Mu0L9b9tvNsZh+XV4+bVLom2SNEWP10SbUA4R8UgREbXTtq0Oldbvl+vQGmpst+Ypg6X9HY7SxJtkfJqm1e7JNoiRVv8dEm0RcrLbZ8vXKmi4p/czjgsrx43r3ZJtEWKtvjpkmgDwjkqBiFS0lJVtL6g/Pb2vA1KSUt1segA2iLj1Tavdkm0RYq2mvNql0RbpLzc5mVePW5e7ZJoixRtNefVLok2IJwEtwMAAAAAAPAsG3S7IK5UeSWEMaaZMeY5Y8yzxphGxpgxxpilxpgpxpjmVTzuJmPMfGPM/BztOOLIovxCpbRsUX47Ob25ivILj/h5o4G2yHi1zatdEm2Roq3mvNol0RYpL7d5mVePm1e7JNoiRVvNebVLog0IJ9zbMSZJypG0XtLHkkok9ZP0maTnQz3IWvuCtbaztbZzO9U/4sjc7MVq2iZDjTLS5U9MVJerBmjJ1I+O+HmjgbbIeLXNq10SbZGiLX66JNoi5eU2L/PqcfNql0RbpGiLny6JNiCccG/HSLXW/lOSjDG3WmsfL7v/n8aY4bFNOyAYCGjy7aM14oNX5PP7NXfCFG3IWeXU5qtEW2S82ubVLom2SNEWP10SbZHycturj/5e553RVo2T62nt+3/XuOff06R3P3M7S5J3j5tXuyTaIkVb/HRJtAHhGFvF54MaYxZbazuW/fkha+2fDlq21FrbPtwGbjYZ7n0AKQAAiIkJnXq4nRDS9Ytmu50AAL8oz9t1xu2GWAqunR+XP9P6TujsynkL93aM94wx9SSp0gBEa0nfxTIMAAAAAADElyrfjmGtHR3i/tXGmOmxSQIAAAAAAPEo3JUQVRkbtQoAAAAAABD3qrwSwhizJNQiSanRzwEAAAAAAPEq7KdjSOojqajS/UbS3JgUAQAAAADgFTbodkFcCTcIkSmpnrV2UeUFxpg5MSkCAAAAAABxKdzElMOrWDYk+jkAAAAAACBeHcnElAAAAAAAIE4ZYy4yxnxnjFltjLmvivUGGWOsMaZzuOcM93YMAAAAAAB+uX6hc0IYY/ySnpXUS1KepGxjzFRrbU6l9epLulPSV9V5Xq6EAAAAAAAAlXWVtNpau9Zau0fSG5IuOcx6f5H0uKTd1XlSBiEAAAAAAPiFMcbcZIyZf9DXTZVWSZO0/qDbeWX3Hfwcp0tqaa2dXt3t8nYMAAAAAAB+Yay1L0h6IdLHG2N8ksZLGlqTxzEIAQAAAABAKMGA2wVuyZfU8qDb6WX37Vdf0qmS5hhjJKmZpKnGmIHW2vmhnpS3YwAAAAAAgMqyJbUxxhxvjKkl6SpJU/cvtNYWW2sbW2szrLUZkr6UVOUAhMQgBAAAAAAAqMRau1fS7ZI+kLRC0hRr7XJjzDhjzMBIn5e3YwAAAAAAgENYa2dImlHpvtEh1r2gOs/JIAQAAAAAACHYYNDthLjC2zEAAAAAAIAjGIQAAAAAAACO4O0YqJF+zeq5nRDSjI073U4AcJRKSvTumHxxqTcvAb1+0Wy3E0Jq8eEHbieEVNC7j9sJIbWo7d3/Fhbs3ut2AgAgSrz7vy4AAAAAABBXvDvkDQAAAACA24IBtwviCldCAAAAAAAARzAIAQAAAAAAHMEgBAAAAAAAcARzQgAAAAAAEApzQkQVV0IAAAAAAABHMAgBAAAAAAAcwSAEAAAAAABwBHNCAAAAAAAQgg0wJ0Q0cSUEAAAAAABwBIMQAAAAAADAEQxCAAAAAAAARzAnBAAAAAAAoQSDbhfEFa6EAAAAAAAAjmAQAgAAAAAAOIJBCAAAAAAA4AgGIQAAAAAAgCOYmBIAAAAAgFCCAbcL4spRcyVEuz7na8y3WRq3ao763HuL2zkV0BZek+5nq8dn03Th3BlqffvwQ5Y3POsMnffhFPVfv0jNL+7lQuEBXjlmh0NbZGirOa92Sc63/ar3ebp72SyNypmtC0bdfMhyf61aGvLa0xqVM1u3ff5fpbRKkyS1ufAc3fHlexq5cKbu+PI9nXjBr8sf02fc/+iPaz7XuG1LY96/H+f08ApyFmjquFv03pibtPzDtw5ZvuDtFzXj0Ts149E7NXXszZoyarAkaVveWn3w91HKfOg2TX/kDq1b8Jmj3U4fsxN7nadbF3+o25dl6ey7f3/Icn+tWhr06lO6fVmWhn/6lpKO2/c6aNG5g276cuq+r6+mqe3AA//Gn3nHMN28YKZunj9Dl738hPzH1Ir5fvA6iIxX27zaJdEGVOWoGIQwPp8GPztOz/QdqrHteqnL4IFqfnJrt7Mk0VYtPp86PPInffm7WzT7/IFK+00/1fvVCRVWKcnboEV3/kn578xwvu8gnjlmh0FbZGiLny7J+Tbj8+k3T43VhAHDNL5jH3W8coCaVtpel2FXqKToR/2tXQ99/vQE9X3kXknST1u3adKlN+rJ0/tqyvBRunLiP8ofsyIzS8+cfWnMug+3H5zTQwWDAWVP+V91v/VB9f/Ts1q34FMVb/ihwjpnDLpB/f74lPr98Sm1Pb+/WnY8S5KUkHiMfn3tXer/p2fV/dYxWvD2i9qza6cj3W68Dvo+OUavXzJc/zrtIp3y2/5qfFLF7Z029LcqKSrWM6deqC//OVE9H75HkrRp+Ur9++xL9cJZA/X6Jder/z8fkvH7Vb9Fqrreeq1ePPs3er5zPxm/X6f+tn/M9mH/fvA6qDmvtnm1S6INCOeoGITI6NpJm1bnasv36xUoLVX2G9PU4ZLebmdJoq06Uk5rr5/W/aBdP+TJlu5V/nsz1axPjwrrlOQV6McVK2Vd/gxerxyzw6EtMrTFT5fkfFvLLh21dU2utpVtb/GUTLUbUPFqrVMG9NSCV9+WJC19e6Zad+8mSSpYlKMdGzZJkgqXr1Rindry19r3m94fvl6kHRs3x6y7Ms7p4W1dt0r1GzdX/cbN5E9IVKvTz9X6JV+FXH/dgk+VccZ5kqQGqWlq0LSFJKluciPVrp+k3Tt/dKTb6WOW1qWjitbkavu69QqWlmr5m9PVtn/PCuu07d9TS157R5KU89/3dXzZlT97S3bLBvZdxpxwzDGy1pY/xpeQoIQ6tWX8fiXWqV3+eokVXgeR8WqbV7sk2oBwajwIYYxpGouQqqSkpapofUH57e15G5SSlup0xmHRFl7tZk1Vkr+x/PbuDYWq08zxv0bV4pVjdji0RYa2mvNql+R8W1JaM23P21B+uzh/g5JaVNxeg7RUFZetEwwEtLt4h+o2SqmwTvvL+ir/m+UK7NkTs9aqcE4Pr6R4q+qmNC6/XTelsUqKtx523Z3bNmnn1kKltu1wyLIt61YquHev6jduFrPWgzl9zOq3OPB3XJJ+zN+o+pW2d/A6NhDQ7h93qk7Z6yCtS8eyt11M1/QRf5YNBLSjoFDznnxRI1d+qj98P08//7hDa7M+j9k+SLwOIuXVNq92SbTFIxsMxOWXW6ochDDGNKz01UjS18aYFGNMwyoed5MxZr4xZn6OdkQ9GgCAo0Vquzbq+/A9+u9tD7idgiOQu+AzHdepm3w+f4X7S4q3ae4rT+jXV4+Q8R0VF5g6Lj97sZ4/o69ePOcynTPqZvmPqaXayQ3Utn9PPX1ydz1xQjclHltX7a+6xO1UAIADwv1ruUXSgoO+5ktKk7Sw7M+HZa19wVrb2VrbuZ3qH3FkUX6hUlq2KL+dnN5cRfmFR/y80UBbeLs3bvu2NwAAIABJREFUblKdtAO/HardPFUlG2N7yWWkvHLMDoe2yNBWc17tkpxvK87fqOT05uW3k9Kaq7ig4vZ+zC9UUtk6Pr9ftZPqa9fWorL1m+maN5/X5Ovv1ra1FecacBLn9PDqJDXSrqIt5bd3FW1RnaRGh103d8Gnyuh8XoX7Skt26ePnxqnTgKvV+PiTYtp6MKeP2Y6CA3/HJalBWjPtqLS9g9cxfr9qN6inkrLXwX5bvlujPTt3qekpv9LxPc7W9nV52rVlm4J79+rbdz9Q+lmnx2wfJF4HkfJqm1e7JNqAcMINQoyS9J2kgdba4621x0vKK/vzCWEeGzW52YvVtE2GGmWky5+YqC5XDdCSqR85tfkq0Rbe9kXLdOzxx6luyzSZxASlXdJXhR987HhHdXjlmB0ObZGhLX66JOfb8uYvUaPWGUop217HK/prReasCuvkZGbpjGsGSZLaD+qrNXPmSZJqJ9XX0Pde0swH/qrceQti1lgdnNPDa9SqjXZsLtDOLRsV2Fuq3IWfKb3DmYesV7wxT3t2/VRhoCGwt1Sf/PsRnXBmdx132tmO9O7n9DHLn79EDVu3UnKrdPkSE3XKby/WyulZFdb5bnqWOvxu32Sr7S67SN9/8qUkKblVuox/39UjSce1UOO2J2h7br5+XF+gtK6dlFCntiTp+O7dtOW71THbB4nXQaS82ubVLok2IJyEqhZaa/9hjJks6QljzHpJD0qyVT0mFoKBgCbfPlojPnhFPr9fcydM0YacVU5nHBZt4dlAQEvvf0Rn/d//yvj9+uGNd7Rj5Rq1HXWbti9ersIP5yi546nqMuFJJSY3ULNeF6jtqNs054LfON7qlWN2OLRFhrb46ZKcbwsGAnpv5BgNn/6yfD6fsl9+U4U5q9TrwZHKW7BUKzKzlD1xsq6cNF6jcmarpKhYr189QpLU7dZr1fjEVur5wB3q+cAdkqQX+12nnzZvVd9H79VpVw5UYt06un/tF/p64hTN+stTMd0PzumhfH6/Ol/xe81+doysDerEs3oquflxWpz5mhod17p8QCJ3wadqdca5MsaUP/aHhZ9r0+rl2vPTDq39crYk6axr7lTD9Nj/jsbpY2YDAc28a6x+N22ijN+vRS+/qc0rVumCP9+pgoXLtHJ6lr6ZNEWXTviHbl+WpZKi7Xr7mpGSpJbdOuuqu3+vYGmpbNBqxp0PqmRrkfK3FmnFO+/rpnnvKbg3oI2Lc7Twpckx2weJ10GkvNrm1S6Jtrjk8uT58cYcPEtxlSsaM1DS/ZIyrLXVnnnpZpPh+KAFYqdfs3puJ4Q0Y6MzH40GIP4kJXr3vfzFpfzHp6ZafPiB2wkhFfTu43ZCSC1qV/m7KVcV7N7rdgKAKjxv15nwax29Sr96Ny5/pk088zeunLdq/6/LWjtVUndJPSXJGDMsVlEAAAAAACD+1OhXP9baEmvtsrKbY2PQAwAAAAAA4lSV190ZY5aEWiSJD5QFAAAAAMQ1Gwy4nRBXwr35L1VSH0lFle43kubGpAgAAAAAAMSlcIMQmZLqWWsXVV5gjJkTkyIAAAAAABCXwn1E5/Aqlg2Jfg4AAAAAAIhX3v1MMgAAAAAAEFe8+4HQAAAAAAC4jYkpo4orIQAAAAAAgCMYhAAAAAAAAI5gEAIAAAAAADiCOSEAAAAAAAglGHS7IK5wJQQAAAAAAHAEgxAAAAAAAMARDEIAAAAAAABHMCcEAAAAAAAh2EDA7YS4wpUQAAAAAADAEQxCAAAAAAAAR/B2DNTIjI073U4AgKgrLuWjt2pqSNcWbieE9HrvPm4nhDShUw+3E0K6ftFstxMAAL8ADEIAAAAAABBKkDkhoom3YwAAAAAAAEcwCAEAAAAAABzBIAQAAAAAAHAEgxAAAAAAAMARTEwJAAAAAEAoTEwZVVwJAQAAAAAAHMEgBAAAAAAAcASDEAAAAAAAwBHMCQEAAAAAQAg2GHQ7Ia5wJQQAAAAAAHAEgxAAAAAAAMARDEIAAAAAAABHMCcEAAAAAAChBANuF8QVroQAAAAAAACOYBACAAAAAAA4gkEIAAAAAADgCOaEAAAAAAAgFOaEiCquhAAAAAAAAI44agYh2vU5X2O+zdK4VXPU595b3M6pgLbIeLXNq10SbZGirea82iXRFik321LOOlOdp/yfurw1RS2vveaQ5UmdOum0lyfq3C8+VeMe3Q9Z7j+2rs6c9q5OvPsPTuRW4NVz+sKDw5SX9aS+eXOc2ymH8Ooxk2iLlFfbvNol0QZU5agYhDA+nwY/O07P9B2qse16qcvggWp+cmu3syTRFimvtnm1S6ItUrTFT5dEW6RcbfP51HrU3Vo28n80/6ohatK7p+oen1Fhld2FG7XyLw9p04cfHfYpMn5/k4q/WRT71kq8fE5fmfaF+t823u2MQ3j5mNEWGa+2ebVLog0I56gYhMjo2kmbVudqy/frFSgtVfYb09Thkt5uZ0miLVJebfNql0RbpGiLny6Jtki52Va/XTuV5OVpd0GB7N692vzRLDU679wK6/y8YaN+Wr1GNhg85PH1TmqrxIYNVfTV1470HszL5/TzhStVVPyT2xmH8PIxoy0yXm3zapdEGxDOUTEIkZKWqqL1BeW3t+dtUEpaqotFB9AWGa+2ebVLoi1StNWcV7sk2iLlZtsxTZvo58LC8ts/b9qsWk2aVO/BxuiEEXdo7dP/jFFd1bx8Tr3Ky8eMtsh4tc2rXRJt8cgGg3H55ZaYDEIYY24yxsw3xszP0Y5YbAIAAMS5FoMu07a587Rn02a3UwAAQJRU+RGdxpiLrLXvl/05SdJ4SV0kLZN0l7W28HCPs9a+IOkFSbrZZNgjjSzKL1RKyxblt5PTm6so/7CbdhxtkfFqm1e7JNoiRVvNebVLoi1Sbrb9vGmzjkk98Fu2Y5o20Z7N1RtUaND+VDXo1FEtBl0mf906MomJCuwq0bp/PRer3Aq8fE69ysvHjLbIeLXNq10SbUA44a6EeOSgP/9D0gZJAyRlS/rfWEVVlpu9WE3bZKhRRrr8iYnqctUALZl6+MmrnEZbZLza5tUuibZI0RY/XRJtkXKzbceKFarTMl21mzeXSUhQk149tfXTz6v12G8fHKuvL7lMX186SGuffkaFM2Y6NgAhefucepWXjxltkfFqm1e7JNqAcKq8EqKSztbaTmV/fsIYc10sgg4nGAho8u2jNeKDV+Tz+zV3whRtyFnl1OarRFtkvNrm1S6JtkjRFj9dEm2RcrUtENDqv4/XqU8/IePza+O0TO36/nu1uukG7VjxrbZ99rnqnXyyTvnro0qoX1+Nzj1HrW4crgWDr3amrwpePqevPvp7nXdGWzVOrqe17/9d455/T5Pe/cztLE8fM9oi49U2r3ZJtMWlYMDtgrhirA39bgljTJ72vQXDSLpN0om27AHGmCXW2g7hNhCNt2MAAABvGdK1RfiVXPL61wXhV3LJhE493E4I6fpFs91OAHCUet6uM243xFLJ1Kfj8mfaOgNHuHLewr0d49+S6kuqJ+llSY0lyRjTTJLzH9gNAAAAAACOWlW+HcNaOzbE/RuNMR/HJgkAAAAAAMSjmswJUdlYSROjFQIAAAAAgOcwJ0RUhfuIziWhFklKDbEMAAAAAADgEOGuhEiV1EdSUaX7jaS5MSkCAAAAAABxKdwgRKaketbaQyahNMbMiUkRAAAAAACIS+EmphxexbIh0c8BAAAAAMA7bIA5IaIp3Ed0AgAAAAAARAWDEAAAAAAAwBEMQgAAAAAAAEcwCAEAAAAAABwR7tMxAAAAAAD45QoG3S6IK1wJAQAAAAAAHMEgBAAAAAAAcASDEAAAAAAAwBHMCQEAAAAAQCjBgNsFcYUrIQAAAAAAgCMYhAAAAAAAAI7g7RgAAKDGXv+6wO2Eo9L1i2a7nRDShE493E4IycvHDQBQMwxCAAAAAAAQgmVOiKji7RgAAAAAAMARDEIAAAAAAABHMAgBAAAAAAAcwZwQAAAAAACEYINBtxPiCldCAAAAAAAARzAIAQAAAAAAHMEgBAAAAAAAcASDEAAAAAAAwBFMTAkAAAAAQAg2wMSU0cSVEAAAAAAAwBEMQgAAAAAAAEcwCAEAAAAAABzBnBAAAAAAAITAnBDRxZUQAAAAAADAEQxCAAAAAAAARzAIAQAAAAAAHMGcEAAAAAAAhGCDzAkRTVwJAQAAAAAAHHHUDEK063O+xnybpXGr5qjPvbe4nVMBbZHxaptXuyTaIkVbzXm1S6ItUrRFxqttXu2SpBceHKa8rCf1zZvj3E45hJePG20159UuiTagKkfFIITx+TT42XF6pu9QjW3XS10GD1Tzk1u7nSWJtkh5tc2rXRJtkaItfrok2iJFW2S82ubVrv1emfaF+t823u2MQ3j5uNEWP10SbUA4R8UgREbXTtq0Oldbvl+vQGmpst+Ypg6X9HY7SxJtkfJqm1e7JNoiRVv8dEm0RYq2yHi1zatd+32+cKWKin9yO+MQXj5utMVPl0RbPLKBYFx+ueWoGIRISUtV0fqC8tvb8zYoJS3VxaIDaIuMV9u82iXRFinaas6rXRJtkaItMl5t82qX13n5uNFWc17tkmgDwqnxIIQxplEsQgAAAAAAQHyrchDCGPOYMaZx2Z87G2PWSvrKGJNrjDm/isfdZIyZb4yZn6MdRxxZlF+olJYtym8npzdXUX7hET9vNNAWGa+2ebVLoi1StNWcV7sk2iJFW2S82ubVLq/z8nGjrea82iXRBoQT7kqIi621W8r+/DdJV1prW0vqJekfoR5krX3BWtvZWtu5neofcWRu9mI1bZOhRhnp8icmqstVA7Rk6kdH/LzRQFtkvNrm1S6JtkjRFj9dEm2Roi0yXm3zapfXefm40RY/XRJtQDgJ4ZYbYxKstXsl1bHWZkuStXalMeaY2OftEwwENPn20RrxwSvy+f2aO2GKNuSscmrzVaItMl5t82qXRFukaIufLom2SNEWGa+2ebVrv1cf/b3OO6OtGifX09r3/65xz7+nSe9+5naWp48bbfHTJdEWj9ycxDEeGWtt6IXG3CFpgKTHJJ0nKUXSfyX1kHSCtfaacBu42WSE3gAAAAA8YUKnHm4nhHT9otluJwCowvN2nXG7IZaKnrsvLn+mTbnlMVfOW5VXQlhr/2mMWSrpFkm/Klu/jaR3Jf0l9nkAAAAAACBehHs7hqy1cyTNqXy/MWaYpInRTwIAAAAAAPEo7CBEFcaKQQgAAAAAQBwLBgJuJ8SVKgchjDFLQi2SlBr9HAAAAAAAEK/CXQmRKqmPpKJK9xtJc2NSBAAAAAAA4lK4QYhMSfWstYsqLzDGzIlJEQAAAAAAiEvhPh1jeBXLhkQ/BwAAAAAA77DBoNsJccXndgAAAAAAAPhlYBACAAAAAAA4gkEIAAAAAADgiHATUwIAAAAA8ItlA8wJEU1cCQEAAAAAABzBIAQAAAAAAHAEgxAAAAAAAMARDEIAAAAAAABHMDElAAAAAAAhMDFldHElBAAAAAAAcASDEAAAAAAAwBEMQgAAAAAAAEcwJwQAAB5WL8Gbvy/YuZf3x8ab6xfNdjshpNfPv9LthMMa8slktxMAOMAG+Tcvmrz5PxsAAAAAABB3GIQAAAAAAACOYBACAAAAAAA4gjkhAAAAAAAIIRhgToho4koIAAAAAADgCAYhAAAAAACAIxiEAAAAAAAAjmBOCAAAAAAAQrDMCRFVXAkBAAAAAAAcwSAEAAAAAABwBIMQAAAAAADAEcwJAQAAAABACMwJEV1cCQEAAAAAABzBIAQAAAAAAHAEgxAAAAAAAMARDEIAAAAAAABHMDElAAAAAAAh2CATU0YTV0IAAAAAAABHHDWDEO36nK8x32Zp3Ko56nPvLW7nVEBbZLza5tUuibZI0VZzXu2SaDtY297n6Z5ls3TfitnqPurmQ5b7a9XS1a89rftWzNaIL/6rlFZpkqS6DZN180ev6eGipbr0qTEVH5OYqMufe1j3Ls/SPUs/UvtLL4r5fnBOa86rXZK7bT27/koLXrlbi14bpbuGXHDI8papyZr6jxs196WRmv7kTWrRJEmSdG6nE/T5i3eWf2368CFdfE47R9s5pzXn1S6JNqAqR8UghPH5NPjZcXqm71CNbddLXQYPVPOTW7udJYm2SHm1zatdEm2Roi1+uiTaKm/v0qfH6sUBw/S3Dn102lUDlFppe2def4VKtv+ox07uoU+fmqCLH7lXkrR39896f8wTyrz30UOe98I/3qadm7bq8VMu1N869NaaT7+K2T7s3w/OaXx0Se62+XxG/7jzNxp07wR1uW68Lu/RUW1bNa2wzkO3XKw3PlygbsOf1OMvZ2nMjfsG2T5btFbn3PCUzrnhKQ246wWV7C7V7OxVjnRLnNN46pJoA8I5KgYhMrp20qbVudry/XoFSkuV/cY0dbikt9tZkmiLlFfbvNol0RYp2uKnS6LtYMd17aita3K1rWx7iyZn6pQBvSqsc8qAnpr/6tuSpCVvz1SbHt0kSXt2lWjdF/NVuvvnQ56369DLNfvx5yRJ1lrt2loUs32QOKfx1CW529b5pJZam79V6zZsU+negN6evVgXn13xaoaTWqXqk4VrJEmffrNG/c4+9GqHS85vr4+++k4lP5c60i1xTuOpS6ItHtlAMC6/3HJUDEKkpKWqaH1B+e3teRuUkpbqYtEBtEXGq21e7ZJoixRtNefVLom2gyW1aKbteRsObC9/g5IqbS+pRaq2r9+3TjAQUEnxDtVtlBLyOWsn1Zck9Rn7B438eqqu+b9nVK9p4xjUH8A5rTmvdknutjVvkqS8zdvLbxdsLi5/u8V+y9YUaOB5p0qSBpx7ihocW1sNG9StsM6gHh311uxFsQ8+COe05rzaJdEGhHNUDEIAAIDY8yUkKLllC+XOW6gnuw5U7lffaMBf/+h2FhA1Dzw3XWd3PEGf/XuEzul4gvI3Fytw0Kz3qQ3r65QTmmnW1ytdrASA+FblR3QaYxZK+q+k/7PWrqnukxpjbpJ0kySdq4Zqp/pHFFmUX6iUli3KbyenN1dRfuERPWe00BYZr7Z5tUuiLVK01ZxXuyTaDlZcsFHJ6c0PbC+tuYorba+4oFDJLZurOH+jfH6/6iTVr/LtFbu2FmnPT7u09J33JUmL35qhrkN/G5sdKMM5rTmvdknutm3YXKz0Jsnlt1s0SVLB5uIK62zcukNXj35VknRsnVoaeH57Fe/cXb78su4dNO2z5drr8GXKnNOa82qXRBsQTrgrIVIkJUv62BjztTHmLmNMizCPkbX2BWttZ2tt5yMdgJCk3OzFatomQ40y0uVPTFSXqwZoydSPjvh5o4G2yHi1zatdEm2Roi1+uiTaDrY+e4kat85Qw7Ltdbqyv5ZnzqqwzvLMLHW+ZpAkqcOgvlr98bywz7s8M0snnn+WJKlNj24qXLE6+vEH4ZzGT5fkbtuC7/J0QnojtWqWosQEvwb16KgZc1dUWKdhUl0ZYyRJfxjSXf+ZkV1h+eUXdtJbWc6+FUPinMZTl0RbPHJ77oZ4mxOiyishJBVZa++WdLcx5lxJgyUtNMas0L6rI16IeaH2vY918u2jNeKDV+Tz+zV3whRtyHFuxuKq0BYZr7Z5tUuiLVK0xU+XRFvl7b1z5xjdOP1lGb9P2ZPeVGHOKvV5cKTWL1iqnMwsfT1hsgZPGq/7VszWrqJi/ed3I8off/+qT1W7QT35ayXqlIG99O9+16lwxWrNuP9xDZ40XgPH/1k/bd6myTfcE7N92L8fnNP46JLcbQsEghr11Ht652/D5ff59OrMbH27rlAPDOulhd/laebcFTq304kac+NFstbqiyXf63+efLf88cc1S1FakyR9vvh7R3oPxjmNny6JNiAcY60NvdCYhdba0yvd55fUS9KV1tph4TZws8kIvQEAAFClegnenL5p5173foOCX57Xz7/S7YTDGvLJZLcTAE943q4zbjfE0g9/HBaXP9Me9+hEV85buCshDpmVx1obkPR+2RcAAAAAAEC1VDkIYa29KtQyY8wwa+3E6CcBAAAAAPD/7d1/mOZ1fd/713tXTBqxglj3IMvJppFYtwluwo8rPY2oGEUShPRHWjCtUTxBPRKNp6dqmnOhbK/EX9Roqy3lmA3BeuKvNAg2USnEROUkhcBCFH9AEMIiLrFdbTRXIsx8zh9zLwzL3jPsl9n7+5l7H4/rmou573vmnqffcee+5z2f7+fuw+Ki1X9r6dGs8bxwzSoAAACAubfaS3TePO2mJJvWPgcAAACYV6vtCbEpyWlJ9n1R8Upy7UEpAgAAAObSakOIjyU5vLX2sBdMrqpPHZQiAAAAYC6ttjHly1a47UVrnwMAAAD9aAs2plxLfb74OAAAADB3DCEAAACAmTCEAAAAAGZitY0pAQAA4JDVFhbGTpgrVkIAAAAAM2EIAQAAAMyEIQQAAAAwE/aEAAAAgCna4uLYCXPFSggAAABgJgwhAAAAgJkwhAAAAABmwp4QAAAAMEVbsCfEWjKEAICOfet+T3zgRb//wbET9mvHtlPHTpjq3J3XjJ0AsF9OxwAAAABmwhACAAAAmAlDCAAAAGAm7AkBAAAAU9iYcm1ZCQEAAADMhCEEAAAAMBOGEAAAAMBM2BMCAAAApli0J8SashICAAAAmAlDCAAAAGAmDCEAAACAmbAnBAAAAEzRFu0JsZashAAAAABmwhACAAAAmAlDCAAAAGAm7AkBAAAAU7SFQ3dPiKp6QZJ3JdmY5L2ttbfsc/v/meR/T3J/kj9Pcm5r7c6V7tNKCAAAAOAhqmpjkvckOT3J1iTnVNXWfT7sxiQnttaOT/KRJG9b7X4NIQAAAIB9nZzkttba7a217yT5QJKzln9Aa+33Wmt/Obn4h0k2r3anhhAAAABwiKmq86rq+mVv5+3zIcckuWvZ5V2T66Z5WZLfXe3rrpshxNbTnpU3ffHqbL/1Uznt9a8cO+chtA3Ta1uvXYm2obQduF67Em1DaRum17ZeuxJtQ1zyxpdm19XvzI0f3j52yn71etx67Uq0sT601i5prZ247O2SofdVVf8syYlJ3r7ax66LIURt2JBz3rM97z79Jblw6/Ny0jln5uinP3XsrCTahuq1rdeuRNtQ2uanK9E2lLZhem3rtSvRNtRlV342Z7zqHWNn7Fevx63XrkTbPGoLbS7fHoG7kxy77PLmyXUPUVU/nuSXkpzZWvvr1e50XQwhtpy8Lffedme+/pW7snDffbnuA1fm+LOeP3ZWEm1D9drWa1eibSht89OVaBtK2zC9tvXalWgb6jM3fDl7vvntsTP2q9fj1mtXoo25cl2S46rq+6rqsUnOTnLF8g+oqh9O8h+zNIC495Hc6boYQhx5zKbsueurD1z+xq57cuQxm0YsepC2YXpt67Ur0TaUtgPXa1eibShtw/Ta1mtXom0e9Xrceu1KtDE/Wmv3Jzk/ySeSfCHJh1prn6+q7VV15uTD3p7k8CQfrqqdVXXFlLt7wGNWurGq9p7TcXeSX0yyI0s7ZH45yXmttRunfN55Sc5Lkmfmidmaxz+C/4kAAABAL1prv5Pkd/a57oJl7//4gd7nikOIJP8+yRuTHJHk2iSvba09r6qeO7nt700JvSTJJUnyitryiE42Wcmeu3fnyGOf8sDlIzYfnT137360d7smtA3Ta1uvXYm2obQduF67Em1DaRum17ZeuxJt86jX49ZrV6JtHi0uLI6dMFdWOx3jsNba77bWfjNJa619JEvvXJ3kuw963cSd192UJx+3JUdt2ZyNhx2Wk85+YW6+4qpZffkVaRum17ZeuxJtQ2mbn65E21Dahum1rdeuRNs86vW49dqVaIPVrLYS4q+q6vlJnpCkVdVPtdYur6pnJVk4+HlLFhcW8sHzL8irP3FZNmzcmGt3fCj33HLrrL78irQN02tbr12JtqG0zU9Xom0obcP02tZrV6JtqPe9+eU55YSn5UlHHJ7bP35Rtl/80Vx6+afHzkrS73HrtSvRBqup1qafLVFVz0jytiSLSV6b5JVJfjZLe0T8XGvt2tW+wFqcjgEAAL3Zse3UsROmOnfnNWMncAi5uN1RYzccTJ/7mZ+cy99pf/D9/2WU79uKKyFaazclOW3ZVa+ZvKWqXpqlfSIAAABgLrXFuZxBjObRvETnhWtWAQAAAMy91V6i8+ZpNyXxgrIAAADAI7baxpSbsnQ6xp59rq84FQMAAAA4AKsNIT6W5PDW2s59b6iqTx2UIgAAAOjE4oI9IdbSahtTvmyF21609jkAAADAvHo0G1MCAAAAPGKGEAAAAMBMGEIAAAAAM7HaxpQAAABwyGoLi2MnzBUrIQAAAICZMIQAAAAAZsIQAgAAAJgJe0IAAADAFG2hjZ0wV6yEAAAAAGbCEAIAAACYCUMIAAAAYCbsCQEAAABTLNoTYk0ZQgAAwADn7rxm7ISpdmw7deyEqXo+bsDB53QMAAAAYCYMIQAAAICZcDoGAAAATNEWFsdOmCtWQgAAAAAzYQgBAAAAzIQhBAAAADAThhAAAADATNiYEgAAAKZYXGxjJ8wVKyEAAACAmTCEAAAAAGbCEAIAAACYCXtCAAAAwBRtwZ4Qa8lKCAAAAGAmDCEAAACAmTCEAAAAAGbCnhAAAAAwxeLC4tgJc8VKCAAAAGAmDCEAAACAmTCEAAAAAGZi3Qwhtp72rLzpi1dn+62fymmvf+XYOQ+hbZhe23rtSrQNpe3A9dqVaBtK2zC9tvXalWgbqte2S9740uy6+p258cPbx055mF6PWaJt3rSFNpdvY1kXQ4jasCHnvGd73n36S3Lh1uflpHPOzNFPf+rYWUm0DdVrW69dibahtM1PV6JtKG3D9NrWa1eibaie2y678rM541XvGDvjYXo+ZtpgZetiCLHl5G2597Y78/Wv3JV236YQAAAcN0lEQVSF++7LdR+4Msef9fyxs5JoG6rXtl67Em1DaZufrkTbUNqG6bWt165E21A9t33mhi9nzze/PXbGw/R8zLTBytbFEOLIYzZlz11ffeDyN3bdkyOP2TRi0YO0DdNrW69dibahtB24XrsSbUNpG6bXtl67Em1D9dzWq56PmTZY2UEZQlTVeVV1fVVdf0v+4mB8CQAAAGCdecxKN1bV4Ulel+QfJdmc5DtJ/jTJxa21S6d9XmvtkiSXJMkrasuj3vFiz927c+SxT3ng8hGbj86eu3c/2rtdE9qG6bWt165E21DaDlyvXYm2obQN02tbr12JtqF6butVz8dM2/wZcxPHebTaSoj3J7k9yWlJLkzyb5P88yTPqapfOchtD7jzupvy5OO25Kgtm7PxsMNy0tkvzM1XXDWrL78ibcP02tZrV6JtKG3z05VoG0rbML229dqVaBuq57Ze9XzMtMHKVlwJkWTLshUP76iq61pr/7qqXprkliT/6qDWTSwuLOSD51+QV3/ismzYuDHX7vhQ7rnl1ll86VVpG6bXtl67Em1DaZufrkTbUNqG6bWt165E21A9t73vzS/PKSc8LU864vDc/vGLsv3ij+bSyz89dlbXx0wbrKxam760pKquTfK61tpnqurMJK9qrZ02ue1LrbWnrfYF1uJ0DAAA4JHbse3UsROmOnfnNWMnsMYubnfU2A0H02d/7Jlz+Tvt3//Mp0f5vq22EuIVSd5bVccl+XySc5Okqv5Wkvcc5DYAAAAY1eLC4tgJc2XFIURr7eYkJ+/n+j+vKi97AQAAADxij+YlOi9cswoAAABg7q32Ep03T7spyaa1zwEAAADm1Wp7QmzK0stz7tnn+kpy7UEpAgAAgE60xbncl3I0qw0hPpbk8Nbazn1vqKpPHZQiAAAAYC6ttjHly1a47UVrnwMAAADMq0ezMSUAAADAI7ba6RgAAABwyFpcsCfEWrISAgAAAJgJQwgAAABgJgwhAAAAgJkwhAAAAABmwsaUAAAAMEVbWBw7Ya5YCQEAAADMhCEEAAAAMBOGEAAAAMBM2BMCAAAApmgLbeyEuWIIAQAAc+bcndeMnbCiHdtOHTthv3o/bjAPnI4BAADMTK8DCGA2DCEAAACAmXA6BgAAAEyxaE+INWUlBAAAADAThhAAAADATBhCAAAAADNhTwgAAACYoi0ujp0wV6yEAAAAAGbCEAIAAACYCUMIAAAAYCYMIQAAAICZsDElAAAATLG40MZOmCtWQgAAAAAzYQgBAAAAzIQhBAAAADAT9oQAAACAKZo9IdaUlRAAAADATBhCAAAAADNhCAEAAADMxLoZQmw97Vl50xevzvZbP5XTXv/KsXMeQtswvbb12pVoG0rbgeu1K9E2lLZhem3rtSvRNpS2A3fJG1+aXVe/Mzd+ePvYKQ/T6zFL+m7rVVtYnMu3sayLIURt2JBz3rM97z79Jblw6/Ny0jln5uinP3XsrCTahuq1rdeuRNtQ2uanK9E2lLZhem3rtSvRNpS2YS678rM541XvGDvjYXo+Zj23cehYF0OILSdvy7233Zmvf+WuLNx3X677wJU5/qznj52VRNtQvbb12pVoG0rb/HQl2obSNkyvbb12JdqG0jbMZ274cvZ889tjZzxMz8es5zYOHetiCHHkMZuy566vPnD5G7vuyZHHbBqx6EHahum1rdeuRNtQ2g5cr12JtqG0DdNrW69dibahtM2Xno9Zz20cOh6z0o1V9YQkv5jkp5I8OUlLcm+SjyZ5S2vtGwe9EAAAAEayuNDGTpgrq62E+FCSPUme3Vp7YmvtqCTPmVz3oWmfVFXnVdX1VXX9LfmLRx255+7dOfLYpzxw+YjNR2fP3bsf9f2uBW3D9NrWa1eibShtB67XrkTbUNqG6bWt165E21Da5kvPx6znNg4dqw0htrTW3tpa+9reK1prX2utvTXJ9077pNbaJa21E1trJ27N4x915J3X3ZQnH7clR23ZnI2HHZaTzn5hbr7iqkd9v2tB2zC9tvXalWgbStv8dCXahtI2TK9tvXYl2obSNl96PmY9t3HoWPF0jCR3VtXrkvxGa213klTVpiQvSXLXQW57wOLCQj54/gV59Scuy4aNG3Ptjg/lnltundWXX5G2YXpt67Ur0TaUtvnpSrQNpW2YXtt67Uq0DaVtmPe9+eU55YSn5UlHHJ7bP35Rtl/80Vx6+afHzur6mPXcxqGjWpt+fktVHZnkDUnOSrIpS3tC7E5yRZK3ttb+x2pf4BW1xQk0AABAkmTHtlPHTpjq3J3XjJ2wLl3c7qixGw6m/3Ls8XP5O+1P3nXzKN+3FVdCtNb2VNWvJ7kqyR+21r6197aqekGSjx/kPgAAABhNszHlmlpxT4iqenWWXgnj/CSfq6qzlt38KwczDAAAAJgvq+0J8XNJTmitfauqtiT5SFVtaa29K8lcL7kBAAAA1tZqQ4gNe0/BaK3dUVXPztIg4ntjCAEAAAAcgNWGELuraltrbWeSTFZEnJFkR5IfOuh1AAAAMKLFFV7MgQO34p4QSV6c5GvLr2it3d9ae3GSUw5aFQAAADB3Vnt1jF0r3PbZtc8BAAAA5tVqKyEAAAAA1sRqe0IAAADAIWvBnhBrykoIAAAAYCYMIQAAAICZMIQAAAAAZsKeEAAAADDFgi0h1pSVEAAAAMBMGEIAAAAAM2EIAQAAAMyEIQQAAAAwEzamBAAAgCkWmp0p15KVEAAAAMBMWAkBAADMzLk7rxk7Yaod204dO2Gqno8bHAgrIQAAAICZsBICAAAApliwJcSashICAAAAmAlDCAAAAGAmDCEAAACAmbAnBAAAAEyx0GwKsZashAAAAABmwhACAAAAmAlDCAAAAGAm7AkBAAAAUyzYEmJNWQkBAAAAzIQhBAAAADAThhAAAADATBhCAAAAADNhY0oAAACYYqHZmXItWQkBAAAAzIQhBAAAADAThhAAAADATKybIcTW056VN33x6my/9VM57fWvHDvnIbQN02tbr12JtqG0HbheuxJtQ2kbpte2XrsSbUNpO3C9diXJJW98aXZd/c7c+OHtY6c8TM/HrVcLbT7fxrIuhhC1YUPOec/2vPv0l+TCrc/LSeecmaOf/tSxs5JoG6rXtl67Em1DaZufrkTbUNqG6bWt165E21Da5qdrr8uu/GzOeNU7xs54mN6PG4eGdTGE2HLyttx72535+lfuysJ99+W6D1yZ4896/thZSbQN1Wtbr12JtqG0zU9Xom0obcP02tZrV6JtKG3z07XXZ274cvZ889tjZzxM78eNQ8O6GEIcecym7Lnrqw9c/saue3LkMZtGLHqQtmF6beu1K9E2lLYD12tXom0obcP02tZrV6JtKG0Hrteu3jlu9OAxQz+xqn63tXb6WsYAAABAT8bcP2EerTiEqKofmXZTkm0rfN55Sc5Lkmfmidmaxw8OTJI9d+/Okcc+5YHLR2w+Onvu3v2o7nOtaBum17ZeuxJtQ2k7cL12JdqG0jZMr229diXahtJ24Hrt6p3jRg9WOx3juiQXJfk3+7xdlOSIaZ/UWruktXZia+3ERzuASJI7r7spTz5uS47asjkbDzssJ539wtx8xVWP+n7XgrZhem3rtSvRNpS2+elKtA2lbZhe23rtSrQNpW1+unrnuNGD1U7H+EKSl7fWbt33hqq66+AkPdziwkI+eP4FefUnLsuGjRtz7Y4P5Z5bHpY0Cm3D9NrWa1eibSht89OVaBtK2zC9tvXalWgbStv8dO31vje/PKec8LQ86YjDc/vHL8r2iz+aSy//9NhZ3R83Dg3V2vQTXKrqHyf5k9bal/Zz20+11i5f7Qu8orY4gwYAAOjejm2njp0w1bk7rxk7YaqL2x01dsPB9O4nPG0uf6c9/5tfGuX7tuLpGK21jySpqnpuVR2+z81/dfCyAAAAgHmz4hCiql6d5KNJfj7J56rqrGU3/8rBDAMAAADmy2p7QvxckhNaa9+qqi1JPlJVW1pr78rSK2QAAAAAPCKrDSE2tNa+lSSttTuq6tlZGkR8bwwhAAAAgAOw2hBid1Vta63tTJLJiogzkuxI8kMHvQ4AAABGtDCX21KOZ8U9IZK8OMnXll/RWru/tfbiJKcctCoAAABg7qy4EqK1tmuF2z679jkAAADAvFptJQQAAADAmlhtTwgAAAA4ZC00m0KsJSshAAAAgJkwhAAAAABmwhACAAAAmAl7QgAAAMAUC7aEWFNWQgAAAAAzYQgBAAAAzIQhBAAAADAT9oQAAACAKRaaTSHWkpUQAAAAwEwYQgAAAAAz4XQMAACAJOfuvGbshKl2bDt17ISpLh47gHXFSggAAABgJqyEAAAAgCkW7Eu5pqyEAAAAAGbCEAIAAACYCUMIAAAAYCbsCQEAAABTLDSbQqwlKyEAAACAmTCEAAAAAGbCEAIAAACYCXtCAAAAwBSLYwfMGSshAAAAgJkwhAAAAABmwhACAAAAmAl7QgAAAMAUC62NnTBXrIQAAAAAZsIQAgAAAJgJQwgAAABgJgwhAAAAgJmwMSUAAABMsWBfyjW1blZCbD3tWXnTF6/O9ls/ldNe/8qxcx5C2zC9tvXalWgbStuB67Ur0TaUtmF6beu1K9E2lLYD12tX0nfbJW98aXZd/c7c+OHtY6dwiFoXQ4jasCHnvGd73n36S3Lh1uflpHPOzNFPf+rYWUm0DdVrW69dibahtM1PV6JtKG3D9NrWa1eibSht89OV9N2WJJdd+dmc8ap3jJ3BIWxdDCG2nLwt9952Z77+lbuycN99ue4DV+b4s54/dlYSbUP12tZrV6JtKG3z05VoG0rbML229dqVaBtK2/x0JX23Jclnbvhy9nzz22NncAhbF0OII4/ZlD13ffWBy9/YdU+OPGbTiEUP0jZMr229diXahtJ24HrtSrQNpW2YXtt67Uq0DaXtwPXalfTdxjALrc3l21hWHEJU1d+sqjdX1fuq6kX73PbvV/i886rq+qq6/pb8xVq1AgAAAOvYaishfj1JJfmtJGdX1W9V1XdNbvvRaZ/UWruktXZia+3ErXn8o47cc/fuHHnsUx64fMTmo7Pn7t2P+n7XgrZhem3rtSvRNpS2A9drV6JtKG3D9NrWa1eibShtB67XrqTvNujBakOI72+tvaG1dnlr7cwkNyS5pqqOmkHbA+687qY8+bgtOWrL5mw87LCcdPYLc/MVV80yYSptw/Ta1mtXom0obfPTlWgbStswvbb12pVoG0rb/HQlfbdBDx6zyu3fVVUbWmuLSdJa++WqujvJHyQ5/KDXTSwuLOSD51+QV3/ismzYuDHX7vhQ7rnl1ll9+RVpG6bXtl67Em1DaZufrkTbUNqG6bWt165E21Da5qcr6bstSd735pfnlBOelicdcXhu//hF2X7xR3Pp5Z8eO6trC+NtnzCXqq2wIUVVvS3JJ1tr/3Wf61+Q5N+11o5b7Qu8orb4lgEAADwKO7adOnbCVN+5cUeN3XAw/V+H/e25/J32ovtuH+X7tuLpGK211yXZVVXPrarDl13/8SSvPthxAAAAwPxY7dUxfj7JR5P8fJLPVdVZy27+5YMZBgAAAMyX1faEOC/JCa21b1XVliQfqaotrbV3ZelVMwAAAGBuLaywhQEHbrUhxIbW2reSpLV2R1U9O0uDiO+NIQQAAABwAFZ7ic7dVbVt74XJQOKMJE9K8kMHMwwAAACYL6sNIV6c5GvLr2it3d9ae3GSUw5aFQAAADB3Vjwdo7W2a4XbPrv2OQAAAMC8Wm1PCAAAADhkLdiXck2tdjoGAAAAwJowhAAAAABmwhACAAAAmAl7QgAAAMAUC82mEGvJSggAAABgJgwhAAAAgJkwhAAAAABmwp4QAAAAMMXCIbwlRFW9IMm7kmxM8t7W2lv2uf27klyW5IQk/z3JP22t3bHSfVoJAQAAADxEVW1M8p4kpyfZmuScqtq6z4e9LMme1tpTk/xqkreudr+GEAAAAMC+Tk5yW2vt9tbad5J8IMlZ+3zMWUl+Y/L+R5I8t6pqpTs1hAAAAAD2dUySu5Zd3jW5br8f01q7P8k3kxy10p0e9D0hLm53rDgFOVBVdV5r7ZK1vM+10GtXom0obcP02tZrV6JtKG0HrteuRNtQ2obpta3XrkTbUGvZdvFa3MkyPR+33qz177S9qKrzkpy37KpLZvH/ifW4EuK81T9kFL12JdqG0jZMr229diXahtJ24HrtSrQNpW2YXtt67Uq0DaWNbrXWLmmtnbjsbd8BxN1Jjl12efPkuv1+TFU9JskTsrRB5VTrcQgBAAAAHFzXJTmuqr6vqh6b5OwkV+zzMVck+dnJ+/84yTWttRVfT8RLdAIAAAAP0Vq7v6rOT/KJLL1E547W2ueranuS61trVyT5tSTvq6rbkvyPLA0qVrQehxC9nrfUa1eibShtw/Ta1mtXom0obQeu165E21Dahum1rdeuRNtQ2ljXWmu/k+R39rnugmXv/1WSnz6Q+6xVVkoAAAAArAl7QgAAAAAzsW6GEFX1gqr6UlXdVlVvGLtnr6raUVX3VtXnxm7ZV1UdW1W/V1W3VNXnq+o1YzftVVXfXVX/rapumrRdOHbTclW1sapurKqPjd2yXFXdUVV/UlU7q+r6sXuWq6ojquojVfXFqvpCVf29sZuSpKqeNjlee9/+Z1X9wthde1XVayf/Bj5XVb9ZVd89dlOSVNVrJk2f7+F47e9nbVU9saquqqpbJ/89spOun54ct8WqOnHWTau0vX3yb/Tmqvrtqjqio7Z/PenaWVWfrKqn9NK27LZ/UVWtqp7US1tVvamq7l72M+4neuiaXP/zk/+/fb6q3jbrrmltVfXBZcfrjqra2VHbtqr6w72P81V1ckdtz6iq/2/yPOTKqvqbI3Tt97ltJ48H09pGf0xYoa2LxwQOPetiCFFVG5O8J8npSbYmOaeqto5b9YBLk7xg7Igp7k/yL1prW5P8aJJXdXTc/jrJqa21ZyTZluQFVfWjIzct95okXxg7YorntNa2tdZG++Vmincl+Xhr7e8keUY6OX6ttS9Njte2JCck+cskvz1yVpKkqo5J8uokJ7bWfjBLG/6supnPwVZVP5jk55KcnKXv5RlV9dRxq/b7s/YNSa5urR2X5OrJ5Vm7NA/v+lySf5jkD2Ze81CX5uFtVyX5wdba8Um+nOQXZx01cWke3vb21trxk3+rH0tywcM+azYuzX4e16vq2CTPT/Jnsw5a5tLs/znHr+79OTc5d3fWLs0+XVX1nCRnJXlGa+3vJrlohK5kP22ttX+67HHht5L85zHCsv/v59uSXDhpu2ByeQyX5uFt703yhtbaD2XpcfRfzjoq05/b9vB4MK2th8eEaW29PCZwiFkXQ4gsPRG+rbV2e2vtO0k+kKUHttG11v4gS7uAdqe1dk9r7YbJ+3+RpV8Kjxm3aklb8q3JxcMmb11sUFJVm5P8ZJYebHkEquoJSU7J0u64aa19p7X2jXGr9uu5Sf60tXbn2CHLPCbJ36il11X+niRfHbknSZ6e5I9aa3/ZWrs/ye9n6QnUaKb8rD0ryW9M3v+NJD8106jsv6u19oXW2pdm3bKvKW2fnHxPk+QPs/R63zM3pe1/Lrv4uIz0mLDC4/qvJnldRnys6vU5x5SuVyZ5S2vtrycfc+/Mw7LyMauqSvJPkvzmTKMmprS1JHtXGDwhIz0mTGn7gTz4i/RVSf7RTKOy4nPbHh4P9tvWw2PCCm1dPCZw6FkvQ4hjkty17PKudPLL9HpRVVuS/HCSPxq35EG1dMrDziT3JrmqtdZL2zuz9ERzceyQ/WhJPllVf1xV540ds8z3JfnzJL9eS6exvLeqHjd21H6cnZGebO5Pa+3uLP118M+S3JPkm621T45blWTprzbPrKqjqup7kvxEkmNHbtqfTa21eybvfy3JpjFj1qFzk/zu2BHLVdUvV9VdSX4m462EeJiqOivJ3a21m8ZumeL8yXLqHWMsQ5/iB7L0c+SPqur3q+qksYP245lJdrfWbh07ZJlfSPL2yb+Di9LXX6Y/nwf/CPjTGflxYZ/ntl09HvT4vHuvFdq6e0xgfq2XIQSPQlUdnqXlhr+wz1+aRtVaW5gsN9yc5OTJEvBRVdUZSe5trf3x2C1T/Fhr7UeydGrSq6rqlLGDJh6T5EeS/IfW2g8n+XbGWQo5VVU9NsmZST48dstek18WzsrSEOcpSR5XVf9s3Kqlv+QneWuSTyb5eJKdSRZGjVpFW3qppy5WU60HVfVLWVqe+/6xW5Zrrf1Sa+3YLHWdP3ZPkkwGcf8qHQ1F9vEfknx/lk5tvCfJvxk35wGPSfLELC39/pdJPjRZedCTc9LRYHrilUleO/l38NpMVhh24twk/0dV/XGSxyf5zlghKz23HfvxoNfn3cn0tl4fE5hf62UIcXceOm3dPLmOVVTVYVn6YfP+1tpY5zyuaLJs//fSx94afz/JmVV1R5ZO+zm1qv7TuEkPmvzlfO+y1t/O0qlKPdiVZNey1SwfydJQoienJ7mhtbZ77JBlfjzJV1prf95auy9L5yX/byM3JUlaa7/WWjuhtXZKkj1ZOle0N7ur6ugkmfx3lOXe601VvSTJGUl+pvX7Ot3vzwhLvaf4/iwNCm+aPDZsTnJDVf0vo1ZNtNZ2T4b6i0n+n/T1uPCfJ6df/rcsrS4cZUPP/ZmcAvcPk3xw7JZ9/Gwe3KPiw+nn+5nW2hdba89vrZ2QpeHNn47RMeW5bRePBz0/757Wtk4eE5gz62UIcV2S46rq+yZ/zTw7yRUjN3Vv8heHX0vyhdbaO8buWa6q/tbeHXir6m8keV6SL45blbTWfrG1trm1tiVL/z+7prU2+l+mk6SqHldVj9/7fpY2SOviVVlaa19LcldVPW1y1XOT3DJi0v70+BevP0vyo1X1PZN/r89NJxt6VtWTJ//9X7P0RP3/Hbdov67I0hP2TP770RFb1oWqekGWTjc7s7X2l2P3LFdVxy27eFY6eExIktban7TWntxa2zJ5bNiV5EcmP/dGt/cXr4l/kE4eF5JcnuQ5SVJVP5DksUm+PmrRQ/14ki+21naNHbKPryZ51uT9U5N0c6rIsseFDUn+7yQXj9Aw7bnt6I8HnT/v3m9bz48JzLnW2rp4y9I5yV/O0tT1l8buWdb1m1la/nhflp6YvGzspmVtP5al5Wg3Z2k59c4kPzF216Tt+CQ3Tto+l+SCsZv20/jsJB8bu2NZz99OctPk7fM9/TuY9G1Lcv3ke3p5kiPHblrW9rgk/z3JE8Zu2U/bhVn6ZetzSd6X5LvGbpp0fTpLg6Sbkjy3g56H/axNclSWdkG/Ncl/TfLETrr+weT9v06yO8knOjpmt2Vpj6W9jwkXd9T2W5N/BzcnuTJLm6Z10bbP7XckeVIvbZOfG38yOW5XJDm6k67HJvlPk+/pDVl6Rawujtnk+kuTvGKMplWO248l+ePJz94/SnJCR22vydJz8S8neUuSGqFrv89tO3k8mNY2+mPCCm1dPCZ4O/TeqjWrbgAAAICDb72cjgEAAACsc4YQAAAAwEwYQgAAAAAzYQgBAAAAzIQhBAAAADAThhAAAADATBhCAAAAADNhCAEAAADMxP8PgdUY53FplGsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(C, cmap='RdBu', annot=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "N3aIOiVGvcIg",
    "XdI8EjuHLsM2"
   ],
   "name": "MIDAS-Task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001d9e5bd2624a1f80bc1b6c711c345d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "003cd01772534e10b6d0425338407bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f12388d372a4ac68f40a7e471be44bd",
      "placeholder": "​",
      "style": "IPY_MODEL_5862321621d64f2994e997439549b9e1",
      "value": " 760/760 [33:20&lt;00:00, 2.63s/B]"
     }
    },
    "033f417598e245a7a91ff4ec9e01344c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "198a6ced6a5d43bd94c0423d1d1363e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5f6f16836f04788a465b50d7af3b06e",
      "placeholder": "​",
      "style": "IPY_MODEL_cde08bde2cc446cc954d398e64fcceb7",
      "value": " 28.0/28.0 [00:06&lt;00:00, 4.45B/s]"
     }
    },
    "1f5188b5ab2f4091b8c88c1be8761ab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70324cb7e09b464692a21b66480fc1c2",
       "IPY_MODEL_431aa13dcdba4c3a8a6d472e64d44e72"
      ],
      "layout": "IPY_MODEL_ba0f9eb03e9349bc8940bc0362c42b86"
     }
    },
    "25323d3253774cf8b4ed1445b946cf28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27470550cb604a1591e145754dbad19a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89d0c63e1a8144fdb83cd2d4068536b5",
       "IPY_MODEL_e6820355bb4e4843bd84d8f401300d1e"
      ],
      "layout": "IPY_MODEL_c60fb9328264495896719cd2924ecd7d"
     }
    },
    "27bf6337646b46ef97942d68c5d9b6a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28f89249755e44b2b674299d5b02e251": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29a5a26093a04f9ab3cdb0e6047a9d8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2ae06d60a24c4ded9a5a761eca994012": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_033f417598e245a7a91ff4ec9e01344c",
      "placeholder": "​",
      "style": "IPY_MODEL_8fd116a2abc94062b365f77574b97466",
      "value": " 798k/798k [00:06&lt;00:00, 125kB/s]"
     }
    },
    "2be6504a9bba485d9cd0851afdba25c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c58603c9d79419f9e7475f4454a1c54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d5974bcfbb549918b6997f17adbc89d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2be6504a9bba485d9cd0851afdba25c2",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a363a8dd95b2494e9a14007a0df9f875",
      "value": 28
     }
    },
    "30ac40c9857049cd92205abf90417495": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "324abcde59354abfbe845c2abf5f82b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34c433a6584b4b689a271d181f90cb72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "397756d45e744570923fc0d126886ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e45214b0f724d13ae453d9866a0bcb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3f12388d372a4ac68f40a7e471be44bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4097cb21fc324e259ed55ee4bca58294": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1e23002972d4a1986d16b1bc5125e63",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f0564c0c490421380a180def217f8cb",
      "value": 231508
     }
    },
    "431aa13dcdba4c3a8a6d472e64d44e72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28f89249755e44b2b674299d5b02e251",
      "placeholder": "​",
      "style": "IPY_MODEL_93235cacd8664c85acebc92fa2d79820",
      "value": " 1.38M/1.38M [00:01&lt;00:00, 1.15MB/s]"
     }
    },
    "479abdf3fa544b2da33a1c04055786eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c09bc2b75774793910305f94d84f177": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3222dc051d04d669e3d4288eb65ca31",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c709994590ef4633bd9618f4e9285b29",
      "value": 466062
     }
    },
    "4c87fa8b40b74713b2154841cb2381ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ef081c49b734170bcab9c71013293b6",
       "IPY_MODEL_003cd01772534e10b6d0425338407bdc"
      ],
      "layout": "IPY_MODEL_d732ac48de144b0ca3a0d8ab9a9d63cf"
     }
    },
    "4f9ee7ad846f4598b91c27d77bf25f5d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51cc5007b53741e68e8f99075ad3b9d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfbfb17265f444a78de57a18e34af7ac",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_adde972b1f814b14ab0654e7e0bdc2ad",
      "value": 267967963
     }
    },
    "5862321621d64f2994e997439549b9e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d660d8a3fc34dc09f5d6c3c251199a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60729f7712fc4c80ad5f9b283a5ad33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64a00263f5b54b12b249a089e4eeb4ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65740ce4199f4c55b55af4d8e560e913": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_479abdf3fa544b2da33a1c04055786eb",
      "placeholder": "​",
      "style": "IPY_MODEL_27bf6337646b46ef97942d68c5d9b6a3",
      "value": " 466k/466k [00:00&lt;00:00, 1.34MB/s]"
     }
    },
    "6a653c2f13e9484390ba021f4351e778": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c09bc2b75774793910305f94d84f177",
       "IPY_MODEL_65740ce4199f4c55b55af4d8e560e913"
      ],
      "layout": "IPY_MODEL_324abcde59354abfbe845c2abf5f82b3"
     }
    },
    "6b650ab0a7e54d0f873b8393a725f7f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "70324cb7e09b464692a21b66480fc1c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c58603c9d79419f9e7475f4454a1c54",
      "max": 1382015,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f27d7340b1f04cf786b69e65f4453527",
      "value": 1382015
     }
    },
    "7d97dac059b64df6866501ee2656ce1a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f0564c0c490421380a180def217f8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "805235e746b54ef0a7eaeeb6003688e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82836eef9acc46f9973c58df9f3bedae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82ff37b8a903411286c64232c57a0d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89d0c63e1a8144fdb83cd2d4068536b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60729f7712fc4c80ad5f9b283a5ad33c",
      "max": 467042463,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b650ab0a7e54d0f873b8393a725f7f1",
      "value": 467042463
     }
    },
    "8bc3a15a49d74bceaf2596bf82b236ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8beb96ea11254e14a693e6acf8f297c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d660d8a3fc34dc09f5d6c3c251199a8",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29a5a26093a04f9ab3cdb0e6047a9d8f",
      "value": 798011
     }
    },
    "8fd116a2abc94062b365f77574b97466": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93235cacd8664c85acebc92fa2d79820": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bd55b5ff9b94d4b8e8f7e5170d17399": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34c433a6584b4b689a271d181f90cb72",
      "placeholder": "​",
      "style": "IPY_MODEL_397756d45e744570923fc0d126886ddb",
      "value": " 442/442 [00:00&lt;00:00, 777B/s]"
     }
    },
    "9ef081c49b734170bcab9c71013293b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e38214c1da6e4e82b9c91589924c0e60",
      "max": 760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e45214b0f724d13ae453d9866a0bcb2",
      "value": 760
     }
    },
    "a363a8dd95b2494e9a14007a0df9f875": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a86bfa28c1fa46ec9b809ad44bbfea67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8d8800d797a4b4786dbf0b583e4b09a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9ea55ebbc4944d4a8e09af5df51a0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8af4ea753f64ef0a9026e55fe70e5d8",
       "IPY_MODEL_9bd55b5ff9b94d4b8e8f7e5170d17399"
      ],
      "layout": "IPY_MODEL_805235e746b54ef0a7eaeeb6003688e1"
     }
    },
    "adde972b1f814b14ab0654e7e0bdc2ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "af65d665374c407d9a73e9ceca872030": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b3222dc051d04d669e3d4288eb65ca31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba0f9eb03e9349bc8940bc0362c42b86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1e23002972d4a1986d16b1bc5125e63": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3ee5617cc7446198933aaa5b781cbd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bc3a15a49d74bceaf2596bf82b236ba",
      "placeholder": "​",
      "style": "IPY_MODEL_001d9e5bd2624a1f80bc1b6c711c345d",
      "value": " 268M/268M [00:05&lt;00:00, 50.7MB/s]"
     }
    },
    "c60fb9328264495896719cd2924ecd7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c709994590ef4633bd9618f4e9285b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c8af4ea753f64ef0a9026e55fe70e5d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30ac40c9857049cd92205abf90417495",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af65d665374c407d9a73e9ceca872030",
      "value": 442
     }
    },
    "cb47065a6dae4908b361a9c9cc563dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82836eef9acc46f9973c58df9f3bedae",
      "placeholder": "​",
      "style": "IPY_MODEL_82ff37b8a903411286c64232c57a0d0a",
      "value": " 232k/232k [00:00&lt;00:00, 1.34MB/s]"
     }
    },
    "cde08bde2cc446cc954d398e64fcceb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d732ac48de144b0ca3a0d8ab9a9d63cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd7cd9aea58e46039f6e4337520cfe62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8beb96ea11254e14a693e6acf8f297c8",
       "IPY_MODEL_2ae06d60a24c4ded9a5a761eca994012"
      ],
      "layout": "IPY_MODEL_a8d8800d797a4b4786dbf0b583e4b09a"
     }
    },
    "dfbfb17265f444a78de57a18e34af7ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e38214c1da6e4e82b9c91589924c0e60": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5f6f16836f04788a465b50d7af3b06e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6820355bb4e4843bd84d8f401300d1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64a00263f5b54b12b249a089e4eeb4ff",
      "placeholder": "​",
      "style": "IPY_MODEL_a86bfa28c1fa46ec9b809ad44bbfea67",
      "value": " 467M/467M [00:13&lt;00:00, 35.2MB/s]"
     }
    },
    "ea7e184c32804f748be14a71bb9acf52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51cc5007b53741e68e8f99075ad3b9d9",
       "IPY_MODEL_c3ee5617cc7446198933aaa5b781cbd7"
      ],
      "layout": "IPY_MODEL_7d97dac059b64df6866501ee2656ce1a"
     }
    },
    "eec19dac5fbd4e489a35e16c3c0e68a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d5974bcfbb549918b6997f17adbc89d",
       "IPY_MODEL_198a6ced6a5d43bd94c0423d1d1363e9"
      ],
      "layout": "IPY_MODEL_4f9ee7ad846f4598b91c27d77bf25f5d"
     }
    },
    "ef501da5eeda46f8b712c8698a6dd3d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4097cb21fc324e259ed55ee4bca58294",
       "IPY_MODEL_cb47065a6dae4908b361a9c9cc563dfe"
      ],
      "layout": "IPY_MODEL_25323d3253774cf8b4ed1445b946cf28"
     }
    },
    "f27d7340b1f04cf786b69e65f4453527": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
